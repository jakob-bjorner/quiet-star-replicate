{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate Quiet-STAR's main results, and make it model agnostic\n",
    "\n",
    "Eval on the same datasets during training?\n",
    "\n",
    "Also add MMLU?\n",
    "\n",
    "CoT for gsm8k?\n",
    "\n",
    "What does eval need for COT eval? -- going through cot eval script now from them... They use the forward pass just the same very odd!!!! very inefficient!!!!! but whatever I guess it is easier to code.\n",
    "\n",
    "\n",
    "Making this system work for any model, how will I deal with the idea of a mixing head? combining the logits in a single stream and predicting with them?\n",
    "\n",
    "Also want to be able to handle the idea of multiple models used in an ensemble to get data uncertainty estimates. (https://pytorch.org/tutorials/intermediate/ensembling.html.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched gen required memory for first inference pass 524288\n",
      "additionally the past_key_value will have a batch of 2048 the entire time but the num keys/values will be 1\n",
      "parallel atten impl required mem for first inference pass 2048 here the past_key_value batch size will be 8 and 256 will be in the number of key and values dimension\n",
      "ultimately we don't take advantage of the repeated sequences if we are forced to generate a thought for every token, but we could argue that we can get diversity in place of this. we may want to instead do better with more context than with less context???\n"
     ]
    }
   ],
   "source": [
    "print(\"batched gen required memory for first inference pass\", 256 * 8 * 256) # memory consumption is reduced massively by the parallel attention head implementation.\n",
    "print(\"additionally the past_key_value will have a batch of\", 256 * 8, \"the entire time but the num keys/values will be 1\")\n",
    "print(\"parallel atten impl required mem for first inference pass\", 256 * 8, \"here the past_key_value batch size will be\", 8, \"and 256 will be in the number of key and values dimension\")\n",
    "\n",
    "print(\"ultimately we don't take advantage of the repeated sequences if we are forced to generate a thought for every token, but we could argue that we can get diversity in place of this. we may want to instead do better with more context than with less context???\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper params\n",
    "# policy_model_name = \"meta-llama/Llama-3.2-1B\" \n",
    "# Q_model_name = \"meta-llama/Llama-3.2-1B\" \n",
    "# reward_y_z_x_model_name = \"meta-llama/Llama-3.2-1B\" \n",
    "\n",
    "# policy_model_name = \"openai-community/gpt2\" \n",
    "# Q_model_name = \"openai-community/gpt2\" \n",
    "# reward_y_z_x_model_name = \"openai-community/gpt2\" \n",
    "\n",
    "# \"mistralai/Mistral-7B-v0.1\" ? \n",
    "quiet_star_model_name = \"openai-community/gpt2\" # \"meta-llama/Llama-3.2-1B\" # \n",
    "\n",
    "tokenizer_sot_token = \"<|sot_token|>\"\n",
    "tokenizer_eot_token = \"<|eot_token|>\"\n",
    "start_of_thought_token_init_embedding = \"---\" # None ??\n",
    "end_of_thought_token_init_embedding = \"---\" # None ??\n",
    "\n",
    "embedding_scaling = 1 # 1e2 TODO: get this working in the forward pass\n",
    "reinforce_loss_scaling = 1e6\n",
    "n_sampled_thoughts = 2 # for trice average\n",
    "original_loss_weight = 0.5\n",
    "base_loss_scaling = 1\n",
    "n_talk_tokens = 4\n",
    "n_thought_tokens = 2 # normally 12 '\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# mean resizing for new tokens will happen if the init embedding is set to None above.\n",
    "### end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(quiet_star_model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(quiet_star_model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "assert tokenizer.pad_token_id is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "def add_special_tokens_to_model_and_tokenizer(specific_model, specific_tokenizer, embedding_scaling):\n",
    "    if tokenizer_sot_token not in specific_tokenizer.get_added_vocab():\n",
    "        # new_tokens = [tokenizer_sot_token, tokenizer_eot_token]\n",
    "        specific_tokenizer.add_tokens(tokenizer_sot_token, special_tokens=True)\n",
    "        specific_model.resize_token_embeddings(len(specific_tokenizer), mean_resizing=True)\n",
    "        tokenizer_sot_token_id = specific_tokenizer.get_added_vocab()[tokenizer_sot_token]\n",
    "\n",
    "        specific_tokenizer.add_tokens(tokenizer_eot_token, special_tokens=True)\n",
    "        specific_model.resize_token_embeddings(len(specific_tokenizer), mean_resizing=True)\n",
    "        tokenizer_eot_token_id = specific_tokenizer.get_added_vocab()[tokenizer_eot_token]\n",
    "        with torch.no_grad():\n",
    "            model_embeddings = specific_model.get_input_embeddings().weight.data\n",
    "            if start_of_thought_token_init_embedding is not None:\n",
    "                sot_embedding = model_embeddings[tokenizer.encode(start_of_thought_token_init_embedding, add_special_tokens=False)[0]]\n",
    "                model_embeddings[tokenizer_sot_token_id] = sot_embedding / embedding_scaling\n",
    "            if end_of_thought_token_init_embedding is not None:\n",
    "                eot_embedding = model_embeddings[tokenizer.encode(end_of_thought_token_init_embedding, add_special_tokens=False)[0]]\n",
    "                model_embeddings[tokenizer_eot_token_id] = eot_embedding / embedding_scaling\n",
    "add_special_tokens_to_model_and_tokenizer(base_model, tokenizer, embedding_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: to test if this is truly working I would want to support at least the eval datasets that quiet-star works with, as well as the model which quiet-star works with.\n",
    "# For this I would need to support much longer sequences like 128 or 256 ideally. \n",
    "# so change the way my forward pass is done. calculate all the input sequences which will be used in the generation batch, then essentially run those through the model doing gradient accumulation on the loss? \n",
    "# (would require a backward pass). I could change the way the data is preprocessed to take this into account. Then the eval would have to be calculated only when a whole example has been able to pass through.\n",
    "# This would likely require my own training loop and then eventually figuring out how to do distributed training with Mistral, so I should come back to this idea if I have time.\n",
    "# Right now, I can add some parts of the DPO training loop which I need into their codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(4.0268, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(3.9827, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(4.0708, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(4.0268, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0., device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor([[[ 1.1575e-01, -3.7863e-02,  5.6798e-01,  ...,  4.7920e-01,\n",
       "           -2.8237e-01,  1.6246e-01],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02,  ..., -1.0000e+02,\n",
       "           -1.0000e+02, -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02,  ..., -1.0000e+02,\n",
       "           -1.0000e+02, -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02,  ..., -1.0000e+02,\n",
       "           -1.0000e+02, -1.0000e+02]],\n",
       " \n",
       "         [[ 1.1575e-01, -3.7863e-02,  5.6798e-01,  ...,  4.7920e-01,\n",
       "           -2.8237e-01,  1.6246e-01],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02,  ..., -1.0000e+02,\n",
       "           -1.0000e+02, -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02,  ..., -1.0000e+02,\n",
       "           -1.0000e+02, -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02,  ..., -1.0000e+02,\n",
       "           -1.0000e+02, -1.0000e+02]],\n",
       " \n",
       "         [[ 4.1180e-01,  2.4470e-01, -6.9713e-01,  ...,  2.2863e-01,\n",
       "           -3.1366e-01, -1.2472e-01],\n",
       "          [ 1.1575e-01, -3.7863e-02,  5.6798e-01,  ...,  4.7920e-01,\n",
       "           -2.8237e-01,  1.6246e-01],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02,  ..., -1.0000e+02,\n",
       "           -1.0000e+02, -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02,  ..., -1.0000e+02,\n",
       "           -1.0000e+02, -1.0000e+02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.8160e-01, -1.3633e-01,  1.5047e-01,  ..., -1.2122e-02,\n",
       "            1.0512e-02,  1.6888e-01],\n",
       "          [ 1.4305e-01,  2.9904e-01, -1.5917e+00,  ..., -2.6680e-01,\n",
       "            8.7320e-03,  2.3587e-01],\n",
       "          [-6.5418e-01, -5.9359e-01, -6.6015e-01,  ..., -1.4455e-01,\n",
       "            2.1628e-01,  2.1437e-01],\n",
       "          [-1.1563e+00, -4.4413e-02,  3.8590e-01,  ..., -7.4039e-02,\n",
       "            4.5854e-01, -1.2858e-01]],\n",
       " \n",
       "         [[-5.7374e-02, -1.7653e-02, -4.4888e-01,  ..., -1.8092e-01,\n",
       "           -3.3592e-02, -1.2949e-01],\n",
       "          [ 1.8160e-01, -1.3633e-01,  1.5047e-01,  ..., -1.2122e-02,\n",
       "            1.0512e-02,  1.6888e-01],\n",
       "          [ 1.4305e-01,  2.9904e-01, -1.5917e+00,  ..., -2.6680e-01,\n",
       "            8.7320e-03,  2.3587e-01],\n",
       "          [-6.5418e-01, -5.9359e-01, -6.6015e-01,  ..., -1.4455e-01,\n",
       "            2.1628e-01,  2.1437e-01]],\n",
       " \n",
       "         [[-5.7374e-02, -1.7653e-02, -4.4888e-01,  ..., -1.8092e-01,\n",
       "           -3.3592e-02, -1.2949e-01],\n",
       "          [ 1.8160e-01, -1.3633e-01,  1.5047e-01,  ..., -1.2122e-02,\n",
       "            1.0512e-02,  1.6888e-01],\n",
       "          [ 1.4305e-01,  2.9904e-01, -1.5917e+00,  ..., -2.6680e-01,\n",
       "            8.7320e-03,  2.3587e-01],\n",
       "          [-6.5418e-01, -5.9359e-01, -6.6015e-01,  ..., -1.4455e-01,\n",
       "            2.1628e-01,  2.1437e-01]]], device='cuda:0', grad_fn=<AddBackward0>),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_to_triangular_sequence_for_parallel_generation(elements_per_batch_element, inputs, fill_value, n_talk_tokens, predict_all=False):\n",
    "    if predict_all:\n",
    "        n_talk_tokens = 0\n",
    "    # predict_all will create thoughts which do not have enough tokens to calculate loss, this is useful for COT setting\n",
    "    max_seq = inputs.size(1)\n",
    "    max_thoughts_producable_with_enough_talk_tokens_remaining = (elements_per_batch_element - (n_talk_tokens)).clamp(min=0).sum().item() # minus 1 because we only predict n_talk_tokens, and without this, we would predict n_talk_tokens + 1 because one for every token and then one for eot token.\n",
    "    expanded_inputs = torch.full(size=(max_thoughts_producable_with_enough_talk_tokens_remaining, max_seq - (n_talk_tokens)),\n",
    "                                 fill_value=fill_value,\n",
    "                                 dtype=inputs.dtype,\n",
    "                                 device=inputs.device)\n",
    "    batch_being_filled = 0\n",
    "    for b_i in range(inputs.size(0)):\n",
    "        # each batch element should be expanded to fit the\n",
    "        elements_in_b_i = elements_per_batch_element[b_i].item()\n",
    "        if n_talk_tokens >= elements_in_b_i and not predict_all:\n",
    "            continue\n",
    "        num_sequences_with_enough_talk_tokens_remaining = elements_in_b_i - (n_talk_tokens)\n",
    "        sequence_b_i_start_index = max_seq - elements_in_b_i\n",
    "        triangular_inputs = inputs[[b_i], ...].expand(elements_in_b_i,-1).gather(1, (sequence_b_i_start_index + torch.arange(num_sequences_with_enough_talk_tokens_remaining, device=inputs.device, dtype=torch.long)[None, :] - torch.arange(num_sequences_with_enough_talk_tokens_remaining, device=inputs.device, dtype=torch.long)[:, None]).triu())\n",
    "        ones_like_triangular_inputs = torch.ones_like(triangular_inputs)\n",
    "        triangular_inputs = triangular_inputs.triu() + (ones_like_triangular_inputs - ones_like_triangular_inputs.triu()) * fill_value            \n",
    "        expanded_inputs[batch_being_filled: batch_being_filled + num_sequences_with_enough_talk_tokens_remaining, -num_sequences_with_enough_talk_tokens_remaining:] = triangular_inputs\n",
    "        batch_being_filled += num_sequences_with_enough_talk_tokens_remaining\n",
    "    return expanded_inputs\n",
    "\n",
    "def get_next_tokens_for_thoughts(elements_per_batch_element, input_ids, n_talk_tokens_to_leave_room_for, fill_value=-100, predict_all=False, get_token_before_label=False): \n",
    "    # get_token_before_label is useful if you want to pluck the hidden state used to predict the next token for the base model predictions.\n",
    "    n_labels_next_tokens = n_talk_tokens_to_leave_room_for\n",
    "    if predict_all:\n",
    "        n_talk_tokens_to_leave_room_for = 0\n",
    "        \n",
    "    # predict_all will populate next_tokens_for_thoughts which do not have enough tokens to calculate loss, this is useful for COT setting\n",
    "    # we assume every thought needs at least n_talk_tokens after it. \n",
    "    max_seq = input_ids.size(1)\n",
    "    max_thoughts_producable_with_enough_talk_tokens_remaining = (elements_per_batch_element - n_talk_tokens_to_leave_room_for).clamp(min=0).sum().item()\n",
    "    remaining_input_shape = tuple(input_ids.shape[2:]) # to support using this same function for base_hidden_state extraction\n",
    "    next_tokens_for_thoughts = torch.full((max_thoughts_producable_with_enough_talk_tokens_remaining, n_labels_next_tokens) + remaining_input_shape, fill_value=fill_value, dtype=input_ids.dtype, device=input_ids.device)\n",
    "    batch_being_filled = 0\n",
    "    input_ids = torch.concat([input_ids, torch.full_like(input_ids[:,[0]], fill_value=fill_value)], dim=1)# This to support -100 in the labels.\n",
    "\n",
    "    for b_i, elements_in_b_i in enumerate(elements_per_batch_element):\n",
    "        elements_in_b_i = elements_in_b_i.item()\n",
    "        if n_talk_tokens_to_leave_room_for >= elements_in_b_i:\n",
    "            continue\n",
    "        num_sequences_with_enough_talk_tokens_remaining = elements_in_b_i - n_talk_tokens_to_leave_room_for\n",
    "        sequence_b_i_start_index = max_seq - elements_in_b_i\n",
    "        indices_of_next_tokens = sequence_b_i_start_index + torch.concat(list(torch.arange(num_sequences_with_enough_talk_tokens_remaining, 0, -1, device=input_ids.device, dtype=torch.long)[:, None] + i for i in range(n_labels_next_tokens)), dim=-1)\n",
    "        if get_token_before_label:\n",
    "            indices_of_next_tokens -= 1\n",
    "        for additional_shape in remaining_input_shape:\n",
    "            indices_of_next_tokens = indices_of_next_tokens[...,None].expand(*(tuple(indices_of_next_tokens.shape) + (additional_shape,)))\n",
    "        # mechanism to support -100 placement at last index will be to append to the input_ids a last sequence element which is just -100s, then make indices which go past the end only grab the end element.\n",
    "        indices_of_next_tokens = indices_of_next_tokens.clamp(max=max_seq)\n",
    "        talk_tokens_for_b_i_thoughts = input_ids[[b_i], ...].expand(*((num_sequences_with_enough_talk_tokens_remaining, -1) + remaining_input_shape)).gather(1, indices_of_next_tokens)\n",
    "        next_tokens_for_thoughts[batch_being_filled: batch_being_filled + num_sequences_with_enough_talk_tokens_remaining] = talk_tokens_for_b_i_thoughts\n",
    "        batch_being_filled += num_sequences_with_enough_talk_tokens_remaining\n",
    "    return next_tokens_for_thoughts\n",
    "\n",
    "def get_input_sized_logits(inputs, logits, elements_per_batch_element):\n",
    "    # this n_sampled_thoughts = 1, and n_talk = 1, and that a thought was generated after every token, and used to predict only the next token.\n",
    "    return_logits = torch.zeros(tuple(inputs.shape) + tuple(logits.shape[-1:]), device=logits.device, dtype=logits.dtype)\n",
    "    # then we have to go through for every input\n",
    "    batch_being_filled = 0\n",
    "    for b_i, elements_in_b_i in enumerate(elements_per_batch_element):\n",
    "        return_logits[b_i, -elements_in_b_i:] = logits[batch_being_filled:batch_being_filled+elements_in_b_i:, -1].flip(dims=(0,))\n",
    "        batch_being_filled += elements_in_b_i\n",
    "    return return_logits\n",
    "# get_input_sized_logits(base_input_ids, talk_logits, elements_per_batch_element)\n",
    "class QuietSTARPolicyModel(nn.Module):\n",
    "    def __init__(self, base_llm_model, n_sampled_thoughts, n_thought_tokens, n_talk_tokens, embedding_scaling, reinforce_loss_scaling, original_loss_weight, base_loss_scaling):\n",
    "        super().__init__()\n",
    "        self.base_llm_model = base_llm_model\n",
    "        self.n_sampled_thoughts = n_sampled_thoughts\n",
    "        self.n_thought_tokens = n_thought_tokens\n",
    "        self.n_talk_tokens = n_talk_tokens\n",
    "        self.embedding_scaling = embedding_scaling\n",
    "        self.reinforce_loss_scaling = reinforce_loss_scaling\n",
    "        self.original_loss_weight = original_loss_weight\n",
    "        self.base_loss_scaling = base_loss_scaling\n",
    "        assert tokenizer.pad_token_id is not None, \"pad token id cannot be None\"\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.lm_head = base_llm_model.lm_head\n",
    "        self.mixing_head = nn.Sequential(\n",
    "            nn.Linear(self.base_llm_model.config.hidden_size * 2, self.base_llm_model.config.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.base_llm_model.config.hidden_size, self.base_llm_model.config.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.base_llm_model.config.hidden_size, 1, bias=False)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            # zero the last linear layer of the mixing head to start, so we rely only on the base model before trying to use our generated thoughts at all.\n",
    "            list(self.mixing_head.modules())[-1].weight.zero_()\n",
    "        # decorate the forward function\n",
    "        if not hasattr(self.base_llm_model, \"old_forward\"):\n",
    "            self.base_llm_model.old_forward = self.base_llm_model.forward\n",
    "        self.base_llm_model.forward = self.forward\n",
    "    def forward(self, *args, **kwargs): # for the purposes of testing with quiet-star's evals, all I have to do is parallely predict next token likelihoods over all tokens in some sequence.\n",
    "        # for passing through this forward pass to predict the next token on a given vocab, we would want to generate\n",
    "        # potentially only at the ends of the input ids? or for every token like a standard forward pass would do?\n",
    "        # if someone passes in a key_value_cache, we would want to behave appropriately by having it only generate a thought for the tokens in the key value cache\n",
    "        # to begin with we don't really have to replicate this desired effect, just generate a thought for every token, and see if we can get this to work. Even quietSTAR doesn't have a method to only think for the last token!\n",
    "        # in a single forward pass, we take in the input ids, \n",
    "        # print(\"kwargs\", kwargs.keys())\n",
    "\n",
    "        # if \"input_ids\" in kwargs:\n",
    "        #     print(kwargs['input_ids'].shape)\n",
    "        # if \"use_cache\" in kwargs:\n",
    "        #     print(kwargs[\"use_cache\"])\n",
    "        # if \"past_key_values\" in kwargs:\n",
    "        #     print(kwargs[\"past_key_values\"][0][0].shape)\n",
    "        if \"position_ids\" in kwargs:\n",
    "            raise Exception(f\"unexpected position_ids in kwargs {kwargs['position_ids'].shape=} with {kwargs.keys()=}\")\n",
    "        base_input_ids = kwargs.pop('input_ids')\n",
    "        base_attention_mask = kwargs.pop('attention_mask')\n",
    "        base_input_position_ids = (base_attention_mask.cumsum(-1) - 1).clamp(min=0)\n",
    "        base_outputs = self.base_llm_model.old_forward(input_ids=base_input_ids,\n",
    "                                                       attention_mask=base_attention_mask,\n",
    "                                                       position_ids=base_input_position_ids,\n",
    "                                                       return_dict=True,\n",
    "                                                       output_hidden_states=True,\n",
    "                                                       *args, **kwargs)\n",
    "        base_hidden_states = base_outputs['hidden_states'][-1] # len(base_outputs['hidden_states']) = input + one for every layer in that order. so base_outputs['hidden_states'][-1] gets last layer\n",
    "        \n",
    "        thoughts_for_every_token_sub_sequence_outputs, next_tokens_for_thoughts, context_sot_attention_mask, elements_per_batch_element = self.generate_for_every_token(base_input_ids, base_attention_mask)\n",
    "\n",
    "        context_sot_thought = thoughts_for_every_token_sub_sequence_outputs.sequences\n",
    "        thought_input_ids = context_sot_thought[:, -self.n_thought_tokens:] # this if we do some past_key_value based impelmentation. (for speed)\n",
    "        eot_tokens_to_right_pad = torch.full_like(context_sot_thought[:, [0]], fill_value=tokenizer.get_added_vocab()[tokenizer_eot_token])\n",
    "        context_sot_thought_eot = torch.concat([context_sot_thought, eot_tokens_to_right_pad], dim=-1)\n",
    "        # past_key_values = thoughts_for_every_token_sub_sequence_outputs.past_key_values # this will be useful later to speed up parallel generation implementation.\n",
    "        # now to get the probability of the next self.n_talk_tokens by feeding in the \n",
    "\n",
    "        # context_sot_thought_eot_label_padding = torch.full_like(context_sot_thought_eot, fill_value=-100, dtype=torch.long)\n",
    "        # talk_token_labels = torch.concat([context_sot_thought_eot_label_padding, next_tokens_for_thoughts], dim=-1)\n",
    "\n",
    "        next_tokens_for_thoughts_input_ids = next_tokens_for_thoughts.clone()\n",
    "        next_tokens_for_thoughts_input_ids[next_tokens_for_thoughts_input_ids == -100] = self.pad_token_id\n",
    "        context_sot_thought_eot_talk_input_ids = torch.concat([context_sot_thought_eot, next_tokens_for_thoughts_input_ids], dim=-1)\n",
    "        next_tokens_for_thoughts_attention_mask = next_tokens_for_thoughts.clone()\n",
    "        next_tokens_for_thoughts_attention_mask[next_tokens_for_thoughts_attention_mask != -100] = 1\n",
    "        next_tokens_for_thoughts_attention_mask[next_tokens_for_thoughts_attention_mask == -100] = 0\n",
    "        context_sot_thought_eot_talk_attention_mask = torch.concat([context_sot_attention_mask, torch.ones_like(thought_input_ids), torch.ones_like(eot_tokens_to_right_pad), next_tokens_for_thoughts_attention_mask], dim=-1)\n",
    "        \n",
    "        context_sot_thought_eot_talk_position_ids = (context_sot_thought_eot_talk_attention_mask.cumsum(-1) - 1).clamp(min=0)\n",
    "        thought_outputs = self.base_llm_model.old_forward(input_ids=context_sot_thought_eot_talk_input_ids[:, :-1], \n",
    "                                                          attention_mask=context_sot_thought_eot_talk_attention_mask[:, :-1],\n",
    "                                                          position_ids=context_sot_thought_eot_talk_position_ids[:,:-1],\n",
    "                                                        #   labels=talk_token_labels, # technically we don't need the last talk token except to see what the model thinks about the very last token which is only useful for generation. # this was commented out because we manually compute the loss and ignore the extra single next token thing.\n",
    "                                                          output_hidden_states=True,\n",
    "                                                          return_dict=True)\n",
    "        thought_hidden_states = thought_outputs[\"hidden_states\"][-1][:, -self.n_talk_tokens:] # how to ensure that we only have the hidden states for tokens pretaining to the talk tokens. just use the label tokens as a guide?\n",
    "        # expand the base_hidden_states for linearly combining them! this is batch_size x max_seq x 768, but needs to be num_thoughts x max_seq x 768, and it is difficult to know how many times to repeat each row,\n",
    "        expanded_base_hidden_states = get_next_tokens_for_thoughts(elements_per_batch_element, base_hidden_states, self.n_talk_tokens, predict_all=True, get_token_before_label=True) # [list(j for j, g in enumerate(thoughts_per_batch_element) for i in range(g))]\n",
    "        expanded_base_hidden_states = expanded_base_hidden_states.repeat_interleave(self.n_sampled_thoughts, dim=0)\n",
    "        mixing_factor = self.mixing_head(torch.concat([expanded_base_hidden_states, thought_hidden_states], dim=-1))\n",
    "        mixed_hidden_states = expanded_base_hidden_states * (1 - mixing_factor) + thought_hidden_states * mixing_factor\n",
    "        talk_logits = self.lm_head(mixed_hidden_states)\n",
    "        \n",
    "        return_dict: dict = defaultdict(lambda : None)\n",
    "        return_dict[\"last_hidden_states\"] = mixed_hidden_states # , \"logits\": talk_logits} logits will very strange shape, and are only used externally for cot eval. More can be done to combine the different predictions later, but for now, Just prepare logits if n_talk_tokens is 1, and get logits from every prediction, and line them in a row.\n",
    "\n",
    "        # TODO: fix the off by one error where I do not generate a token for the end of the sequence, because I don't generate a thought for the very last token because I assumed that we would always want the full context of self.n_talk_tokens.\n",
    "        #       or just leave it, and return the logits from this method only when the n_talk is 1, because that is the only time it makes sense, because we have one prediction for every seq token \n",
    "        # during the COT eval, how do they generate the next token?\n",
    "        if \"labels\" in kwargs: # without the labels defined, we still want to get the logits for every token position. when n_talk_tokens is greater than 1, we can just average them? or just return the logit corresponding to when this is the first thought. What quietstar does is they just output the logits which would predict the next token after n_thought. so at that point it is only logits for the seq_len - n_talk + 1\n",
    "            # move labels to correct device to enable model parallelism\n",
    "            next_tokens_for_thoughts = next_tokens_for_thoughts.to(talk_logits.device)\n",
    "            # Shift so that tokens < n predict n\n",
    "            talk_shift_logits = talk_logits.contiguous()\n",
    "            talk_shift_labels = next_tokens_for_thoughts.contiguous()\n",
    "            # Flatten the tokens\n",
    "            loss_fct = nn.CrossEntropyLoss(reduction='none') # this does mean reduction, but we need to comute the non reduced version to be able to calculate reward as defined by change in log likelihood (new_ll - old_ll)\n",
    "            talk_loss_per_talk_token = loss_fct(talk_shift_logits.view(-1, talk_shift_logits.size(-1)), talk_shift_labels.view(-1)).view(*talk_shift_labels.shape)\n",
    "            return_dict[\"talk_loss\"] = talk_loss_per_talk_token.sum() / (talk_shift_labels != -100).sum()\n",
    "\n",
    "            base_labels = kwargs[\"labels\"]\n",
    "            base_shift_logits = base_outputs['logits'][:,:-1].contiguous()\n",
    "            base_shift_labels = base_labels[:,1:].contiguous()\n",
    "            base_talk_loss = loss_fct(base_shift_logits.view(-1, base_shift_logits.size(-1)), base_shift_labels.view(-1)).view(*base_shift_labels.shape)\n",
    "            expanded_base_talk_loss = get_next_tokens_for_thoughts(elements_per_batch_element, base_talk_loss, self.n_talk_tokens, fill_value=0, predict_all=True, get_token_before_label=False)\n",
    "            expanded_base_talk_loss = expanded_base_talk_loss.repeat_interleave(self.n_sampled_thoughts, dim=0)\n",
    "            return_dict[\"base_talk_loss\"] = base_talk_loss.sum() / (base_shift_labels != -100).sum()\n",
    "            change_in_log_likelihood = expanded_base_talk_loss - talk_loss_per_talk_token\n",
    "            # reward per thought is stored in the rows\n",
    "            # num_predicted_labels_per_thought = (talk_shift_labels != -100).sum(-1)\n",
    "            reward_per_thought = change_in_log_likelihood.sum(-1) \n",
    "            # / num_predicted_labels_per_thought # I think I should just do the sum over the nll reduction because average would remove information about number of tokens predicted.\n",
    "            # reward_per_thought[num_predicted_labels_per_thought == 0] = 0.0 # remove the nan division by zeros\n",
    "            \n",
    "            # goal is to perform trice, which should be average performance on the prefix\n",
    "            control_variate = reward_per_thought.view(-1, self.n_sampled_thoughts).mean(-1).repeat_interleave(self.n_sampled_thoughts, dim=0) # if there are some\n",
    "            control_adjusted_reward_per_thought = reward_per_thought - control_variate\n",
    "            positive_control_adjusted_reward_per_thought = control_adjusted_reward_per_thought.clamp(min=0).detach()\n",
    "            # now we need log_thought_probabilities, to be able to get the reinforce loss\n",
    "            start_of_thought_index_in_context_sot_thought_eot_labels_m1 = -self.n_thought_tokens-self.n_talk_tokens-1\n",
    "            end_of_thought_index_in_context_sot_thought_eot_labels_m1 = -self.n_talk_tokens-1\n",
    "            thought_log_probabilities = thought_outputs[\"logits\"][:, start_of_thought_index_in_context_sot_thought_eot_labels_m1 : end_of_thought_index_in_context_sot_thought_eot_labels_m1].log_softmax(-1).gather(-1, thought_input_ids[..., None]).squeeze(-1).sum(-1)\n",
    "            policy_loss = - positive_control_adjusted_reward_per_thought * thought_log_probabilities\n",
    "            policy_loss = policy_loss.mean()\n",
    "            # base_outputs['loss'] # this should be defined if there are labels.\n",
    "            return_dict['base_and_talk_loss'] = (return_dict[\"base_talk_loss\"] * self.original_loss_weight + return_dict[\"talk_loss\"]  * (1 - self.original_loss_weight))\n",
    "            return_dict['policy_loss'] = policy_loss\n",
    "            return_dict['loss'] = return_dict['policy_loss'] * self.reinforce_loss_scaling + return_dict['base_and_talk_loss'] * self.base_loss_scaling\n",
    "            \n",
    "        else:\n",
    "            # no loss computation when labels aren't given, just give the language models predictions for the next token, which we will define to be the one right after the last talk token. \n",
    "            # This is nice for our generation evals, but doesn't reflect our loss well if we report it in the evals :<\n",
    "            assert self.n_talk_tokens == 1, \"num_talk_tokens must be one to return logits, and that is the only thing that makes sense if we are doing a forward pass without labels.\"\n",
    "            raise NotImplemented\n",
    "\n",
    "        if self.n_talk_tokens == 1 and self.n_sampled_thoughts == 1: # we want one logit per token, so we have to gather the corresponding token locations.\n",
    "            # logits on the corresponding token locations.\n",
    "            return_dict['logits'] = get_input_sized_logits(base_input_ids, talk_logits, elements_per_batch_element)\n",
    "        # we now have the hidden states num_thoughts x max_seq x 768 now using the same code we used to get the label mask, we can get the base hidden states corresponding to each label position.\n",
    "        return tuple(return_dict[key] for key in ['loss', \"talk_loss\", \"base_talk_loss\", \"base_and_talk_loss\", \"policy_loss\", 'last_hidden_states', 'logits']) # must return a tuple when working with huggingface trainer.\n",
    "    def base_model_generate(self, *args, **kwargs):\n",
    "        return self.generate(self.base_llm_model.old_forward, *args, **kwargs)\n",
    "    def generate(self, forward_function, *args, **kwargs):\n",
    "        temp_forward = forward_function\n",
    "        try:\n",
    "            self.base_llm_model.forward = self.base_llm_model.old_forward\n",
    "            gen_output = self.base_llm_model.generate(*args, **kwargs)\n",
    "        except:\n",
    "            raise\n",
    "        finally:\n",
    "            self.base_llm_model.forward = temp_forward\n",
    "        return gen_output\n",
    "        # now the choice is do I generate a thought per token, or do I just generate a single next token. The standard interface would be to support sampling the next token with this method, so I will create a different method to support the operation I want.\n",
    "\n",
    "    def generate_for_every_token(self, input_ids, attention_mask):\n",
    "        # this is simply just spreading out every token as a generation task.\n",
    "        # in the future, I can speed this up with past_key_values from a single standard forward pass on the input_ids as one \n",
    "        elements_per_batch_element = attention_mask.sum(-1)\n",
    "        # (num_tokens) x max_seq # the effective batch size is way larger. possibly max_seq * original_batch_size\n",
    "\n",
    "        # the strategy is to make only as many thoughts to where you have at least n_talk remaining tokens for labels.\n",
    "        thoughts_per_batch_element = (elements_per_batch_element - self.n_talk_tokens).clamp(min=0)\n",
    "        next_tokens_for_thoughts = get_next_tokens_for_thoughts(elements_per_batch_element, input_ids, self.n_talk_tokens, predict_all=True) # input_ids\n",
    "        expanded_input_ids = expand_to_triangular_sequence_for_parallel_generation(elements_per_batch_element, input_ids, fill_value=self.pad_token_id, n_talk_tokens=self.n_talk_tokens, predict_all=True)\n",
    "        expanded_attention_mask = expand_to_triangular_sequence_for_parallel_generation(elements_per_batch_element, attention_mask, fill_value=0, n_talk_tokens=self.n_talk_tokens, predict_all=True)\n",
    "        \n",
    "        sot_tokens_to_right_pad = torch.full_like(expanded_input_ids[:, [0]], fill_value=tokenizer.get_added_vocab()[tokenizer_sot_token])\n",
    "        expanded_input_ids = torch.concat([expanded_input_ids, sot_tokens_to_right_pad], dim=-1)\n",
    "        expanded_input_ids = expanded_input_ids.repeat_interleave(self.n_sampled_thoughts, 0)\n",
    "        mask_to_right_pad = torch.full_like(expanded_attention_mask[:, [0]], fill_value=1)\n",
    "        expanded_attention_mask = torch.concat([expanded_attention_mask, mask_to_right_pad], dim=-1)\n",
    "        expanded_attention_mask = expanded_attention_mask.repeat_interleave(self.n_sampled_thoughts, 0)\n",
    "\n",
    "        next_tokens_for_thoughts = next_tokens_for_thoughts.repeat_interleave(self.n_sampled_thoughts, 0)\n",
    "        # print(expanded_input_ids)\n",
    "        # print(expanded_attention_mask)\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        outputs = self.base_model_generate(input_ids=expanded_input_ids, attention_mask=expanded_attention_mask, max_new_tokens=self.n_thought_tokens, do_sample=True, return_dict_in_generate=True)\n",
    "        # print(outputs.keys())\n",
    "        return outputs, next_tokens_for_thoughts,  expanded_attention_mask, elements_per_batch_element\n",
    "\n",
    "quiet_star_model = QuietSTARPolicyModel(deepcopy(base_model), n_sampled_thoughts, n_thought_tokens, n_talk_tokens, embedding_scaling, reinforce_loss_scaling, original_loss_weight, base_loss_scaling).to(device)\n",
    "# quiet_star_model = QuietSTARPolicyModel(deepcopy(base_model), 1, n_thought_tokens, 1, embedding_scaling, reinforce_loss_scaling, original_loss_weight, base_loss_scaling).to(device)\n",
    "base_inputs = tokenizer([\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\", \"how is it going Schrammy?\"], return_tensors='pt', padding=True, padding_side=\"left\", add_special_tokens=True).to(device)\n",
    "# print(base_inputs)\n",
    "base_input_labels = base_inputs.input_ids.clone()\n",
    "base_input_labels[base_inputs.attention_mask == 0] = -100\n",
    "base_input_labels[torch.arange(base_input_labels.size(0)), base_inputs.attention_mask.argmax(dim=-1)] = -100 # gets the first location? I don't know  if this is a safe bet, but whatever for now...\n",
    "quiet_star_model.forward(**base_inputs, labels=base_input_labels)\n",
    "# quiet_star_model.generate_for_every_token(**base_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4a97397b4147f7979a59b198d7b104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjakobbbjorner\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nethome/jbjorner3/dev/hallucination-fun/quiet_star_replicate/scratch/wandb/run-20241205_114035-in6k5cn9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jakobbbjorner/huggingface/runs/in6k5cn9' target=\"_blank\">quiet_star_replicate_runs/cache/quietstar/1733416833</a></strong> to <a href='https://wandb.ai/jakobbbjorner/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jakobbbjorner/huggingface' target=\"_blank\">https://wandb.ai/jakobbbjorner/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jakobbbjorner/huggingface/runs/in6k5cn9' target=\"_blank\">https://wandb.ai/jakobbbjorner/huggingface/runs/in6k5cn9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='425' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   425/100000 03:14 < 12:42:11, 2.18 it/s, Epoch 0.85/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>891.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3228.316600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5515.293700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6293.570300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6178.756300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>7252.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>7733.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>6586.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>6455.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5995.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5905.518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5190.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>6104.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>6078.840200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5684.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>6697.660200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5893.401200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5949.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>6053.866400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6794.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5127.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>6277.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5045.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>6206.814100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5578.565200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5209.388300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5066.967600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5447.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5028.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>6154.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5191.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4584.929300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4363.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4739.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4287.881300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4106.789100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4827.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4800.680100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4036.913300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4594.091400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4294.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4300.900400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 110\u001b[0m\n\u001b[1;32m     78\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# use_cpu=True,\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# no_cuda=True, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     save_total_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m#running out of scratch storage, only save latest ckpt\u001b[39;00m\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    102\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    103\u001b[0m     model\u001b[38;5;241m=\u001b[39mquiet_star_model,\n\u001b[1;32m    104\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# model_init=model_init,\u001b[39;00m\n\u001b[1;32m    109\u001b[0m )\n\u001b[0;32m--> 110\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/accelerate/utils/memory.py:158\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2479\u001b[0m )\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/trainer.py:3579\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3579\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3584\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3585\u001b[0m ):\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 124\u001b[0m, in \u001b[0;36mQuietSTARPolicyModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m base_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_llm_model\u001b[38;5;241m.\u001b[39mold_forward(input_ids\u001b[38;5;241m=\u001b[39mbase_input_ids,\n\u001b[1;32m    117\u001b[0m                                                attention_mask\u001b[38;5;241m=\u001b[39mbase_attention_mask,\n\u001b[1;32m    118\u001b[0m                                                position_ids\u001b[38;5;241m=\u001b[39mbase_input_position_ids,\n\u001b[1;32m    119\u001b[0m                                                return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                                                output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    121\u001b[0m                                                \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    122\u001b[0m base_hidden_states \u001b[38;5;241m=\u001b[39m base_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# len(base_outputs['hidden_states']) = input + one for every layer in that order. so base_outputs['hidden_states'][-1] gets last layer\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m thoughts_for_every_token_sub_sequence_outputs, next_tokens_for_thoughts, context_sot_attention_mask, elements_per_batch_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_for_every_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_attention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m context_sot_thought \u001b[38;5;241m=\u001b[39m thoughts_for_every_token_sub_sequence_outputs\u001b[38;5;241m.\u001b[39msequences\n\u001b[1;32m    127\u001b[0m thought_input_ids \u001b[38;5;241m=\u001b[39m context_sot_thought[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_thought_tokens:] \u001b[38;5;66;03m# this if we do some past_key_value based impelmentation. (for speed)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 253\u001b[0m, in \u001b[0;36mQuietSTARPolicyModel.generate_for_every_token\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    249\u001b[0m next_tokens_for_thoughts \u001b[38;5;241m=\u001b[39m next_tokens_for_thoughts\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_sampled_thoughts, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# print(expanded_input_ids)\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# print(expanded_attention_mask)\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# import ipdb; ipdb.set_trace()\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_thought_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# print(outputs.keys())\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, next_tokens_for_thoughts,  expanded_attention_mask, elements_per_batch_element\n",
      "Cell \u001b[0;32mIn[6], line 217\u001b[0m, in \u001b[0;36mQuietSTARPolicyModel.base_model_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbase_model_generate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_llm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mold_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 222\u001b[0m, in \u001b[0;36mQuietSTARPolicyModel.generate\u001b[0;34m(self, forward_function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_llm_model\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_llm_model\u001b[38;5;241m.\u001b[39mold_forward\n\u001b[0;32m--> 222\u001b[0m     gen_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_llm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/generation/utils.py:3195\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3192\u001b[0m unfinished_sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(batch_size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3193\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_initial_cache_position(input_ids, model_kwargs)\n\u001b[0;32m-> 3195\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_unfinished_sequences(\n\u001b[1;32m   3196\u001b[0m     this_peer_finished, synced_gpus, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice, cur_len\u001b[38;5;241m=\u001b[39mcur_len, max_length\u001b[38;5;241m=\u001b[39mmax_length\n\u001b[1;32m   3197\u001b[0m ):\n\u001b[1;32m   3198\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[1;32m   3199\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   3201\u001b[0m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "random_seed = 42\n",
    "\n",
    "dataset_name = 'open-web-math/open-web-math'\n",
    "n_examples = 1_000\n",
    "max_seq_len = 32\n",
    "\n",
    "\n",
    "dataset = load_dataset(\n",
    "    dataset_name,\n",
    "    \"en\" if \"c4\" in dataset_name else \"default\",\n",
    "    split=f\"train[:{n_examples}]\",\n",
    "    # ignore_verifications=True,\n",
    "    verification_mode=datasets.VerificationMode.NO_CHECKS,\n",
    "    num_proc=4,\n",
    "    # cache_dir=root_prefix + \"cache/datasets/\",\n",
    ")\n",
    "def get_preprocess_function(max_length):\n",
    "    def preprocess_function(examples):\n",
    "        if isinstance(examples[\"text\"], str):\n",
    "            dataset_transform = lambda xs: [xs[\"text\"]]\n",
    "        else:\n",
    "            dataset_transform = lambda xs: xs[\"text\"]\n",
    "        all_tokenized = [tokenizer.encode(t, return_tensors=\"pt\", ) for t in dataset_transform(examples)]\n",
    "        new_tokenized = [{\"input_ids\": t} for t in all_tokenized]\n",
    "        for i, t in enumerate(new_tokenized):\n",
    "            new_tokenized[i][\"input_ids\"] = truncate_or_pad(t['input_ids'], tokenizer.pad_token_id, max_length)\n",
    "        new_input_ids = torch.cat([t[\"input_ids\"] for t in new_tokenized], dim=0)\n",
    "        new_attention_mask = (new_input_ids != tokenizer.pad_token_id).long()\n",
    "        tokenized = {\"input_ids\": new_input_ids, \"attention_mask\": new_attention_mask}\n",
    "        tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "        tokenized[\"labels\"][new_attention_mask == 0] = -100\n",
    "        tokenized['labels'][torch.arange(new_attention_mask.size(0)), new_attention_mask.argmax(dim=-1)] = -100\n",
    "        return tokenized\n",
    "    # def preprocess_function(examples):\n",
    "    #     if isinstance(examples[\"text\"], str):\n",
    "    #         dataset_transform = lambda xs: [xs[\"text\"]]\n",
    "    #     else:\n",
    "    #         dataset_transform = lambda xs: xs[\"text\"]\n",
    "    #     print(examples)\n",
    "    #     print()\n",
    "    #     all_tokenized = tokenizer(dataset_transform(examples), return_tensors=\"pt\", padding=True, padding_side='left', max_length=max_seq_len)\n",
    "    #     # all_tokenized = [tokenizer(t, return_tensors=\"pt\", padding_side='left', max_length=max_seq_len) for t in dataset_transform(examples)] # Jakob: changed to padding side right\n",
    "    #     # new_tokenized = [{\"input_ids\": t.input_ids,} for t in all_tokenized]\n",
    "    #     assert tokenizer.pad_token_id is not None, \"Must have a valid pad token, but it was None.\"\n",
    "    #     new_input_ids = all_tokenized.input_ids\n",
    "    #     new_attention_mask = all_tokenized.attention_mask\n",
    "    #     tokenized = {\"input_ids\": new_input_ids, \"attention_mask\": new_attention_mask}\n",
    "    #     tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    #     tokenized['labels'][new_attention_mask == 0] = -100 # Jakob: changed\n",
    "    #     tokenized['labels'][torch.arange(new_attention_mask.size(0)), new_attention_mask.argmax(dim=-1)] = -100 # gets the first location? I don't know  if this is a safe bet, but whatever for now...\n",
    "    #     # tokenized['position_ids'] = (base_inputs.attention_mask.cumsum(-1) - 1).clamp(min=0)\n",
    "    #     # tokenized['labels'][new_attention_mask == 0] = -100 # Jakob: changed\n",
    "    #     return tokenized\n",
    "    return preprocess_function\n",
    "def truncate_or_pad(t, padding_idx=0, max_length=256): # now left padding\n",
    "    if t.shape[1] > max_length:\n",
    "        start = random.randint(0, t.shape[1] - max_length)\n",
    "        t = t[:, start:start + max_length]\n",
    "    else:\n",
    "        padding = torch.zeros(t.shape[0], max_length - t.shape[1], dtype=t.dtype, device=t.device)\n",
    "        t = torch.cat([padding + padding_idx, t], dim=1) # left now.\n",
    "    return t\n",
    "train_dataset = dataset.shuffle(seed=random_seed).map(get_preprocess_function(max_seq_len), batched=True, writer_batch_size=200, remove_columns=[\"text\"])\n",
    "root_prefix = 'quiet_star_replicate_runs/'\n",
    "full_batch_size = 2\n",
    "n_passes_global = 2\n",
    "gradient_accumulation_steps = 1\n",
    "import time\n",
    "run_id = int(time.time())\n",
    "\n",
    "batch_size = full_batch_size // n_passes_global\n",
    "global_gradient_accumulation_steps = full_batch_size // batch_size * gradient_accumulation_steps\n",
    "eval_and_logging_steps = 10\n",
    "training_args = TrainingArguments(\n",
    "    # use_cpu=True,\n",
    "    # no_cuda=True, \n",
    "    output_dir=root_prefix + f\"cache/quietstar/{run_id}\",\n",
    "    learning_rate=1e-6,\n",
    "    optim= \"adamw_torch_fused\" if torch.cuda.is_available() else \"adamw_torch\",  # \"adamw_8bit\", #\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=global_gradient_accumulation_steps,\n",
    "    max_grad_norm=1.0,\n",
    "    max_steps=100000,\n",
    "    warmup_steps=20,\n",
    "    auto_find_batch_size=True, # doesn't seem to work for my a40 Jakob\n",
    "    weight_decay=0.001,\n",
    "    label_names=[\"labels\", \"input_ids\", \"attention_mask\"],\n",
    "    # include_inputs_for_metrics=True,\n",
    "    logging_steps=eval_and_logging_steps,\n",
    "    # eval_steps=eval_and_logging_steps,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    save_safetensors=False,\n",
    "    # save_steps=save_steps,\n",
    "    # run_name=f\"{debug_prefix}n={n_ahead_global}_nt={n_ahead_talk_global}_np={n_passes_global}_fbz={full_batch_size}_seql={max_seq_len}_gacc={gradient_accumulation_steps}_sot={initial_start_token}_embsc={embedding_scale}_cyc={cycling_sot_token}_rm={reward_modeling}_rmb={rm_beta}_plb={policy_loss_beta}_mp={use_meta_prompt}_{meta_prompt_list}\",\n",
    "    save_total_limit = 1, #running out of scratch storage, only save latest ckpt\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=quiet_star_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=eval_datasets,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    # model_init=model_init,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6456, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_inputs_left_pad = tokenizer([\"What can you tell me about the Janet egg problem?\", \"how is it going Schrammy?\"], return_tensors='pt', padding=True, padding_side=\"left\", add_special_tokens=True)\n",
    "base_inputs_left_pad.input_ids\n",
    "labels_left_pad = base_inputs_left_pad.input_ids.clone()\n",
    "labels_left_pad[base_inputs_left_pad.attention_mask == 0] = -100\n",
    "labels_left_pad[torch.arange(labels_left_pad.size(0)), base_inputs_left_pad.attention_mask.argmax(dim=-1)] = -100 # gets the first location? I don't know  if this is a safe bet, but whatever for now...\n",
    "position_ids_left = (base_inputs_left_pad.attention_mask.cumsum(-1) - 1).clamp(min=0)\n",
    "base_model(**base_inputs_left_pad, labels=labels_left_pad, position_ids=position_ids_left).loss# .logits[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6456, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -37.2173,  -70.6897, -124.5740,  -97.8898, -105.1452,  -76.4182,\n",
       "          -90.5668,  -71.3065,  -83.2462,  -77.9504, -135.7136],\n",
       "        [ -29.7428,  -74.9223,  -85.6836,  -48.5544,  -93.3122,  -70.0023,\n",
       "          -64.0737, -119.7977,  -91.2024,  -90.9099,  -90.9580]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_inputs_right_pad = tokenizer([\"What can you tell me about the Janet egg problem?\", \"how is it going Schrammy?\"], return_tensors='pt', padding=True, padding_side=\"right\", add_special_tokens=True)\n",
    "base_inputs_right_pad.input_ids\n",
    "labels_right_pad = base_inputs_right_pad.input_ids.clone()\n",
    "labels_right_pad[base_inputs_right_pad.attention_mask == 0] = -100\n",
    "print(base_model(**base_inputs_right_pad, labels=labels_right_pad).loss)\n",
    "base_model(**base_inputs_right_pad, labels=labels_right_pad).logits[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16, 17],\n",
       "        [15, 16],\n",
       "        [14, 15],\n",
       "        [13, 14],\n",
       "        [12, 13],\n",
       "        [11, 12]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.arange(8)[None, :].repeat(8, 1) + 10).gather(1, torch.concat(list(torch.arange(8 - 2 , 0, -1)[:, None] + i for i in range(2)), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'past_key_values', 'hidden_states'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_outputs = base_model(**base_inputs, labels=base_inputs.input_ids, return_dict=True, output_hidden_states=True, past_key)\n",
    "base_outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"how is it going?\\n\\nThe answer is that it's not going\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(quiet_star_model.base_model_generate(**base_inputs, max_new_tokens=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifically so gradients get aggregated to the same forward pass which computed the initial key values. \n",
    "# this for the base model mixed in logits or for parallel generation? (parallel gen has no grads, so mix in portion.)\n",
    "# TODO: is this useful? does it save compute if we need to compute the gradient on the new thoughts anyways?\n",
    "base_outputs.past_key_values[0][1].shape\n",
    "reshaped_past_key_values = tuple()\n",
    "for key, value in base_outputs.past_key_values:\n",
    "    # we get a new key for every batch, and we have to left padd these new keys with something stupid, so we can notice if we have done anything wrong.\n",
    "    batch_sz = key.size(0)\n",
    "    num_tokens = key.size(2)\n",
    "    new_key = torch.zeros_like(key).repeat((num_tokens,1,1,1)) #torch.concat(key[i] for i in range(key.size(-2)))\n",
    "    new_value = torch.zeros_like(value).repeat((num_tokens,1,1,1))\n",
    "    for b_i in range(batch_sz):\n",
    "        for i in range(num_tokens):\n",
    "            new_key[b_i * num_tokens + i, :, -(i+1):, :] = key[b_i, :, :i+1, :] # makes a lower right trangular matrix out of the batch and sequence dimensions.\n",
    "            new_value[b_i * num_tokens + i, :, -(i+1):, :] = value[b_i, :, :i+1, :] \n",
    "            # print(new_key[:,0,:,0])\n",
    "            # print(key[:, 0, :, 0])\n",
    "            # print(key[b_i, :i+1, :, 0])\n",
    "            # print(new_key[b_i * num_tokens + i, -(i+1):, :, 0])\n",
    "    #     break\n",
    "    # break\n",
    "    reshaped_past_key_values += ((new_key, new_value),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       "        [10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "        [10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [10, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "        [10, 10, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "        [10, 10, 10, 10, 10, 10, 11, 12, 13, 14, 15, 16],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 11, 12, 13, 14, 15],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 13, 14],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 13],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.arange(12) + 10)[None, :].expand(12,-1).gather(1, (torch.arange(12)[None, :] - torch.arange(12)[:, None]).triu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11,\n",
       "         11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17,\n",
       "         17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "         19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20,\n",
       "         20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.triu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|begin_of_text|>how is it going? I am so happy to be back in the US. I am '\n",
      " 'so excited to be back in the']\n"
     ]
    }
   ],
   "source": [
    "base_samples = model.generate(**base_inputs, do_sample=False, max_new_tokens=20)\n",
    "pprint(tokenizer.batch_decode(base_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128001, 128001, 128001, 128001, 128000,   5269,   4521],\n",
       "        [128001, 128001, 128001, 128000,   5269,    374,   4521],\n",
       "        [128001, 128001, 128000,   5269,    374,    433,   4521],\n",
       "        [128001, 128000,   5269,    374,    433,   2133,   4521],\n",
       "        [128000,   5269,    374,    433,   2133,     30,   4521]]), 'attention_mask': tensor([[0, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer([sent + start_of_thought_token for sent in [\"how\", \"how is\", \"how is it\", \"how is it going\", \"how is it going?\"]], return_tensors='pt', padding=True, padding_side=\"left\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>how---to---make---a---screw---driver---with',\n",
      " '<|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>how '\n",
      " 'is---the---solar---panel---made---and---how',\n",
      " '<|end_of_text|><|end_of_text|><|begin_of_text|>how is it---the 2nd time i '\n",
      " 'have seen this movie. i',\n",
      " '<|end_of_text|><|begin_of_text|>how is it going---i am still here. i have '\n",
      " 'been busy with my new',\n",
      " \"<|begin_of_text|>how is it going?---i'm back from my trip to the west coast. \"\n",
      " 'i')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=12, do_sample=False, return_dict_in_generate=True)\n",
    "    print(tokenizer.batch_decode(outputs.sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8, 18, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = (outputs.sequences != tokenizer.pad_token_id).long()\n",
    "# shift the attention matrix by 1 to the left, so we include the begin of sentence token which happens to also equal the end of sentence token.\n",
    "# attention_mask = torch.concat([attention_mask[:, 1:], torch.ones_like(attention_mask[:, [0]])], dim=-1)\n",
    "attention_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8, 18, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['sequences', 'past_key_values'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_kv_test = model.generate(input_ids=outputs.sequences, attention_mask=attention_mask, max_new_tokens=12, do_sample=False, return_dict_in_generate=True, past_key_values=outputs.past_key_values)\n",
    "outputs_kv_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>how---to---make---a---screw---driver---with---a---screw---driver---and---a---',\n",
       " '<|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>how is---the---solar---panel---made---and---how---does---it---work---?\\nhow is---the',\n",
       " '<|end_of_text|><|end_of_text|><|begin_of_text|>how is it---the 2nd time i have seen this movie. i was not impressed the first time. i think it was a',\n",
       " '<|end_of_text|><|begin_of_text|>how is it going---i am still here. i have been busy with my new job and i am still trying to get my new place in',\n",
       " \"<|begin_of_text|>how is it going?---i'm back from my trip to the west coast. i had a great time, and i'm looking forward to getting\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs_kv_test.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>how---to---make---a---screw---driver---with---a---screw---driver---and---a---',\n",
       " '<|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>how is---the---solar---panel---made---and---how---does---it---work---?\\nhow is---the',\n",
       " '<|end_of_text|><|end_of_text|><|begin_of_text|>how is it---the 2nd time i have seen this movie. i was not impressed the first time. i think it was a',\n",
       " '<|end_of_text|><|begin_of_text|>how is it going---i am still here. i have been busy with my new job and i am still trying to get my new place in',\n",
       " \"<|begin_of_text|>how is it going?---i'm back from my trip to the west coast. i had a great time, and i'm looking forward to getting\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs_kv_test.sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(1, 2048)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128258, 2048)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "\"\"\"GPT2LMHeadModel(\n",
    "  (transformer): GPT2Model(\n",
    "    (wte): Embedding(50257, 768)\n",
    "    (wpe): Embedding(1024, 768)\n",
    "    (drop): Dropout(p=0.1, inplace=False)\n",
    "    (h): ModuleList(\n",
    "      (0-11): 12 x GPT2Block(\n",
    "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "        (attn): GPT2SdpaAttention(\n",
    "          (c_attn): Conv1D(nf=2304, nx=768)\n",
    "          (c_proj): Conv1D(nf=768, nx=768)\n",
    "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
    "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "        (mlp): GPT2MLP(\n",
    "          (c_fc): Conv1D(nf=3072, nx=768)\n",
    "          (c_proj): Conv1D(nf=768, nx=3072)\n",
    "          (act): NewGELUActivation()\n",
    "          (dropout): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "  )\n",
    "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
    ")\n",
    "\n",
    "\n",
    "lm_head seems to be common at least in here and in the other hting.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiet-STAR on the hidden representation\n",
    "with character level language model\n",
    "\n",
    "GRU updated:\n",
    "$$h_t = \\tilde{h_t} \\odot z_t + h_{t-1} \\odot (1-z_t)$$\n",
    "$$r_t = \\sigma(W^r[h_{t-1}; x_t])$$\n",
    "$$z_t = \\sigma(W^z[h_{t-1}; x_t])$$\n",
    "$$\\tilde{h_t} = \\tanh(W^{\\tilde{h}}[r_t \\odot h_{t-1}; x_t])$$\n",
    "\n",
    "Adding stochasticity to the $\\tilde{h_t}$ computation, to simulate quiet-star\n",
    "\n",
    "$$\\tilde{h_{base_{t}}} = \\tanh(W^{\\tilde{h_{base}}}[r_t \\odot h_{t-1}; x_t])$$\n",
    "$$\\epsilon \\sim \\mathcal{N}(0,1)$$\n",
    "$$\\tilde{h_t} = W^{\\mu_{\\tilde{h}}}[\\tilde{h_{base_{t}}}] + \\epsilon \\exp(W^{\\sigma_{\\tilde{h}}}[\\tilde{h_{base_{t}}}])$$\n",
    "\n",
    "essentially:\n",
    "$$\\tilde{h_t} \\sim \\mathcal{N}(\\mu_{\\tilde{h_t}},\\sigma_{\\tilde{h_t}})$$\n",
    "\n",
    "\n",
    "Adding stochasticity to the $h_t$ computation, to simulate quiet-star, where they don't have the gating. This kind of seems like an RNN? Yeah, and it removes the impact of gating, so it should have the exploading gradients problem.\n",
    "\n",
    "$$h_{base_{t}} = \\tilde{h_t} \\odot z_t + h_{t-1} \\odot (1-z_t)$$\n",
    "$$\\epsilon \\sim \\mathcal{N}(0,1)$$\n",
    "$$h_t = W^{\\mu_{h}}[h_{base_{t}}] + \\epsilon \\exp(W^{\\sigma_{h}}[h_{base_{t}}])$$\n",
    "\n",
    "essentially:\n",
    "$$h_t \\sim \\mathcal{N}(\\mu_{h_t},\\sigma_{h_t})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import cast\n",
    "from functools import partial\n",
    "import pickle\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import OrderedDict\n",
    "from typing import Any\n",
    "\n",
    "### Hyper parameters\n",
    "device = 'cuda'\n",
    "seq_len = 128\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to rebalance my data so that it isn't sequential. my true setting isn't concerned with unseen text being future text. assume the text is in training distribution just not trained on directly, and same for the set dedicated to reward model training.\n",
    "# train_str = open(\"./tiny_shakespeare_train.txt\", 'r').read()[-914334:]\n",
    "# train_reward_model_str = open(\"./tiny_shakespeare_train.txt\", 'r').read()[:-914334] # 10% of original train set to the reward modeling set to ensure generality, and not learning instantaniuous reward.\n",
    "# eval_str = open(\"./tiny_shakespeare_eval.txt\", 'r').read()\n",
    "\n",
    "data_str = open('./tiny_shakespeare.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(data_str)\n",
    "vocab = sorted(list(vocab))\n",
    "vocab.insert(0, '<sot>')\n",
    "index_to_char_list = vocab\n",
    "char_to_index_dict = dict((c, i) for i, c in enumerate(index_to_char_list))\n",
    "# chat_to_index_dict, index_to_char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(ids):\n",
    "    if isinstance(ids, torch.Tensor):\n",
    "        assert len(ids.shape) == 1, \"the size of a detokenized ids tensor can only be one dimensional\"\n",
    "        ids = ids.tolist()\n",
    "    return \"\".join([index_to_char_list[i] for i in ids])\n",
    "def batch_detokenize(batch_ids):\n",
    "    return [detokenize(ids) for ids in batch_ids]\n",
    "def tokenize(string: str):\n",
    "    return [char_to_index_dict[c] for c in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 129])\n",
      "('<sot>ere effusion of thy proper loins,\\n'\n",
      " 'Do curse the gout, serpigo, and the rheum,\\n'\n",
      " 'For ending thee no sooner. Thou hast nor youth nor ')\n"
     ]
    }
   ],
   "source": [
    "class ShakespeareDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_str, seq_len):\n",
    "        self.data = [data_str[i * seq_len: (i+1) * seq_len] for i in range(len(data_str) // seq_len)]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "full_dataset_shakespeare = ShakespeareDataset(data_str, seq_len)\n",
    "\n",
    "train_dataset_shakespeare, train_reward_model_dataset_shakespeare, eval_dataset_shakespeare = torch.utils.data.random_split(full_dataset_shakespeare, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "\n",
    "def shakespeare_collate_fn(examples):\n",
    "    input_ids = []\n",
    "    for example in examples:\n",
    "        input_ids.append([char_to_index_dict['<sot>']] + tokenize(example))\n",
    "    return torch.tensor(input_ids)\n",
    "\n",
    "\n",
    "example_input = None\n",
    "for example_input in torch.utils.data.DataLoader(train_dataset_shakespeare, batch_size=batch_size, collate_fn=shakespeare_collate_fn):\n",
    "    # example_input = example_input.to(device)\n",
    "    print(example_input.shape)\n",
    "    pprint(detokenize(example_input[0]))\n",
    "    break\n",
    "example_input = cast(torch.Tensor, example_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomizedGRUCell(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, sample_h_tilda:bool, sample_identity:bool, reparameterize:bool):\n",
    "        '''has assumed batch by sequence input dimension, and assume randomness is in the hidden representation to be sent to the output and the next layer'''\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.linear_z = torch.nn.Linear(in_features=hidden_dim + input_size, out_features=hidden_dim)\n",
    "        self.linear_r = torch.nn.Linear(in_features=hidden_dim + input_size, out_features=hidden_dim)\n",
    "        self.linear_h_tilda_x = torch.nn.Linear(in_features=input_size, out_features=hidden_dim)\n",
    "        self.linear_h_tilda_h_m1 = torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "        self.sample_h_tilda = sample_h_tilda\n",
    "        self.sample_identity = sample_identity\n",
    "        self.reparameterize = reparameterize\n",
    "\n",
    "        self.distribution_params = torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim*2)\n",
    "\n",
    "    # @torch.compile(options={\"triton.cudagraphs\": True}, fullgraph=True)\n",
    "    def forward(self, x_t, h_t_m1, h_tilda_start=None):\n",
    "        ''' expect [batch, 1, input_dim] for x hx and h_tilda (if provided)'''\n",
    "        dict_return = dict()\n",
    "        x_concat_h = torch.concat([x_t, h_t_m1], dim=-1)\n",
    "        z_t = self.linear_z(x_concat_h).sigmoid()\n",
    "        r_t = self.linear_r(x_concat_h).sigmoid()\n",
    "        if h_tilda_start is not None and self.sample_h_tilda:\n",
    "            h_tilda_t = h_tilda_start\n",
    "        else:\n",
    "            h_tilda_t = torch.tanh(self.linear_h_tilda_x(x_t) + r_t * self.linear_h_tilda_h_m1(h_t_m1))\n",
    "\n",
    "        if self.sample_h_tilda:\n",
    "            if h_tilda_start is not None:\n",
    "                h_tilda_t = h_tilda_start.tanh() # This has tanh on it because I only record the h_tilda before the final tanh is applied, so this will need a tanh to make it the right one.\n",
    "                dict_return['h_tilda_t'] = h_tilda_t # TODO: account for the fact that I won't be returning a distibution or log prob if a starting h_tilda is given.\n",
    "            else:\n",
    "                h_tilda_t_base = h_tilda_t # we take in a tanh'd computation, so that the gradient with respect to the h_t_m1 doesn't expload on extreme values. with tanh activation the partial derivative is 1 - tanh^2(x). without it we see gradient explosion.\n",
    "                h_tilda_dist, h_tilda_t, log_prob_h_tilda_t = self.create_dist_sample_get_log_prob(h_tilda_t_base)\n",
    "                dict_return['log_prob_h_tilda_t'] = log_prob_h_tilda_t\n",
    "                dict_return['h_tilda_t'] = h_tilda_t # this is recorded without the tanh applied, TODO: rename everything to indicate that this is before tanh is applied, and move tanh\n",
    "                dict_return['h_tilda_dist'] = h_tilda_dist\n",
    "                h_tilda_t = (h_tilda_t).tanh() # this to keep the output in the same distirbution as without this sampling procedure.\n",
    "            h_t = z_t * h_t_m1 + (1 - z_t) * h_tilda_t\n",
    "        else:\n",
    "            h_t_base = z_t * h_t_m1 + (1 - z_t) * h_tilda_t\n",
    "            h_t_dist, h_t, log_prob_h_t = self.create_dist_sample_get_log_prob(h_t_base)\n",
    "            dict_return['log_prob_h_t'] = log_prob_h_t\n",
    "            dict_return['h_t_dist'] = h_t_dist\n",
    "\n",
    "        dict_return[\"h_t\"] = h_t\n",
    "        return dict_return\n",
    "    def create_dist_sample_get_log_prob(self, representation):\n",
    "        if self.sample_identity: # this for testing if base GRU implementation is ok.\n",
    "            return None, representation, torch.zeros_like(representation)\n",
    "        mean, log_var = self.distribution_params(representation).chunk(2, dim=-1)\n",
    "\n",
    "        data_type_info = torch.finfo(torch.float32)\n",
    "        max_log_var_val = 30\n",
    "        max_mean_val = 1000\n",
    "        mean = torch.clamp(mean, min=-max_mean_val, max=max_mean_val)\n",
    "        log_var = torch.clamp(log_var, min=-max_log_var_val, max=max_log_var_val) # do clamping first because the clamp post exp with inf doesn't work the grad turns to nan instead of 0.0\n",
    "        dist = torch.distributions.Normal(loc=mean, scale=(0.5 * log_var).exp()) # numerical stability.\n",
    "        if self.reparameterize:\n",
    "            sample = dist.rsample()\n",
    "        else:\n",
    "            sample = dist.sample()\n",
    "        log_prob_sample = dist.log_prob(sample)\n",
    "        return dist, sample, log_prob_sample\n",
    "        \n",
    "def combine_normals(normal_distributions_list, dim):\n",
    "    locs = torch.concat([n.loc for n in normal_distributions_list], dim=dim)\n",
    "    scales = torch.concat([n.scale for n in normal_distributions_list], dim=dim)\n",
    "    return torch.distributions.Normal(loc=locs, scale=scales)\n",
    "class RandomizedGRU(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers, sample_h_tilda:bool, sample_identity:bool, reparameterize:bool):\n",
    "        super().__init__()\n",
    "        # TODO: support multiple layers\n",
    "        # NOTE: this implementation doesn't work with any kind of padding...\n",
    "        self.sample_h_tilda = sample_h_tilda\n",
    "        self.cell = RandomizedGRUCell(input_size, hidden_dim, sample_h_tilda, sample_identity, reparameterize)\n",
    "        self.hidden_dim = hidden_dim\n",
    "    def forward(self, x, hx=None, h_tilda_start=None, return_dict=False):\n",
    "        if hx is None:\n",
    "            hx = torch.zeros_like(x[:, [0]][...,[0]]).repeat(1, 1, self.hidden_dim)\n",
    "        h_t_m1 = hx\n",
    "        h_ts = []\n",
    "        h_tilda_ts = []\n",
    "        log_prob_h_ts = []\n",
    "        log_prob_h_tilda_ts = []\n",
    "        h_t_dists = []\n",
    "        h_tilda_dists = []\n",
    "        for t in range(x.size(1)):\n",
    "            x_t = x[:, [t], :]\n",
    "            dict_return_t = self.cell(x_t, h_t_m1=h_t_m1, h_tilda_start=h_tilda_start if t == 0 and h_tilda_start is not None and self.sample_h_tilda else None)\n",
    "\n",
    "            if self.sample_h_tilda:\n",
    "                h_tilda_ts.append(dict_return_t['h_tilda_t'])\n",
    "                log_prob_h_tilda_ts.append(dict_return_t['log_prob_h_tilda_t'])\n",
    "                h_tilda_dists.append(dict_return_t['h_tilda_dist'])\n",
    "            else:\n",
    "                log_prob_h_ts.append(dict_return_t['log_prob_h_t'])\n",
    "                h_t_dists.append(dict_return_t['h_t_dist'])\n",
    "            h_ts.append(dict_return_t['h_t'])\n",
    "            h_t_m1 = dict_return_t['h_t'] # .clone() this may be necessary if I want to figure out the compile thing??\n",
    "        h_ts = torch.concat(h_ts, dim=1)\n",
    "        if return_dict:\n",
    "            dict_return: dict = {\"h_ts\": h_ts, \"h_n\": h_ts[:, [-1], :]}\n",
    "            if self.sample_h_tilda:\n",
    "                dict_return[\"h_tilda_ts\"] = torch.concat(h_tilda_ts, dim=1)\n",
    "                dict_return[\"log_prob_h_tilda_ts\"] = torch.concat(log_prob_h_tilda_ts, dim=1)\n",
    "                dict_return['h_tilda_dists'] = combine_normals(h_tilda_dists, dim=1)\n",
    "            else:\n",
    "                dict_return[\"log_prob_h_ts\"] = torch.concat(log_prob_h_ts, dim=1)\n",
    "                dict_return['h_t_dists'] = combine_normals(h_t_dists, dim=1)\n",
    "\n",
    "            return dict_return\n",
    "        else:\n",
    "            return h_ts, h_ts[:, [-1], :]\n",
    "        \n",
    "# r_gru = RandomizedGRU(3, 4, 1, True)\n",
    "# r_gru(torch.zeros((1,5,3)), return_dict=True)\n",
    "# train_model(get_nll, lambda model: eval_loss_fn(model, get_nll), RandomizedGRU(len(vocab), 100, 1, True), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn with torch\n",
    "\n",
    "class SampleMixin:\n",
    "    token_embedding: torch.nn.Module\n",
    "    model: torch.nn.Module\n",
    "    lm_head: torch.nn.Module\n",
    "\n",
    "    def sample(self, input_ids, hx=None, max_gen_length=10):\n",
    "        '''greedy sample from the model'''\n",
    "        x_t = self.token_embedding(input_ids)\n",
    "        x_t, hidden_t = self.model(x_t, hx=hx)\n",
    "        x_t = self.lm_head(x_t)\n",
    "        input_id_t = x_t[:, [-1], :].argmax(-1)\n",
    "        # print(input_id_t)\n",
    "        x_t = self.token_embedding(input_id_t)\n",
    "        generated_ids = [input_id_t]\n",
    "        for _ in range(max_gen_length):\n",
    "            x_t, hidden_t = self.model(x_t, hidden_t)\n",
    "            x_t = self.lm_head(x_t)\n",
    "            input_id_t = x_t[:, [-1], :].argmax(-1)\n",
    "            x_t = self.token_embedding(input_id_t)\n",
    "            generated_ids.append(input_id_t)\n",
    "        generated_ids = torch.concat(generated_ids, dim=-1)\n",
    "        return generated_ids\n",
    "def get_model_type(model_type, hidden_dim, num_layers):\n",
    "    if model_type == \"lstm\":\n",
    "        model = torch.nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "    elif model_type == \"gru\":\n",
    "        model = torch.nn.GRU(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "    elif model_type == 'rgruhtilda':\n",
    "        model = RandomizedGRU(input_size=hidden_dim, hidden_dim=hidden_dim, num_layers=1, sample_h_tilda=True, sample_identity=False, reparameterize=False)\n",
    "    elif model_type == 'rgruhtildar':\n",
    "        model = RandomizedGRU(input_size=hidden_dim, hidden_dim=hidden_dim, num_layers=1, sample_h_tilda=True, sample_identity=False, reparameterize=True)\n",
    "    elif model_type == 'rgruh':\n",
    "        model = RandomizedGRU(input_size=hidden_dim, hidden_dim=hidden_dim, num_layers=1, sample_h_tilda=False, sample_identity=False, reparameterize=False)\n",
    "    elif model_type == 'rgruhr':\n",
    "        model = RandomizedGRU(input_size=hidden_dim, hidden_dim=hidden_dim, num_layers=1, sample_h_tilda=False, sample_identity=False, reparameterize=True)\n",
    "    elif model_type == 'rgrui':\n",
    "        model = RandomizedGRU(input_size=hidden_dim, hidden_dim=hidden_dim, num_layers=1, sample_h_tilda=True, sample_identity=True, reparameterize=False)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{model_type=}. Is not impelmented\")\n",
    "    return model\n",
    "class LanguageModelLSTM(torch.nn.Module, SampleMixin):\n",
    "    def __init__(self, vocab_size, hidden_dim, num_layers, detach_hidden_state=False, model_type='lstm'):\n",
    "        super().__init__()\n",
    "        self.token_embedding = torch.nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.model = get_model_type(model_type, hidden_dim, num_layers)\n",
    "        self.lm_head = torch.nn.Linear(in_features=hidden_dim, out_features=vocab_size)\n",
    "        self.detach_hidden_state = detach_hidden_state\n",
    "        self.detach_hidden_state_linear_layer = torch.nn.Sequential(\n",
    "            # torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "        )\n",
    "    def forward(self, x, hx=None, return_dict=False):\n",
    "        x = self.token_embedding(x)\n",
    "        hidden_states, _ = self.model(x, hx=hx)\n",
    "        if self.detach_hidden_state:\n",
    "            x = self.detach_hidden_state_linear_layer(hidden_states).detach() # testing the model performance in same case as quiet-star to get worst case baseline\n",
    "        x = self.lm_head(hidden_states)\n",
    "        if return_dict:\n",
    "            return OrderedDict(logits=x, hidden_states=hidden_states)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nll_from_logits_and_labels(logits, labels):\n",
    "    shifted_logits = logits[:, :-1].contiguous()\n",
    "    shifted_labels = labels[:, 1:].contiguous()\n",
    "    return torch.nn.CrossEntropyLoss(reduction='mean')(shifted_logits.view(-1, len(vocab)), shifted_labels.view(-1))\n",
    "def get_nll(model, inputs):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = inputs.clone()\n",
    "    logits = model(inputs)\n",
    "    return get_nll_from_logits_and_labels(logits, labels)\n",
    "def eval_loss_fn(model, get_loss, dataloader=None):\n",
    "    if dataloader is None:\n",
    "        dataloader = torch.utils.data.DataLoader(eval_dataset_shakespeare, batch_size=batch_size, collate_fn=shakespeare_collate_fn)\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for d in dataloader:\n",
    "            loss = get_loss(model, d)\n",
    "            losses.append(loss)\n",
    "    return float(sum(losses)) / len(losses)\n",
    "def get_grad_norm(model):\n",
    "    params = [p.grad.flatten() for p in model.parameters() if p.grad is not None]\n",
    "    return torch.concat(params).norm()\n",
    "def get_model_param_norm(model):\n",
    "    params = [p.flatten() for p in model.parameters()]\n",
    "    return torch.concat(params).norm()\n",
    "def train_model(get_loss_fn, eval_fn, model, batch_size=batch_size, epochs=10, train_dl=None, eval_every=100, print_stuff=True, lr=0.001):\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    i = 0\n",
    "    d = None\n",
    "    if train_dl is None:\n",
    "        train_dl = torch.utils.data.DataLoader(train_dataset_shakespeare, batch_size=batch_size, collate_fn=shakespeare_collate_fn, shuffle=True)\n",
    "    if print_stuff:\n",
    "        print('Number training steps total:', len(train_dl) * epochs)\n",
    "    for epoch_i in range(epochs):\n",
    "        for d in train_dl:\n",
    "            if i % eval_every == 0 and print_stuff:\n",
    "                eval_loss = eval_fn(model)\n",
    "                print('eval loss', eval_loss)\n",
    "                eval_losses.append((i, eval_loss))\n",
    "            optim.zero_grad()\n",
    "            loss = get_loss_fn(model, d)\n",
    "            loss.backward()\n",
    "            if print_stuff:\n",
    "                print(f\"loss {i:>5}: {loss.item():<8.4f} grad norm: {get_grad_norm(model):<15.4f} model param norm: {get_model_param_norm(model):<15.4f}\")\n",
    "            train_losses.append((i, loss.item()))\n",
    "            # if torch.stack([p.isnan().any() for p in model.parameters()]).any():\n",
    "            #     import ipdb; ipdb.set_trace()\n",
    "            optim.step()\n",
    "            # if torch.stack([p.isnan().any() for p in model.parameters()]).any():\n",
    "            #     import ipdb; ipdb.set_trace()\n",
    "            i += 1\n",
    "\n",
    "    if print_stuff:\n",
    "        eval_loss = eval_fn(model)\n",
    "        print('eval loss', eval_loss)\n",
    "        eval_losses.append((i, eval_loss))\n",
    "        plt.plot(*zip(*train_losses), label='train')\n",
    "        plt.plot(*zip(*eval_losses), label='eval')\n",
    "        plt.show()\n",
    "\n",
    "        if isinstance(d, torch.Tensor) and hasattr(model, \"sample\"): # doesn't work for reward model, but nice to have for the language models\n",
    "            d = d.to(device)\n",
    "            pprint(batch_detokenize(d[:, :100]))\n",
    "            pprint(batch_detokenize(model.sample(d[:, :100], max_gen_length=20)))\n",
    "\n",
    "            print(batch_detokenize(model(d).argmax(dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rnn_lm \u001b[38;5;241m=\u001b[39m \u001b[43mLanguageModelLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgruh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# eval loss: 1.505 30 seconds gru\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# eval loss: 1.519 took 450 seconds tho rgrui same ish performance (my init might be off, but close enough for me.)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# eval loss: 2.5 rgruh for 1000 steps? , another run hit to 2.02 in 200 steps and went to 1.56\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# eval loss: 1.48 for r gru h_tilda reparameterized. took 680 seconds maybe longer because the back prop graph was longer.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# eval loss: 1.52 for r gru h_tilda pre tanh reparameterized. took 840 seconds.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m train_model(get_nll, \u001b[38;5;28;01mlambda\u001b[39;00m model: eval_loss_fn(model, get_nll), rnn_lm, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/cuda/__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "rnn_lm = LanguageModelLSTM(vocab_size=len(vocab), hidden_dim=100, num_layers=1, model_type='rgruh').to(device) \n",
    "# eval loss: 1.505 30 seconds gru\n",
    "# eval loss: 1.519 took 450 seconds tho rgrui same ish performance (my init might be off, but close enough for me.)\n",
    "# eval loss: 2.5 rgruh for 1000 steps? , another run hit to 2.02 in 200 steps and went to 1.56\n",
    "# eval loss: 1.48 for r gru h_tilda reparameterized. took 680 seconds maybe longer because the back prop graph was longer.\n",
    "# eval loss: 1.52 for r gru h_tilda pre tanh reparameterized. took 840 seconds.\n",
    "train_model(get_nll, lambda model: eval_loss_fn(model, get_nll), rnn_lm, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, h = rnn_lm(x = torch.arange(10, device=device).reshape(2,5), return_dict=True).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[44,  2, 58, 54,  2, 59, 47, 44,  2, 58, 59],\n",
       "        [32, 44, 42, 54, 53, 43,  2, 32, 44, 57, 61],\n",
       "        [48, 58, 58, 44, 40, 57,  2, 59, 47, 44,  2],\n",
       "        [ 2, 16, 51, 40, 43, 43,  2, 40, 53, 43,  2],\n",
       "        [51, 51,  2, 59, 47, 44,  2, 58, 59, 57, 54],\n",
       "        [59,  2, 48, 58,  2, 59, 47, 44,  2, 58, 44],\n",
       "        [51, 51, 43,  7,  1, 14, 53, 43,  2, 59, 47],\n",
       "        [ 2, 40, 53, 43,  2, 59, 47, 44,  2, 58, 44],\n",
       "        [ 1,  1, 25, 14, 17, 38,  2, 16, 14, 29, 34],\n",
       "        [ 1,  1, 25, 34, 16, 22, 28, 11,  1, 36, 47]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_lm.sample(input_ids=torch.arange(10, device=device).reshape(-1,1), hx=h.reshape(1,10,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 100]), torch.Size([2, 5, 66]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape, l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train based on the lstm model a quiet-star version... simulates having a good reward function for the quiet-star setting. \n",
    "# need to create some distirbution over the hidden representations that I can train analogous to the rational.\n",
    "\n",
    "class QuietStarLSTMModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, reparameterization_trick, model_type):\n",
    "        super().__init__()\n",
    "        if model_type == 'lstm':\n",
    "            self.model = torch.nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        elif model_type == 'gru':\n",
    "            self.model = torch.nn.GRU(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"no implementation for the model type: {model_type}\")\n",
    "        self.distribution_params = torch.nn.Linear(in_features=hidden_dim, out_features=2*hidden_dim)\n",
    "        self.reparameterization_trick = reparameterization_trick\n",
    "    def forward(self, x, h_c=None):\n",
    "        dist, (h_n, c_n) = self.get_hidden_dist(x, h_c)\n",
    "        if self.reparameterization_trick:\n",
    "            sample = dist.rsample()\n",
    "        else:\n",
    "            sample = dist.sample()\n",
    "        return sample, (h_n, c_n) # doing sample instead of rsample means there is no gradient flowing through this computation.\n",
    "    # sampling is technically a differentiable decision unless you sample all of the space and compute probability over those elements ??\n",
    "    def get_hidden_dist(self, x, h_c=None):\n",
    "        x, (h_n, c_n)= self.model(x, h_c)\n",
    "        x = self.distribution_params(x)\n",
    "        mu, log_var = x.chunk(2, dim=-1)\n",
    "        dist = torch.distributions.Normal(loc=mu, scale=(0.5*log_var).exp())\n",
    "        return dist, (h_n, c_n)\n",
    "    \n",
    "class QuietStarLanguageModel(ABC):\n",
    "    token_embedding: torch.nn.Embedding\n",
    "    model: Any\n",
    "    lm_head: torch.nn.Linear\n",
    "    def forward(self, x):\n",
    "        x = self.token_embedding(x)\n",
    "        x, hidden = self.model(x)\n",
    "        x = self.lm_head(x)\n",
    "        return x\n",
    "    @abstractmethod\n",
    "    def get_logits_and_hidden_states_and_log_prob_hidden_states_dist(self, x) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.distributions.Normal]:\n",
    "        ...\n",
    "\n",
    "\n",
    "class QuietStarLanguageModelLSTM(torch.nn.Module, SampleMixin, QuietStarLanguageModel):\n",
    "    def __init__(self, vocab_size, hidden_dim, num_layers, reparameterization_trick=False, model_type='lstm'):\n",
    "        super().__init__()\n",
    "        self.token_embedding = torch.nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.model = QuietStarLSTMModel(hidden_dim, num_layers, reparameterization_trick, model_type)\n",
    "        self.lm_head = torch.nn.Linear(in_features=hidden_dim, out_features=vocab_size)\n",
    "    def get_logits_and_hidden_states_and_log_prob_hidden_states_dist(self, x):\n",
    "        x = self.token_embedding(x)\n",
    "        dist, _ = cast(QuietStarLSTMModel, self.model).get_hidden_dist(x)\n",
    "        sampled_hidden_states = dist.sample()\n",
    "        x = self.lm_head(sampled_hidden_states)\n",
    "        log_p_hidden_states = dist.log_prob(sampled_hidden_states)\n",
    "        return x, sampled_hidden_states, log_p_hidden_states, dist\n",
    "    # support reward model setting, which seeks to get an estimate for the expected log probability of data under the model given the context, and the chosen hidden representation.\n",
    "    # so need a way to get out hidden_states form the model along with the performance of the model given those hidden states. We can just return the logits, and have the calling \n",
    "    # function compute the performance, because performance can be measured differently, so pass the responsibility to caller.\n",
    "\n",
    "class QuietStarLanguageModelrGRU(SampleMixin, torch.nn.Module, QuietStarLanguageModel):\n",
    "    def __init__(self, vocab_size, hidden_dim, num_layers, model_type='rgruh'):\n",
    "        super().__init__()\n",
    "        assert model_type not in [\"rgrui\"], \"no identity, becuase they don't impart a distirbution over the action space, so this model wouldn't be trainable by quiet-star.\"\n",
    "        self.model_type = model_type\n",
    "        self.token_embedding = torch.nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.model = cast(RandomizedGRU, get_model_type(model_type, hidden_dim, num_layers))\n",
    "        self.lm_head = torch.nn.Linear(in_features=hidden_dim, out_features=vocab_size)\n",
    "    def forward(self, x):\n",
    "        x = self.token_embedding(x)\n",
    "        x, hidden = self.model(x)\n",
    "        x = self.lm_head(x)\n",
    "        return x\n",
    "    def get_logits_and_hidden_states_and_log_prob_hidden_states_dist(self, x, x_embed=None, hx=None):\n",
    "        if x_embed is not None:\n",
    "            x = x_embed\n",
    "        else:\n",
    "            x = self.token_embedding(x)\n",
    "        dict_returned = self.model(x, hx=hx, return_dict=True)\n",
    "        output_states = dict_returned['h_ts']\n",
    "        x = self.lm_head(output_states)\n",
    "        # dict_return: dict = {\"h_ts\": h_ts, \"h_n\": h_ts[:, [-1], :]}\n",
    "        # if self.sample_h_tilda:\n",
    "        #     dict_return[\"h_tilda_ts\"] = torch.concat(h_tilda_ts, dim=1)\n",
    "        #     dict_return[\"log_prob_h_tilda_ts\"] = torch.concat(log_prob_h_tilda_ts, dim=1)\n",
    "        #     dict_return['h_tilda_dists'] = combine_normals(h_tilda_dists, dim=1)\n",
    "        # else:\n",
    "        #     dict_return[\"log_prob_h_ts\"] = torch.concat(log_prob_h_ts, dim=1)\n",
    "        #     dict_return['h_t_dists'] = combine_normals(h_t_dists, dim=1)\n",
    "        if cast(RandomizedGRU, self.model).sample_h_tilda:\n",
    "            dist = dict_returned['h_tilda_dists']\n",
    "            sampled_states = dict_returned[\"h_tilda_ts\"]\n",
    "            sampled_states_log_prob = dict_returned[\"log_prob_h_tilda_ts\"]# .sum(-1)\n",
    "        else:\n",
    "            # assume the model is the hidden state variety of sampling.\n",
    "            dist = dict_returned['h_t_dists']\n",
    "            sampled_states = dict_returned[\"h_ts\"]\n",
    "            sampled_states_log_prob = dict_returned[\"log_prob_h_ts\"]# .sum(-1)\n",
    "        return x, sampled_states, sampled_states_log_prob, dist\n",
    "\n",
    "\n",
    "\n",
    "m = QuietStarLSTMModel(10, 1, False, 'lstm')\n",
    "m.forward(torch.arange(20.).reshape(2, 10))[0]\n",
    "quiet_star_model = QuietStarLanguageModelLSTM(len(vocab), 100, 1).to(device)\n",
    "quiet_star_model.sample(torch.arange(60, device=device).reshape(6, 10) % len(vocab))\n",
    "quiet_star_model = QuietStarLanguageModelrGRU(len(vocab), 100, 1).to(device)\n",
    "opt = torch.optim.AdamW(quiet_star_model.parameters())\n",
    "for _ in range(00):\n",
    "    opt.zero_grad()\n",
    "    input_ids = torch.arange(250, device=device).reshape(1,250) % len(vocab)\n",
    "    with torch.no_grad():\n",
    "        input_embeds = quiet_star_model.token_embedding(input_ids)\n",
    "    input_embeds.requires_grad = True\n",
    "    logits, hidden_states, log_prob_hidden_states, dist = quiet_star_model.get_logits_and_hidden_states_and_log_prob_hidden_states_dist(x=None, x_embed=input_embeds)\n",
    "    # pseudo_loss = -log_prob_hidden_states[0,-1].sum() \n",
    "    pseudo_loss = log_prob_hidden_states.sum()\n",
    "    pseudo_loss.backward()\n",
    "    print()\n",
    "    print(f\"{pseudo_loss=}\")\n",
    "    print({n: p.grad.norm().item() for n, p in quiet_star_model.named_parameters() if p.grad is not None})\n",
    "    print(\"dist std min max:\", dist.scale.min().item(), dist.scale.mean().item(), dist.scale.max().item())\n",
    "    print(\"hidden_states min max:\", hidden_states.min().item(), hidden_states.max().item())\n",
    "    print(\"hidden_state minus mean squared max:\", (hidden_states - dist.loc).square().max().item())\n",
    "    print(\"hidden_state minus mean divided by std max:\", ((hidden_states - dist.loc)/ dist.scale).max().item())\n",
    "    print(\"log_prob min max:\", log_prob_hidden_states.min().item(), log_prob_hidden_states.max().item())\n",
    "    opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the optimization function, flexible enough so I can try a variety of forms? \n",
    "# or just keep it simple and then create the augmentations with if statements, and duplicate code?\n",
    "# for now just test the form that I want to test the most, which is the KL with reward fuction form.\n",
    "# could also test quiet-STAR equivelent form which I think should work basic reinforce set up. \n",
    "# Would still need variance reduction technique like TRICE.\n",
    "def get_quiet_star_loss(model: QuietStarLanguageModel, inputs: torch.Tensor, policy_loss_beta:float=1e6, nll_loss_beta:float=1, trice_samples:int=2, n_tokens_ahead=1, only_positive=False):\n",
    "    # this loss consists of nll for the base model? \n",
    "    # well given that we don't parameterize a basemodel,\n",
    "    # we will ignore that part of the loss for now.\n",
    "    # getting nll for thoughts is still important tho, for training the lm head.\n",
    "    n_tokens_ahead = min(inputs.size(1)-1, n_tokens_ahead)\n",
    "    inputs = inputs.to(device)\n",
    "    labels = inputs.clone()\n",
    "    original_batch_size = inputs.size(0)\n",
    "    repeated_inputs = inputs.repeat_interleave(trice_samples, dim=0) # every example shows up twice, this for trice!\n",
    "    repeated_labels = labels.repeat_interleave(trice_samples, dim=0) # every example shows up twice, this for trice!\n",
    "    repeated_logits, repeated_hidden_states, repeated_log_p_hidden_states, dist = model.get_logits_and_hidden_states_and_log_prob_hidden_states_dist(repeated_inputs)\n",
    "    # if repeated_log_p_hidden_states.isnan().any():\n",
    "    #     import ipdb; ipdb.set_trace()\n",
    "    #     repeated_logits, _, repeated_log_p_hidden_states, dist = model.get_logits_and_hidden_states_and_log_prob_hidden_states_dist(repeated_inputs)\n",
    "    repeated_shifted_logits = repeated_logits[:, :-1].contiguous()\n",
    "    repeated_shifted_labels = repeated_labels[:, 1:].contiguous()\n",
    "    repeated_reward = - torch.nn.CrossEntropyLoss(reduction='none')(repeated_shifted_logits.view(-1, len(vocab)), repeated_shifted_labels.view(-1))\n",
    "    repeated_reward = repeated_reward.reshape(*repeated_shifted_labels.shape) # change repeated reward so that I can take the average over my samples\n",
    "    repeated_reward_n_ahead = torch.clone(repeated_reward)\n",
    "    for i in range(n_tokens_ahead-1):\n",
    "        repeated_reward_n_ahead[:, :-(i+1)] += repeated_reward[:, (i+1):]\n",
    "    # no baseline to regress from, but can still average to create a baseline\n",
    "    trice_baseline_reward_n_ahead = repeated_reward_n_ahead.reshape(original_batch_size, trice_samples, -1)\n",
    "    repeated_reward_n_ahead_minus_baseline = (repeated_reward_n_ahead.view(original_batch_size, trice_samples, -1) - trice_baseline_reward_n_ahead.mean(1, keepdim=True)).view(*repeated_reward_n_ahead.shape)\n",
    "    if only_positive:\n",
    "        repeated_reward_n_ahead_minus_baseline = repeated_reward_n_ahead_minus_baseline.clamp(min=0)\n",
    "    quiet_star_policy_loss = - (repeated_reward_n_ahead_minus_baseline.detach() * repeated_log_p_hidden_states[:, :-1].sum(-1)).mean()\n",
    "    nll_loss = (-repeated_reward).mean()\n",
    "    loss = policy_loss_beta * quiet_star_policy_loss + nll_loss_beta * nll_loss # mean allowed because no pad tokens.\n",
    "    quiet_star_policy_loss = quiet_star_policy_loss.item()\n",
    "    print()\n",
    "    print(f\"{quiet_star_policy_loss= }\")\n",
    "    nll_loss = nll_loss.item()\n",
    "    print(f\"{nll_loss= }\")\n",
    "    avg_std = dist.scale.mean().item()\n",
    "    print(f\"{avg_std= }\")\n",
    "    # print({n: p.grad.norm().item() for n, p in model.named_parameters() if p.grad is not None})\n",
    "    print(\"dist std min max:\", dist.scale.min().item(), dist.scale.mean().item(), dist.scale.max().item())\n",
    "    print(\"hidden_states min max:\", repeated_hidden_states.min().item(), repeated_hidden_states.max().item())\n",
    "    print(\"hidden_state minus mean squared max:\", (repeated_hidden_states - dist.loc).square().max().item())\n",
    "    print(\"hidden_state minus mean divided by std max:\", ((repeated_hidden_states - dist.loc)/ dist.scale).max().item())\n",
    "    print(\"log_prob min max:\", repeated_log_p_hidden_states.min().item(), repeated_log_p_hidden_states.max().item())\n",
    "    # if loss.isnan().any() or loss > 10:\n",
    "    #     import ipdb; ipdb.set_trace()\n",
    "    return loss\n",
    "\n",
    "# example_input = cast(torch.Tensor, example_input)\n",
    "# get_quiet_star_loss(quiet_star_model, example_input, example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_quiet_star_loss_partial = partial(get_quiet_star_loss, policy_loss_beta=1, trice_samples=10, \n",
    "                                      n_tokens_ahead=100000) # TODO: Change learning rate?? smaller because more influence of loss from early hidden representations is increased, potentially unstable?\n",
    "# import ipdb\n",
    "\n",
    "# with ipdb.launch_ipdb_on_exception():\n",
    "train_model(get_quiet_star_loss_partial, lambda model: eval_loss_fn(model, get_nll), QuietStarLanguageModelrGRU(len(vocab), 100, 1, 'rgruh').to(device), epochs=100) # epochs=1, batch_size=8000)\n",
    "\n",
    "# eval loss 1.7922298908233643 for gru h_tilda 0.0871 std avg, got 1.75 with 0.12 std avg \n",
    "#           with 10 samples gets to 1.66 loss, and 0.04 avg std. takes 23 minutes\n",
    "# 1.756 eval when doing tanh afterwards as well, std 0.24. 23 minutes grad norm between 1.25 and 2, with 3 ish at the peaks\n",
    "\n",
    "# for r gru h, seems semi stable with 10 samples. kind of similar to reparam. have restricted variance, so no reaching zero, but can still be unstable.\n",
    "#           Want to train fully with GPU, using mps it takes near an hour. Useful? - this setting is cleaner for reward modeling based on context and hidden state.\n",
    "# 1.7736 eval at 2400 10 samples full ahead\n",
    "# 1.61 eval at 2800 100 samples full ahead. (0.0538966991007328 avg std, and around 1.0 to 1.5 gradient norm seems normal here.)\n",
    "# can use flip(dims=(1,)).cumsum(1).flip(dims=(1,))\n",
    "\n",
    "# is it possible to just use the version of the codebase that I developed to be model agnostic to work with this setting of creating a rationalization with a random linear layer?\n",
    "#           maybe, would require some abstraction over the generation procedure instead of just taking it as tokens, but this would be relatively ok to do. Then would test the exact quiet-star setting.\n",
    "#           Would this introduce complexity? - Each prefix would generate independantly and next token prediction would have to be done like quiet-star. I am just interested in NLL reduction based on some rationalization, and don't care too much if it is at the beginning or if it is throughout the generation process.\n",
    "#           Kind of like the idea of producing a rationalization specific to each prefix, but generating per token, and studying this optimization setting still is nice for learning about the single prefix optimization setting, just potentially the results might not transfer, like it might not work here, and still work there.\n",
    "#           Is it worth continuing with this idea? what do I gain? seeing if the reward model distillation idea has any viability. \n",
    "#           I think it does. Just have to get the model signal for its wide impact. Also might be necessary to improve the probability \n",
    "#           density model over randomly sampled state. Could choose to randomly sample from some vector set or something. \n",
    "#           This is just if the DPO doesn't seem to be working nicely tho... Fingers crossed that the optimization landscape has one clear \n",
    "#           optima that we are able to randomly sample towards. But we know this isn't true, and that there is a ton of symetry, \n",
    "#           but perhaps our starting distirbution can only sample one of the optima, and we just find that one?\n",
    "# Right now, I am testing the r gru h_tilda with full token ahead visibility on the loss, which should achieve 1.5 loss because it is theoretically the same gradient as the reparameterization gradient, which achieves this loss.\n",
    "#           Not sure if I need to implement the fact that the loss should be in expectation ie take more samples of the next token likelihoods given this starting hidden state\n",
    "#           I don't think more than 10 samples is helpful because in my other test cases, which had correct samples for hidden states, 10 seemed to work. (I tried with 100, but this didn't seem too successful. Essentially many samples from random parts of the parameter space, with low confidence rather than high confidence on few samples is what we are checking the performance of.)"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results from replications of quiet-star algorithm\n",
    "normal llm algorithm able to get 1.65 eval nll with 100 epochs, 100 hidden dim.\n",
    "\n",
    "policy loss beta = 1, with 100 epochs, and 100 hidden dim. 1000 hidden dim somehow performs worse. eval nll ~1.81 for two tokens -> 1.86\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "policy loss beta = 1000000, with 100 epochs, and 100 hidden. eval nll ~1.805 for two tokens -> 1.85\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "modifying the n_tokens_ahead from 1 to 2 to 16 had no effect. in fact at 16 it performed worse. notably, I don't modify the parameters of the lm head for those future tokens, unlike quiet-star which modifies the parameters of the base language model based on using the hidden representation context vector.\n",
    "\n",
    "may want to create nll graph and record the mean nll from eval because it is the metric I care about?\n",
    "\n",
    "when only training with positive rewards above the trice mean, there is a noticable drop in performance:\n",
    "eval loss 1.97 for both two tokens ahead and 1 token ahead, with policy loss beta 1. For plb 1000000  eval loss 2.07 Could point to substantial optimization room left on the table by not using the negative rewards. (they note this is for stability, so we could fix it with a reference policy (?). Also could use DPO method, but DPO method still needs to be proven that we can train an ok reward model. There are also probably other PPO works which deal with the fact of poor negative reward performance)\n",
    "\n",
    "get_quiet_star_loss_partial = partial(get_quiet_star_loss, policy_loss_beta=1, trice_samples=2, n_tokens_ahead=1)\n",
    "\n",
    "train_model(get_nll, lambda model: eval_loss_fn(model, get_quiet_star_loss_partial), QuietStarLanguageModelLSTM(len(vocab), 100, 1, reparameterization_trick=True).to(device), epochs=100)\n",
    "\n",
    "with reparameterization trick, and just training on NLL loss (because the score function trick isn't required with reparam), we can get eval loss 1.67, further more the avg std goes to about 0.009. This would be the equivelent of a gumbel trick. Doesn't nicely translate to language setting. (but why do they have different performances in the first place? shouldn't the expected gradient be the same? Answer: they are you just need to do more samples in the expectation for the score function trick to get good performance tho. maybe)\n",
    "\n",
    "can get 1.72 with 10 samples. trying with only positives gets 2.3 very sad! got 1.698 with 20 samples avg std goes to 0.014, normally with 2 it goes to 0.027\n",
    "\n",
    "For the DPO reward function, we are not just in the single next token setting, we are trying to get an idea of the performance achievable from some given latent representation\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "training with tanh after the sampling step. unstable? Had a huge gradient norm near the end. the fix was to add tanh to the activations which determined the distribution activations, this prevented high gradients from flowing backwards from the distribution parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dpo_loss(model: QuietStarLanguageModelrGRU, inputs: torch.Tensor, beta_2: float=1, target_model=None, num_samples=2, dpo_loss_beta:float=1, nll_loss_beta:float=1, forward_kl_reward:bool=True, reward_model=None, train_reward_model=None):\n",
    "    # need a reward model, or if the other model is defined, I can use this as a reward model, and match with it.\n",
    "    inputs = inputs.to(device)\n",
    "    labels = inputs.clone()\n",
    "    original_batch_size = inputs.size(0)\n",
    "    repeat_inputs = inputs.repeat_interleave(num_samples, dim=0)\n",
    "    repeat_labels = labels.repeat_interleave(num_samples, dim=0)\n",
    "    repeat_logits, repeat_hidden_states, repeat_log_prob_hidden_states, dist = model.get_logits_and_hidden_states_and_log_prob_hidden_states_dist(repeat_inputs)\n",
    "    repeat_log_prob_hidden_states = repeat_log_prob_hidden_states.sum(-1)\n",
    "    nll_loss = get_nll_from_logits_and_labels(repeat_logits, repeat_labels)\n",
    "    if target_model is not None:\n",
    "        '''\n",
    "        using a pretrained language model as the reward signal implies that I will get the divergence between\n",
    "        the two langauge models given some prefix. The language model defined by this pretrained model,\n",
    "        and the language model defined by the current hidden state at this point in the sentence (randomly sampled),\n",
    "        and implicit to this hidden states predictions over the next tokens is also the parameters of the lm head,\n",
    "        and the next sampled hidden representations. E_{D(y | x)} E_{pi} [log(D(y | x) / pi(y | h1))], where y is a full trajectory\n",
    "        KL with this language model, and another?\n",
    "        Not over real language, but over the proposed next language. For this vocab that is relatively easy only 26 tokens,\n",
    "        Can probably do 26 ** 4, which is 456976 in size, but the real thing to consider, is that I would have to run\n",
    "        17576 forward calls, which would take forever, and therefor even for that few vocab size, this is not acceptable.\n",
    "        Perhaps, if I only focus on some of the generations, like taking a subset, only top 3 tokens per generation, then\n",
    "        I can do many more tokens ahead for the same compute budget. Not sure if this is a valid approx to the KL.\n",
    "        Could just do several samples from the target model, and get the log ratio performance over this text in expectation.\n",
    "        So need a function for computing the KL, first for every partial sequence of inputs,\n",
    "        I would want to compute continuations with my target LM, then produce a log probability over those samples with the same LM,\n",
    "        Then produce a log probability with the policy model given the sampled starting state we are trying to evaluate.\n",
    "        Approximate KL with these log probs, and use as reward. Should be able to achieve good training with this.\n",
    "        Worst case scenario to verify my implementation at least for the single token scenario, can try to recreate my original\n",
    "        LSTM experiments with single next token prediction where I saw distribution based KL working as a reward signal.\n",
    "\n",
    "        Is This KL implementation worth investing time into? What is the overall goal? To test the idea of reward model distillation \n",
    "        in place of REINFORCE. This KL implementation made sense in the single next token prediction setting, as the KL was exactly \n",
    "        what the reward model was supposed to fit in to have minimal loss, but now, the KL approximates what the reward model should \n",
    "        be learning in the first place, and I'm not sure of the quality of the approximation. Before when it was closed form for the true\n",
    "        reward, it needed to work in order for the next part to work. Now, not so much, might not work, but would really depend on the \n",
    "        quality of the KL approximation produced. I could look at the marginal change in KL upon successive increases in number of \n",
    "        future tokens, or number of beams for a given prefix, and decide to terminate when the % change is small for all sequence prefixes.\n",
    "        This would then tell me to be sure of the KL approximation that I am using, in a way I couldn't do with a reward model. \n",
    "        Thus again a useful experimental step in guarenteeing the theory that a perfect ish reward model would at least allow for training \n",
    "        if this works. Then again, even if it does work, the implication isn't that learning is solved, it is just that reward model distillation\n",
    "        is a viable alternative to reinforce style algorithms, but this is already proven through AlphaZero. But I guess there is a question on when \n",
    "        is it better to try to train with reward model distillation versus policy gradient (REINFORCE) based methods, and that question, I don't \n",
    "        answer at all. I think in service of answering this question, I should review more in what people have already said about distillation style \n",
    "        methods like with advantage actor critic vs ppo, or looking at control as inference works. I think I am missing something, and I am not \n",
    "        confident in the success likelihood of my experiments. Should I keep going till I run into some wall in performance, which I believe can't \n",
    "        be surmounted? I now, have some confidence. The Control as inference works, lead me to thinking of AlphaZero works even more, and I \n",
    "        think there are some modifications I can make to my setup to make it flexible enough to include AlphaZero style methods, which should work\n",
    "        (I am however not sure how to tune AlphaZero style methods. I should experiment in a different arena, like that of solved board game agents)\n",
    "        Trying to solve this directly on my language model setting will just lead to reinventing the wheel? not bad tho, just hard here, and would \n",
    "        want some grounding first? Maybe if I hit a wall then I will take time to go back to the basics rather than going to the basics because I \n",
    "        think I will hit a wall.\n",
    "\n",
    "        In light of the similarities between AlphaZero and this method, what would this experiment say in the Alpha zero setting?\n",
    "        - First of all the actions which I am taking are sampled probabilistically based on my current policy, in alpha zero they are taken based\n",
    "            on the current reward function and policy with a tree search that calls the reward function multiple times, and builds confidence in \n",
    "            the gold action distribution through multiple inference calls. Then based on this confident distribution from the multiple calls to the state \n",
    "            eval model with tree search, the distribution to tune on is created. With my proposed solution, there is a clear potential issue with the \n",
    "            correctness of my reward function, because I rely on its value from a single inference step across those states which were sampled from \n",
    "            the current policy. My more full proposal is to have more models, and quantify the model uncertainty, so as only to train on very confident \n",
    "            action pairs. The complexity isn't very high, but I haven't implmented this idea yet.\n",
    "        - Using a more confident prediction of my true reward created through a KL divergence with a psuedo true language distribution can isolate the \n",
    "            reward model's implementation, and tell me about my other algorithm choices like:\n",
    "            - if the idea of using a state distribution collected from simple on policy model is ok or perhaps some other state distribution \n",
    "                would be better like reference model or even AlphaZero style model. (If I say the state distribution is determined by something off policy, \n",
    "                then the way I collect data for my reward function must be collected seperately. I already do this here for correctness, but might be less \n",
    "                efficient).\n",
    "            - Also if using actions proposed from the on policy model versus a different model would be best (This gets into iterative DPO considerations).\n",
    "                Ultimately what we want to be doing is sampling from the gold action distribution, which is the exponential Q distirbution. Alpha Zero \n",
    "                does this in a nicer way than simple on policy actions in my opinion, because of the added confidence through multiple reward model forward \n",
    "                calls, and using number of visits rather than a simple ratio of average Q values to ensure only the confident predictions are matched, not \n",
    "                the overly speculative with no evidence.\n",
    "        Answer: in the AlphaZero setting the method in general would rewrite the MCTS portion in place of high confidence reward functions to create the distribution \n",
    "            over actions, which should be matched by the policy. Having this high confidence reward function with the KL with a psuedo target language distirbution,\n",
    "            in the AlphaZero setting would let someone designing the alpha zero setting know if their N ^ 1/T distribution over actions is getting closer to the \n",
    "            distribution given from this psuedo target langauge distirbution possibly helpful for tuning different parameters in the MCTS stack. \n",
    "            \n",
    "        The distribution should match that of the optimal distribution for your reward or for your value model, so only the Q values which you are confident in work...\n",
    "        '''\n",
    "        # raise NotImplementedError(\"Using a pretrained language model need to implement.\")\n",
    "        with torch.no_grad():\n",
    "            assert forward_kl_reward, \"reverse KL is dropped from support, because it didn't show promise in early experiments.\"\n",
    "            # repeat_reward = (torch.softmax(target_model_repeat_logits, dim=-1) * torch.log_softmax(repeat_logits, dim=-1)).sum(-1)\n",
    "            # need to get so much shit. Just take in for now some defined types, and I know how to play with them. main difficulty is getting target model able to have its hidden representations and use them for generation from the middle of a sentence, and then reshaping the generations to be (batch=batch_parent x num_samples_p x seq_len_p) x num_samples x num_tokens_ahead\n",
    "            repeat_reward = get_forward_kl_reward_with_target_model(target_model, repeat_inputs, repeat_hidden_states, num_tokens_ahead_of_hidden_representation=10, num_samples_per_hidden_representation=2, model.get_logits_and_hidden_states_and_log_prob_hidden_states_dist)\n",
    "            # target_model_repeat_logits = target_model(repeat_inputs)\n",
    "            ...\n",
    "            # else: # reverse KL didn't show much promise, just ignored what it was getting wrong I think. pretty piss poor exploration. the entropy encouragement beta_2 doesn't really help.\n",
    "            #     # repeat_reward = (torch.softmax(repeat_logits, dim=-1) * (torch.log_softmax(target_model_repeat_logits, dim=-1) - torch.log_softmax(repeat_logits, dim=-1))).sum(-1)\n",
    "            #     ...\n",
    "    elif reward_model is not None and train_reward_model is not None:\n",
    "        # train the reward model every so often to ensure it remains relevant to the current lm head and hidden state distribution.\n",
    "        train_reward_model(reward_model, model)\n",
    "        with torch.no_grad():\n",
    "            repeat_reward = reward_model(repeat_inputs, repeat_hidden_states)\n",
    "    else:\n",
    "        raise ValueError(\"must define either reward model or target model to train with DPO loss, i.e. need some way to get reward.\")\n",
    "    repeat_reward = repeat_reward.view(original_batch_size, num_samples, -1)\n",
    "    # this for numerical stability.\n",
    "    repeat_reward = repeat_reward - repeat_reward.max(dim=1, keepdim=True).values\n",
    "    repeat_exp_reward = (repeat_reward).exp()\n",
    "    repeat_gold_action_weight = repeat_exp_reward / repeat_exp_reward.sum(1, keepdim=True)\n",
    "    repeat_log_prob_hidden_states = repeat_log_prob_hidden_states.view(original_batch_size, num_samples, -1)\n",
    "    repeat_log_prob_hidden_states_divided_by_max_hidden_state_prob = repeat_log_prob_hidden_states - repeat_log_prob_hidden_states.max(1, keepdim=True).values # need to get the sum of the probabilities in the denominator\n",
    "    repeat_beta2_log_prob_hidden_states_divided_by_max_hidden_state_prob = beta_2 * repeat_log_prob_hidden_states_divided_by_max_hidden_state_prob\n",
    "    repeat_log_weight_on_hidden_states = repeat_beta2_log_prob_hidden_states_divided_by_max_hidden_state_prob - repeat_beta2_log_prob_hidden_states_divided_by_max_hidden_state_prob.exp().sum(1, keepdim=True).log()\n",
    "    dpo_loss = -(repeat_gold_action_weight.detach() * repeat_log_weight_on_hidden_states).sum(1).mean()\n",
    "    loss = dpo_loss * dpo_loss_beta + nll_loss * nll_loss_beta\n",
    "    print(f\"{dpo_loss= }\")\n",
    "    print(f\"{nll_loss= }\")\n",
    "    avg_std = dist.scale.mean()\n",
    "    print(f\"{avg_std= }\")\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(rnn_lm.cpu(), open(\"rnn_lm_1.51_eval_1.5_train.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_lm = pickle.load(open(\"rnn_lm_1.51_eval_1.5_train.pkl\", 'rb')).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dpo_loss_partial = partial(get_dpo_loss, target_model=rnn_lm, beta_2=0.0001, dpo_loss_beta=10000, num_samples=2)\n",
    "dpo_trained_model = QuietStarLanguageModelrGRU(len(vocab), 100, 1, model_type = 'rgruh').to(device)\n",
    "train_model(get_dpo_loss_partial, lambda model: eval_loss_fn(model, get_nll), dpo_trained_model, epochs=100)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best obtainable 1.65 with normal nll 100 hidden dim 100 epochs.  got 1.82 eval with 100 hidden dim, and 100 epochs beta_2 = 0.0001\n",
    "\n",
    "\n",
    "\n",
    "dpo with beta value 0.0001, no reference model hence the high beta value. eval nll 1.86. with best obtainable 1.5? with normal nll with 1000 hidden dim 100 epochs\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "\n",
    "get_dpo_loss_partial = partial(get_dpo_loss, target_model=rnn_lm, beta_2=0.0001, dpo_loss_beta=10000) # ceiling is 1.65. obtained 1.79 matching quiet-star with positive and negative rewards.\n",
    "\n",
    "train_model(get_dpo_loss_partial, lambda model: eval_loss_fn(model, get_nll), QuietStarLanguageModelLSTM(len(vocab), 100, 1).to(device), epochs=100)\n",
    "\n",
    "\n",
    "eval 1.738 with ceiling of 1.657 with increase samples. beta_2=0.0001, dpo_loss_beta=10000, num_samples=10. 20 samples gets 1.728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, num_layers=1, dim_of_latent=None):\n",
    "        super().__init__()\n",
    "        if dim_of_latent is None:\n",
    "            dim_of_latent = hidden_dim\n",
    "        self.embed_tokens = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=hidden_dim)\n",
    "        self.model = torch.nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=num_layers)\n",
    "        self.output_layer = torch.nn.Linear(in_features=hidden_dim + dim_of_latent, out_features=1)\n",
    "    def forward(self, token_context, latent_states):\n",
    "        # produce the expected reward for a particular choice of latent state and context x. right? the expectation is that there is a latent state per token in the token_context tensor\n",
    "        x = self.embed_tokens(token_context)\n",
    "        x, _ = self.model(x)\n",
    "        x = self.output_layer(torch.concat((x, latent_states), dim=-1))\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(dpo_trained_model.cpu(), open(\"dpo_trained_model_1.64_eval.pkl\", 'wb'))\n",
    "dpo_trained_model = pickle.load(open(\"dpo_trained_model_1.64_eval.pkl\", 'rb')).to(device)\n",
    "rnn_lm = pickle.load(open(\"rnn_lm_1.51_eval_1.5_train.pkl\", 'rb')).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the input_ids, and latent_states to train off of for the reward model.\n",
    "\n",
    "# create a function to collect the nlls input_ids and latent states. Could do this in the train model loop with a unique loss function, but I don't need to update the parameters of my model, so I could just create a new loop for this explicit purpose.\n",
    "def get_data_for_reward_model_training(model: QuietStarLanguageModelLSTM, repeat_sample, sample_for_train):\n",
    "    train_size = int(len(train_reward_model_dataset_shakespeare) // 10 * 0.9) * 10\n",
    "    input_and_latent_states_and_labels_dataset_train = []\n",
    "    input_and_latent_states_and_labels_dataset_eval = []\n",
    "    for _ in range(repeat_sample):\n",
    "        i = 0\n",
    "        for d in torch.utils.data.DataLoader(train_reward_model_dataset_shakespeare, batch_size=10, collate_fn=shakespeare_collate_fn): # no shuffle here can shuffle later if want to.\n",
    "            d = d.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits, hidden_states, _, _ = model.get_logits_and_hidden_states_and_log_prob_hidden_states_dist(d)\n",
    "                \n",
    "                shifted_logits = logits[:, :-1].contiguous()\n",
    "                shifted_input = d[:, :-1]\n",
    "                shifted_hidden_states = hidden_states[:, :-1].contiguous()\n",
    "                shifted_labels = d[:, 1:].contiguous()\n",
    "                is_train_data = i < train_size\n",
    "                if is_train_data:\n",
    "                    inputs_to_extend = input_and_latent_states_and_labels_dataset_train\n",
    "                else:\n",
    "                    inputs_to_extend = input_and_latent_states_and_labels_dataset_eval\n",
    "                if sample_for_train and is_train_data:\n",
    "                    targets = - torch.nn.CrossEntropyLoss(reduction='none')(shifted_logits.view(-1, logits.size(-1)), shifted_labels.view(-1)).view_as(shifted_labels)\n",
    "                else:\n",
    "                    # targets can also be decided based on the KL[D_ref(y | x) || policy(y | h)] with a reference policy, this is when we assume the reference policy represents the true data distribution.\n",
    "                    target_logits = rnn_lm(shifted_input)\n",
    "                    targets = (torch.softmax(target_logits, dim=-1) * torch.log_softmax(shifted_logits, dim=-1)).sum(-1) # has similar mean to just samples from the data, as expected, but the std between samples is smaller which makes sense, as we remove the variation from sampling and just directly get the expected KL on the distribution provided from the dpo model compared to the rnn_lm.\n",
    "                i += shifted_input.size(0)\n",
    "                inputs_to_extend.extend(zip(shifted_input.cpu(), shifted_hidden_states.cpu(), targets.cpu()))\n",
    "    # I can choose to reward model the dpo models KL with data it was trained on or with data it wasn't trained on? I really need to generalize to the reward of the data we are going to use for training with DPO. \n",
    "    # I should not train on that data tho, because then I would learn to give the exact loss achieved on that sample with that hidden state, which has the problem of not being the expected reward for that input/hidden state.\n",
    "    return input_and_latent_states_and_labels_dataset_train, input_and_latent_states_and_labels_dataset_eval\n",
    "input_and_latent_states_and_labels_dataset_train, input_and_latent_states_and_labels_dataset_eval = get_data_for_reward_model_training(dpo_trained_model, repeat_sample=10, sample_for_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.6405), tensor(1.4577))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_from_data_distribution = torch.concat([input_and_latent_states_and_labels_dataset_train[i][-1] for i in range(len(input_and_latent_states_and_labels_dataset_train))])\n",
    "labels_from_data_distribution.mean(), labels_from_data_distribution.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.6699), tensor(0.9500))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_from_closed_from_kl = torch.concat([input_and_latent_states_and_labels_dataset_eval[i][-1] for i in range(len(input_and_latent_states_and_labels_dataset_eval))])\n",
    "labels_from_closed_from_kl.mean(), labels_from_closed_from_kl.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number training steps total: 305\n",
      "eval loss 2.7291702694363065\n",
      "loss 0     2.7774062156677246\n",
      "loss 1     2.3098318576812744\n",
      "loss 2     1.8561772108078003\n",
      "loss 3     1.5061426162719727\n",
      "loss 4     1.2220115661621094\n",
      "loss 5     0.9549753665924072\n",
      "loss 6     0.7695146799087524\n",
      "loss 7     0.6432797312736511\n",
      "loss 8     0.5641867518424988\n",
      "loss 9     0.5374022126197815\n",
      "eval loss 0.5519882837931315\n",
      "loss 10    0.5478295683860779\n",
      "loss 11    0.5818609595298767\n",
      "loss 12    0.6107260584831238\n",
      "loss 13    0.6193346977233887\n",
      "loss 14    0.6370869874954224\n",
      "loss 15    0.6021691560745239\n",
      "loss 16    0.5674903392791748\n",
      "loss 17    0.5297573804855347\n",
      "loss 18    0.4988583028316498\n",
      "loss 19    0.45056289434432983\n",
      "eval loss 0.4159539010789659\n",
      "loss 20    0.41295671463012695\n",
      "loss 21    0.38520535826683044\n",
      "loss 22    0.36624735593795776\n",
      "loss 23    0.35001081228256226\n",
      "loss 24    0.3358851671218872\n",
      "loss 25    0.3260577321052551\n",
      "loss 26    0.32394763827323914\n",
      "loss 27    0.3230610489845276\n",
      "loss 28    0.3115394115447998\n",
      "loss 29    0.31150078773498535\n",
      "eval loss 0.30452783902486164\n",
      "loss 30    0.3096417188644409\n",
      "loss 31    0.3083253502845764\n",
      "loss 32    0.2995508313179016\n",
      "loss 33    0.29083138704299927\n",
      "loss 34    0.2887668013572693\n",
      "loss 35    0.2845281660556793\n",
      "loss 36    0.2743665874004364\n",
      "loss 37    0.26261210441589355\n",
      "loss 38    0.2569277286529541\n",
      "loss 39    0.2603013515472412\n",
      "eval loss 0.2471910317738851\n",
      "loss 40    0.2518223226070404\n",
      "loss 41    0.24499298632144928\n",
      "loss 42    0.2515409588813782\n",
      "loss 43    0.24381551146507263\n",
      "loss 44    0.24357479810714722\n",
      "loss 45    0.24382427334785461\n",
      "loss 46    0.24348482489585876\n",
      "loss 47    0.24175822734832764\n",
      "loss 48    0.24407720565795898\n",
      "loss 49    0.2440171092748642\n",
      "eval loss 0.23545710245768228\n",
      "loss 50    0.2334664762020111\n",
      "loss 51    0.23722413182258606\n",
      "loss 52    0.23319025337696075\n",
      "loss 53    0.23119434714317322\n",
      "loss 54    0.22552402317523956\n",
      "loss 55    0.22733494639396667\n",
      "loss 56    0.22605589032173157\n",
      "loss 57    0.22506479918956757\n",
      "loss 58    0.2219812273979187\n",
      "loss 59    0.22179511189460754\n",
      "eval loss 0.21792995929718018\n",
      "loss 60    0.22303369641304016\n",
      "loss 61    0.2198176085948944\n",
      "loss 62    0.21871286630630493\n",
      "loss 63    0.22113002836704254\n",
      "loss 64    0.21692517399787903\n",
      "loss 65    0.2203231304883957\n",
      "loss 66    0.22067378461360931\n",
      "loss 67    0.21462665498256683\n",
      "loss 68    0.214946448802948\n",
      "loss 69    0.2190709412097931\n",
      "eval loss 0.20976703696780735\n",
      "loss 70    0.213178813457489\n",
      "loss 71    0.21109916269779205\n",
      "loss 72    0.21416465938091278\n",
      "loss 73    0.2121727168560028\n",
      "loss 74    0.20793651044368744\n",
      "loss 75    0.2132469117641449\n",
      "loss 76    0.20876622200012207\n",
      "loss 77    0.20748871564865112\n",
      "loss 78    0.2078796774148941\n",
      "loss 79    0.20763510465621948\n",
      "eval loss 0.20476202170054117\n",
      "loss 80    0.20643189549446106\n",
      "loss 81    0.2078130841255188\n",
      "loss 82    0.20363514125347137\n",
      "loss 83    0.20602357387542725\n",
      "loss 84    0.20776638388633728\n",
      "loss 85    0.2076827883720398\n",
      "loss 86    0.20930099487304688\n",
      "loss 87    0.20855596661567688\n",
      "loss 88    0.20240193605422974\n",
      "loss 89    0.20901209115982056\n",
      "eval loss 0.2001775238249037\n",
      "loss 90    0.20622041821479797\n",
      "loss 91    0.204222172498703\n",
      "loss 92    0.202508807182312\n",
      "loss 93    0.20249342918395996\n",
      "loss 94    0.20272402465343475\n",
      "loss 95    0.20390585064888\n",
      "loss 96    0.20187412202358246\n",
      "loss 97    0.20062166452407837\n",
      "loss 98    0.19827058911323547\n",
      "loss 99    0.19964495301246643\n",
      "eval loss 0.19727957248687744\n",
      "loss 100   0.20100165903568268\n",
      "loss 101   0.20094695687294006\n",
      "loss 102   0.2027754783630371\n",
      "loss 103   0.20373816788196564\n",
      "loss 104   0.2015969157218933\n",
      "loss 105   0.1971244513988495\n",
      "loss 106   0.19964599609375\n",
      "loss 107   0.2008313536643982\n",
      "loss 108   0.20280739665031433\n",
      "loss 109   0.19938799738883972\n",
      "eval loss 0.1947863366868761\n",
      "loss 110   0.1982155442237854\n",
      "loss 111   0.19791388511657715\n",
      "loss 112   0.19353517889976501\n",
      "loss 113   0.1951644867658615\n",
      "loss 114   0.2025235891342163\n",
      "loss 115   0.20033420622348785\n",
      "loss 116   0.19740793108940125\n",
      "loss 117   0.19849273562431335\n",
      "loss 118   0.20050814747810364\n",
      "loss 119   0.19700764119625092\n",
      "eval loss 0.1925224330690172\n",
      "loss 120   0.19780531525611877\n",
      "loss 121   0.19804655015468597\n",
      "loss 122   0.1983514130115509\n",
      "loss 123   0.1954021453857422\n",
      "loss 124   0.198357492685318\n",
      "loss 125   0.19336184859275818\n",
      "loss 126   0.19501295685768127\n",
      "loss 127   0.19356560707092285\n",
      "loss 128   0.19835571944713593\n",
      "loss 129   0.1957067847251892\n",
      "eval loss 0.19089602099524605\n",
      "loss 130   0.1956218034029007\n",
      "loss 131   0.1915343552827835\n",
      "loss 132   0.19532379508018494\n",
      "loss 133   0.19748592376708984\n",
      "loss 134   0.1937367022037506\n",
      "loss 135   0.19049417972564697\n",
      "loss 136   0.19114123284816742\n",
      "loss 137   0.1948651820421219\n",
      "loss 138   0.1965554654598236\n",
      "loss 139   0.19328361749649048\n",
      "eval loss 0.18932648499806723\n",
      "loss 140   0.1916249394416809\n",
      "loss 141   0.19382338225841522\n",
      "loss 142   0.19674257934093475\n",
      "loss 143   0.18800967931747437\n",
      "loss 144   0.19004809856414795\n",
      "loss 145   0.1889592409133911\n",
      "loss 146   0.19459989666938782\n",
      "loss 147   0.1942158043384552\n",
      "loss 148   0.18976804614067078\n",
      "loss 149   0.194039985537529\n",
      "eval loss 0.18823077943589953\n",
      "loss 150   0.19090163707733154\n",
      "loss 151   0.19100259244441986\n",
      "loss 152   0.18802514672279358\n",
      "loss 153   0.19183772802352905\n",
      "loss 154   0.19216492772102356\n",
      "loss 155   0.1906658113002777\n",
      "loss 156   0.1887020468711853\n",
      "loss 157   0.19105857610702515\n",
      "loss 158   0.1894385814666748\n",
      "loss 159   0.1942920684814453\n",
      "eval loss 0.18717479705810547\n",
      "loss 160   0.19267310202121735\n",
      "loss 161   0.1923697143793106\n",
      "loss 162   0.19193151593208313\n",
      "loss 163   0.18734784424304962\n",
      "loss 164   0.18948397040367126\n",
      "loss 165   0.18890981376171112\n",
      "loss 166   0.18973664939403534\n",
      "loss 167   0.18722623586654663\n",
      "loss 168   0.19321127235889435\n",
      "loss 169   0.18878251314163208\n",
      "eval loss 0.1865031189388699\n",
      "loss 170   0.19416162371635437\n",
      "loss 171   0.19225594401359558\n",
      "loss 172   0.18744492530822754\n",
      "loss 173   0.1899631917476654\n",
      "loss 174   0.18954883515834808\n",
      "loss 175   0.19188809394836426\n",
      "loss 176   0.1912299245595932\n",
      "loss 177   0.18795764446258545\n",
      "loss 178   0.18743741512298584\n",
      "loss 179   0.1893881857395172\n",
      "eval loss 0.18535704082912868\n",
      "loss 180   0.18705692887306213\n",
      "loss 181   0.18735557794570923\n",
      "loss 182   0.18655085563659668\n",
      "loss 183   0.19376856088638306\n",
      "loss 184   0.1868399977684021\n",
      "loss 185   0.1905006617307663\n",
      "loss 186   0.19056057929992676\n",
      "loss 187   0.18873825669288635\n",
      "loss 188   0.19073793292045593\n",
      "loss 189   0.19207055866718292\n",
      "eval loss 0.1846945815616184\n",
      "loss 190   0.1867028772830963\n",
      "loss 191   0.1886586844921112\n",
      "loss 192   0.18677687644958496\n",
      "loss 193   0.1877845674753189\n",
      "loss 194   0.18395066261291504\n",
      "loss 195   0.1837969571352005\n",
      "loss 196   0.18835893273353577\n",
      "loss 197   0.18833325803279877\n",
      "loss 198   0.18729670345783234\n",
      "loss 199   0.1891794204711914\n",
      "eval loss 0.1840560038884481\n",
      "loss 200   0.19257202744483948\n",
      "loss 201   0.18800371885299683\n",
      "loss 202   0.1855514645576477\n",
      "loss 203   0.18697158992290497\n",
      "loss 204   0.1852586269378662\n",
      "loss 205   0.18784046173095703\n",
      "loss 206   0.1835126131772995\n",
      "loss 207   0.1893916130065918\n",
      "loss 208   0.18727761507034302\n",
      "loss 209   0.18599295616149902\n",
      "eval loss 0.18349528312683105\n",
      "loss 210   0.18789148330688477\n",
      "loss 211   0.18241772055625916\n",
      "loss 212   0.18794789910316467\n",
      "loss 213   0.18564969301223755\n",
      "loss 214   0.19176459312438965\n",
      "loss 215   0.18842822313308716\n",
      "loss 216   0.1836167871952057\n",
      "loss 217   0.18372583389282227\n",
      "loss 218   0.1874752789735794\n",
      "loss 219   0.1861017644405365\n",
      "eval loss 0.1828700436486138\n",
      "loss 220   0.18516376614570618\n",
      "loss 221   0.18864426016807556\n",
      "loss 222   0.1862790286540985\n",
      "loss 223   0.18753990530967712\n",
      "loss 224   0.18803533911705017\n",
      "loss 225   0.18452073633670807\n",
      "loss 226   0.1833282709121704\n",
      "loss 227   0.18743012845516205\n",
      "loss 228   0.18578758835792542\n",
      "loss 229   0.18895670771598816\n",
      "eval loss 0.18246091736687553\n",
      "loss 230   0.1868315488100052\n",
      "loss 231   0.1845788061618805\n",
      "loss 232   0.19408977031707764\n",
      "loss 233   0.18336862325668335\n",
      "loss 234   0.1861851066350937\n",
      "loss 235   0.18586742877960205\n",
      "loss 236   0.18621429800987244\n",
      "loss 237   0.18604065477848053\n",
      "loss 238   0.18295137584209442\n",
      "loss 239   0.19271133840084076\n",
      "eval loss 0.18204785717858207\n",
      "loss 240   0.18489059805870056\n",
      "loss 241   0.18575207889080048\n",
      "loss 242   0.18762226402759552\n",
      "loss 243   0.1835566610097885\n",
      "loss 244   0.18630599975585938\n",
      "loss 245   0.18731510639190674\n",
      "loss 246   0.1852254867553711\n",
      "loss 247   0.18518751859664917\n",
      "loss 248   0.18681444227695465\n",
      "loss 249   0.18460413813591003\n",
      "eval loss 0.18157716592152914\n",
      "loss 250   0.1852991133928299\n",
      "loss 251   0.1856815218925476\n",
      "loss 252   0.1839527189731598\n",
      "loss 253   0.18534782528877258\n",
      "loss 254   0.1827535331249237\n",
      "loss 255   0.18641623854637146\n",
      "loss 256   0.1837318241596222\n",
      "loss 257   0.18590903282165527\n",
      "loss 258   0.18560980260372162\n",
      "loss 259   0.18308910727500916\n",
      "eval loss 0.18122443887922499\n",
      "loss 260   0.18472887575626373\n",
      "loss 261   0.18138696253299713\n",
      "loss 262   0.18733273446559906\n",
      "loss 263   0.18293017148971558\n",
      "loss 264   0.1814313530921936\n",
      "loss 265   0.1850154548883438\n",
      "loss 266   0.18344195187091827\n",
      "loss 267   0.17777128517627716\n",
      "loss 268   0.181028813123703\n",
      "loss 269   0.18570487201213837\n",
      "eval loss 0.18064812819163004\n",
      "loss 270   0.1835126280784607\n",
      "loss 271   0.17854280769824982\n",
      "loss 272   0.18342849612236023\n",
      "loss 273   0.18479155004024506\n",
      "loss 274   0.18247920274734497\n",
      "loss 275   0.18150953948497772\n",
      "loss 276   0.18653634190559387\n",
      "loss 277   0.18255729973316193\n",
      "loss 278   0.18048548698425293\n",
      "loss 279   0.19193479418754578\n",
      "eval loss 0.18032916386922201\n",
      "loss 280   0.1847379207611084\n",
      "loss 281   0.18277305364608765\n",
      "loss 282   0.1854928433895111\n",
      "loss 283   0.18678522109985352\n",
      "loss 284   0.18043074011802673\n",
      "loss 285   0.18303854763507843\n",
      "loss 286   0.18204984068870544\n",
      "loss 287   0.1824892908334732\n",
      "loss 288   0.18145465850830078\n",
      "loss 289   0.1838294118642807\n",
      "eval loss 0.18012064033084446\n",
      "loss 290   0.18465566635131836\n",
      "loss 291   0.18593193590641022\n",
      "loss 292   0.18169589340686798\n",
      "loss 293   0.1812450885772705\n",
      "loss 294   0.1801709085702896\n",
      "loss 295   0.18154191970825195\n",
      "loss 296   0.1851355880498886\n",
      "loss 297   0.18459174036979675\n",
      "loss 298   0.18366441130638123\n",
      "loss 299   0.1821363866329193\n",
      "eval loss 0.17976082695855033\n",
      "loss 300   0.18436594307422638\n",
      "loss 301   0.17959663271903992\n",
      "loss 302   0.18565316498279572\n",
      "loss 303   0.1829720288515091\n",
      "loss 304   0.17751581966876984\n",
      "eval loss 0.17965598901112875\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Could change the data loader change the inputs and labels for this setting as it is no longer a language modeling setting, but a reward modeling setting.\n",
    "# should modify them so that inputs is context text and hidden_state chosen, and labels is what the correct (instant or expected) reward should have been\n",
    "def get_reward_model_loss(model: RewardModel, inputs: tuple[torch.Tensor, torch.Tensor, torch.Tensor]):\n",
    "    # expect to find input_ids, and a latent_states of similar dimension plus the dimension of the hidden state for the language model which produced the latent.\n",
    "    # get_logits_and_hidden_states\n",
    "    input_ids, latent_states, labels = inputs\n",
    "    input_ids, latent_states, labels = input_ids.to(device), latent_states.to(device), labels.to(device)\n",
    "    predicted_rewards = model(input_ids, latent_states)\n",
    "    diffs = labels - predicted_rewards\n",
    "    # print(f\"{labels= }\")\n",
    "    # print(f\"{predicted_rewards= }\")\n",
    "    # print(f\"{diffs= }\")\n",
    "    loss = 0.5 * (diffs).square().mean()\n",
    "    return loss\n",
    "def train_reward_model(reward_model, model, repeat_sample, sample_for_train, print_stuff):\n",
    "    input_and_latent_states_and_labels_dataset_train, input_and_latent_states_and_labels_dataset_eval = get_data_for_reward_model_training(model, repeat_sample=repeat_sample, sample_for_train=sample_for_train)\n",
    "    train_model(get_reward_model_loss, \n",
    "                lambda model: eval_loss_fn(model, get_reward_model_loss, dataloader=torch.utils.data.DataLoader(input_and_latent_states_and_labels_dataset_eval, batch_size=256)), \n",
    "                reward_model, \n",
    "                epochs=100,\n",
    "                train_dl=torch.utils.data.DataLoader(input_and_latent_states_and_labels_dataset_train, batch_size=256, shuffle=True),\n",
    "                eval_every=10,\n",
    "                print_stuff=print_stuff) # strange observation we aren't over fitting at all? This is nice I guess, but we should be able to overfit if we want to. I did 1000 hidden state, and tried 30 epochs, nothing.\n",
    "# we converge quickly, but is it to a good value? mse 0.7 for samples or 0.18 to the closed KL to reference model. Some of the rewards are very far off actually, not sure if this will be useful. \n",
    "# Will try first to use it in DPO, if doesn't work will then move to train ensemble. # matches eval 0.23 when trained on samples of log likelihood and matches eval to 0.17 when trained from the KL\n",
    "train_reward_model(RewardModel(len(vocab), hidden_dim=100).to(device), dpo_trained_model, repeat_sample=10, sample_for_train=False, print_stuff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number training steps total: 2800\n",
      "eval loss 4.336419582366943\n",
      "Number training steps total: 40\n",
      "eval loss 9.647443771362305\n",
      "loss 0     9.659393310546875\n",
      "loss 1     9.393880844116211\n",
      "loss 2     9.164434432983398\n",
      "loss 3     8.995941162109375\n",
      "loss 4     8.695518493652344\n",
      "loss 5     8.451360702514648\n",
      "loss 6     8.15606689453125\n",
      "loss 7     8.059782981872559\n",
      "loss 8     7.59528923034668\n",
      "loss 9     7.285473823547363\n",
      "eval loss 6.952795028686523\n",
      "loss 10    6.901096343994141\n",
      "loss 11    6.999740123748779\n",
      "loss 12    6.0428996086120605\n",
      "loss 13    5.559576034545898\n",
      "loss 14    4.997659683227539\n",
      "loss 15    5.322469711303711\n",
      "loss 16    3.710531711578369\n",
      "loss 17    3.0752735137939453\n",
      "loss 18    2.4951343536376953\n",
      "loss 19    3.587360382080078\n",
      "eval loss 1.6079705953598022\n",
      "loss 20    1.4478669166564941\n",
      "loss 21    1.098055362701416\n",
      "loss 22    0.8249633312225342\n",
      "loss 23    2.082962989807129\n",
      "loss 24    0.4383693337440491\n",
      "loss 25    0.3284553289413452\n",
      "loss 26    0.2810075879096985\n",
      "loss 27    1.1991065740585327\n",
      "loss 28    0.2528616487979889\n",
      "loss 29    0.27280426025390625\n",
      "eval loss 0.3771148920059204\n",
      "loss 30    0.30472075939178467\n",
      "loss 31    1.1941286325454712\n",
      "loss 32    0.3548298478126526\n",
      "loss 33    0.38678038120269775\n",
      "loss 34    0.4011830687522888\n",
      "loss 35    1.1313326358795166\n",
      "loss 36    0.40147864818573\n",
      "loss 37    0.39530593156814575\n",
      "loss 38    0.37384164333343506\n",
      "loss 39    1.1012516021728516\n",
      "eval loss 0.3865692615509033\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.3333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 0     6935.806640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.3269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1     6935.79833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.3243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 2     6935.7919921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.3141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 3     6935.7841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.3089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 4     6935.78076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.3085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 5     6935.77783203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.2993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 6     6935.7783203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.2977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 7     6935.77685546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.2831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 8     6935.7587890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.2756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(0.9992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 9     6935.75439453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.2676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 10    6935.73486328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.2514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 11    6935.7314453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.2301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 12    6935.69921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.2023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 13    6935.666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.1676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 14    6935.646484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.1147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 15    6935.58056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(4.0619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 16    6935.53125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.9821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 17    6935.4521484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.9068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 18    6935.3701171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.8284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 19    6935.296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.7564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 20    6935.2197265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.7017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 21    6935.17041015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 22    6935.12060546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 23    6935.1005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 24    6935.072265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 25    6935.0771484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 26    6935.07763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 27    6935.119140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 28    6935.076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 29    6935.1279296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 30    6935.1357421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 31    6935.13818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 32    6935.140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 33    6935.12548828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 34    6935.099609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 35    6935.07373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 36    6935.083984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 37    6935.0654296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 38    6935.06103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 39    6935.06884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 40    6935.04931640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 41    6935.087890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 42    6935.04736328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 43    6935.0595703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 44    6935.03759765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 45    6934.98681640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 46    6935.041015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 47    6935.017578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 48    6935.02685546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 49    6935.06005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 50    6935.00390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 51    6934.99609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 52    6934.990234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 53    6935.0302734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 54    6935.0205078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 55    6934.978515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 56    6934.9931640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.1937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 57    6935.0166015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 58    6935.02734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 59    6934.990234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 60    6935.00146484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 61    6934.9912109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 62    6935.00732421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 63    6934.9931640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 64    6935.0166015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 65    6935.01611328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 66    6935.01806640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 67    6935.02294921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 68    6935.01611328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 69    6934.962890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 70    6934.9873046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.2999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 71    6934.9970703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 72    6934.99658203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 73    6935.0126953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 74    6934.99951171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 75    6934.98681640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 76    6935.0126953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 77    6934.9921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 78    6934.98095703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 79    6934.99267578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 80    6934.9921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 81    6934.99658203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 82    6934.9931640625\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 83    6935.001953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 84    6934.9970703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 85    6934.98388671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 86    6934.96630859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 87    6934.98046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 88    6934.96240234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 89    6934.9775390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 90    6934.9970703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 91    6934.974609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 92    6934.97900390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 93    6934.98974609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 94    6934.9658203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 95    6934.970703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.3964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 96    6934.955078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 97    6934.98486328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 98    6934.9736328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 99    6934.98779296875\n",
      "eval loss 3.5031802654266357\n",
      "Number training steps total: 40\n",
      "eval loss 474.5733337402344\n",
      "loss 0     472.347900390625\n",
      "loss 1     434.66265869140625\n",
      "loss 2     399.1605224609375\n",
      "loss 3     384.62548828125\n",
      "loss 4     332.60626220703125\n",
      "loss 5     302.45306396484375\n",
      "loss 6     273.0792541503906\n",
      "loss 7     264.61328125\n",
      "loss 8     220.198486328125\n",
      "loss 9     196.33477783203125\n",
      "eval loss 175.60699462890625\n",
      "loss 10    173.968017578125\n",
      "loss 11    169.1885986328125\n",
      "loss 12    134.2865447998047\n",
      "loss 13    116.41537475585938\n",
      "loss 14    100.68399810791016\n",
      "loss 15    97.38875579833984\n",
      "loss 16    72.80846405029297\n",
      "loss 17    61.02927780151367\n",
      "loss 18    50.857810974121094\n",
      "loss 19    51.4609489440918\n",
      "eval loss 34.346588134765625\n",
      "loss 20    33.51768493652344\n",
      "loss 21    26.67582893371582\n",
      "loss 22    20.741485595703125\n",
      "loss 23    22.179973602294922\n",
      "loss 24    11.77342414855957\n",
      "loss 25    8.423903465270996\n",
      "loss 26    5.888657569885254\n",
      "loss 27    8.547713279724121\n",
      "loss 28    2.4425816535949707\n",
      "loss 29    1.4819129705429077\n",
      "eval loss 1.0833498239517212\n",
      "loss 30    0.8846485614776611\n",
      "loss 31    2.8658359050750732\n",
      "loss 32    0.5811852812767029\n",
      "loss 33    0.776880145072937\n",
      "loss 34    1.1032482385635376\n",
      "loss 35    2.568047523498535\n",
      "loss 36    1.9641755819320679\n",
      "loss 37    2.429368495941162\n",
      "loss 38    2.9324378967285156\n",
      "loss 39    3.300844669342041\n",
      "eval loss 3.635862350463867\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 100   6934.97412109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 101   6934.9560546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 102   6935.0029296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 103   6934.96484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 104   6934.96044921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 105   6934.97412109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 106   6934.96875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 107   6934.9775390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 108   6934.96875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 109   6934.955078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 110   6934.9697265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 111   6935.0068359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 112   6934.96826171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 113   6934.96142578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 114   6934.994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 115   6934.9833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 116   6934.96630859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 117   6934.97607421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 118   6934.97509765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 119   6934.94189453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 120   6934.94677734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 121   6934.93603515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 122   6934.9541015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 123   6934.9482421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 124   6934.96142578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 125   6934.95703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 126   6934.9462890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 127   6934.96044921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 128   6934.94140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 129   6934.95556640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 130   6934.95556640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 131   6934.96728515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 132   6934.92919921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 133   6934.9326171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 134   6934.94140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 135   6934.94189453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 136   6934.9443359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 137   6934.9404296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 138   6934.9365234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 139   6934.9228515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 140   6934.95556640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 141   6934.90478515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.5978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 142   6934.93505859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 143   6934.9462890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 144   6934.94580078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 145   6934.935546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 146   6934.9365234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 147   6934.94091796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 148   6934.96533203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 149   6934.9384765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 150   6934.9248046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 151   6934.9375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 152   6934.92529296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 153   6934.94140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 154   6934.9404296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 155   6934.9453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 156   6934.94140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.6940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 157   6934.9326171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 158   6934.91455078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 159   6934.927734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 160   6934.93359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 161   6934.93408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 162   6934.94580078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 163   6934.9267578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 164   6934.93603515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 165   6934.94677734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 166   6934.9423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 167   6934.8974609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.7967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 168   6934.9384765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 169   6934.93212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 170   6934.9375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 171   6934.93408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 172   6934.9365234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 173   6934.93408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 174   6934.93994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 175   6934.94384765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 176   6934.9453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 177   6934.93994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.8999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 178   6934.9326171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.9095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 179   6934.9384765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 180   6934.93896484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 181   6934.9365234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.9417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 182   6934.94921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 183   6934.9453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 184   6934.93896484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(1.9858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 185   6934.931640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 186   6934.92919921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 187   6934.93212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 188   6934.93603515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 189   6934.90478515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 190   6934.91552734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 191   6934.91796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 192   6934.93701171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 193   6934.93017578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 194   6934.9140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 195   6935.005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 196   6934.9453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 197   6934.93701171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 198   6934.92333984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 199   6934.935546875\n",
      "eval loss 3.4608025550842285\n",
      "Number training steps total: 40\n",
      "eval loss 97.71612548828125\n",
      "loss 0     96.40255737304688\n",
      "loss 1     80.29834747314453\n",
      "loss 2     66.32054901123047\n",
      "loss 3     63.48746871948242\n",
      "loss 4     41.85707092285156\n",
      "loss 5     31.96949005126953\n",
      "loss 6     23.616756439208984\n",
      "loss 7     22.120786666870117\n",
      "loss 8     11.215535163879395\n",
      "loss 9     6.890561103820801\n",
      "eval loss 4.258557319641113\n",
      "loss 10    3.9247260093688965\n",
      "loss 11    5.2729363441467285\n",
      "loss 12    0.923489511013031\n",
      "loss 13    0.7359163761138916\n",
      "loss 14    1.010823369026184\n",
      "loss 15    2.349539279937744\n",
      "loss 16    2.7548868656158447\n",
      "loss 17    3.829383611679077\n",
      "loss 18    4.876821517944336\n",
      "loss 19    5.3785400390625\n",
      "eval loss 6.291474342346191\n",
      "loss 20    6.349123001098633\n",
      "loss 21    6.840434551239014\n",
      "loss 22    6.957488059997559\n",
      "loss 23    6.304992198944092\n",
      "loss 24    6.499017715454102\n",
      "loss 25    5.929083824157715\n",
      "loss 26    5.254276275634766\n",
      "loss 27    4.9496588706970215\n",
      "loss 28    3.7964723110198975\n",
      "loss 29    3.102214813232422\n",
      "eval loss 2.4298810958862305\n",
      "loss 30    2.441866397857666\n",
      "loss 31    2.4073777198791504\n",
      "loss 32    1.4354679584503174\n",
      "loss 33    1.070289134979248\n",
      "loss 34    0.8412626385688782\n",
      "loss 35    2.883392810821533\n",
      "loss 36    0.6724417805671692\n",
      "loss 37    0.6991426944732666\n",
      "loss 38    0.7379236221313477\n",
      "loss 39    2.759315252304077\n",
      "eval loss 1.1255266666412354\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 200   6934.91650390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 201   6934.9423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 202   6934.92138671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 203   6934.9267578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 204   6934.951171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 205   6934.943359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 206   6934.912109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 207   6934.9462890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.1989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 208   6934.9580078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 209   6934.939453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 210   6934.92333984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 211   6934.9296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 212   6934.93408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 213   6934.93408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 214   6934.9375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 215   6934.962890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 216   6934.9130859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 217   6934.89990234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.2980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 218   6934.9111328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 219   6934.94677734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 220   6934.94873046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 221   6934.92529296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 222   6934.9365234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 223   6934.89990234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 224   6934.94580078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 225   6934.9521484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 226   6934.9150390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 227   6934.892578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 228   6934.9140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.3961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 229   6934.96923828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 230   6934.93408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 231   6934.91162109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 232   6934.91845703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 233   6934.935546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 234   6934.939453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 235   6934.90869140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 236   6934.89453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 237   6934.9208984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 238   6934.962890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 239   6934.9267578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 240   6934.9091796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.4989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 241   6934.9365234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.5092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 242   6934.91455078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.5203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 243   6934.9072265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.5308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 244   6934.8994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.5404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 245   6934.94873046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.5523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 246   6934.91455078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 247   6934.92236328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.5780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 248   6934.94091796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.5904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 249   6934.9208984375\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.6024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 250   6934.94482421875\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.6192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 251   6934.9296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.6389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 252   6934.8857421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.6563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 253   6934.9140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.6730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 254   6934.91748046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.6889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 255   6934.9033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.7021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 256   6934.94677734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 257   6934.916015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.7346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 258   6934.90087890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.7509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 259   6934.88720703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.7663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 260   6934.92724609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.7782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 261   6934.93212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.7945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 262   6934.8994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.8145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 263   6934.91015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.8353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 264   6934.927734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.8626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 265   6934.90576171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 266   6934.90966796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.9192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 267   6934.87841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 268   6934.90576171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.9635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 269   6934.87890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(2.9810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 270   6934.89453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.0012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 271   6934.90673828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.0235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 272   6934.9033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 273   6934.92529296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.0840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 274   6934.89453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 275   6934.89453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 276   6934.91259765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.1907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 277   6934.91015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.2278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 278   6934.89794921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 279   6934.8974609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.3011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 280   6934.89453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.3348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 281   6934.92529296875\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.3565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 282   6934.9482421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.3852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 283   6934.94189453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.4137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 284   6934.91259765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.4484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 285   6934.9208984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.4791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 286   6934.916015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.5111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 287   6934.896484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.5477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 288   6934.95263671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.5885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 289   6934.9306640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.6261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 290   6934.91796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.6692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 291   6934.90966796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.7047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 292   6934.9150390625\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.7445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 293   6934.94287109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 294   6934.9384765625\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.8369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 295   6934.9375\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.8824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 296   6934.9482421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.9396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 297   6934.8876953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(3.9987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 298   6934.919921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.0589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 299   6934.9228515625\n",
      "eval loss 3.4513320922851562\n",
      "Number training steps total: 40\n",
      "eval loss 81.23530578613281\n",
      "loss 0     80.33263397216797\n",
      "loss 1     64.1990966796875\n",
      "loss 2     49.60596466064453\n",
      "loss 3     43.99616241455078\n",
      "loss 4     26.415800094604492\n",
      "loss 5     18.092653274536133\n",
      "loss 6     11.452333450317383\n",
      "loss 7     9.785103797912598\n",
      "loss 8     3.242565155029297\n",
      "loss 9     1.4201478958129883\n",
      "eval loss 0.9857640862464905\n",
      "loss 10    0.8366053104400635\n",
      "loss 11    2.8744616508483887\n",
      "loss 12    2.2290706634521484\n",
      "loss 13    3.5737695693969727\n",
      "loss 14    4.996722221374512\n",
      "loss 15    6.01690673828125\n",
      "loss 16    7.3308024406433105\n",
      "loss 17    7.8817033767700195\n",
      "loss 18    8.215587615966797\n",
      "loss 19    7.081971168518066\n",
      "eval loss 7.300054550170898\n",
      "loss 20    7.401268005371094\n",
      "loss 21    6.6336669921875\n",
      "loss 22    5.664681434631348\n",
      "loss 23    4.4429168701171875\n",
      "loss 24    3.6379361152648926\n",
      "loss 25    2.762962579727173\n",
      "loss 26    1.992577075958252\n",
      "loss 27    2.2788004875183105\n",
      "loss 28    1.0428887605667114\n",
      "loss 29    0.8303123116493225\n",
      "eval loss 0.9048261046409607\n",
      "loss 30    0.7687501907348633\n",
      "loss 31    2.673618793487549\n",
      "loss 32    1.0074098110198975\n",
      "loss 33    1.167420506477356\n",
      "loss 34    1.3787870407104492\n",
      "loss 35    3.779843807220459\n",
      "loss 36    1.562791109085083\n",
      "loss 37    1.5654780864715576\n",
      "loss 38    1.5357333421707153\n",
      "loss 39    3.264207363128662\n",
      "eval loss 1.4765260219573975\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 300   6934.9208984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 301   6934.92236328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 302   6934.89794921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 303   6934.8955078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 304   6934.91943359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 305   6934.921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 306   6934.91650390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 307   6934.9443359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 308   6934.89990234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 309   6934.921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 310   6934.9150390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 311   6934.90283203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 312   6934.9140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 313   6934.923828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 314   6934.90576171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 315   6934.89794921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 316   6934.8984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 317   6934.91162109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 318   6934.8671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 319   6934.92724609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 320   6934.9375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 321   6934.93408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 322   6934.90625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 323   6934.88671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 324   6934.884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 325   6934.8935546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 326   6934.90673828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 327   6934.86572265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 328   6934.900390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 329   6934.89697265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 330   6934.8896484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 331   6934.90185546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 332   6934.89697265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 333   6934.916015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 334   6934.8857421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 335   6934.89892578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 336   6934.90234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 337   6934.90625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 338   6934.8955078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 339   6934.8974609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 340   6934.876953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 341   6934.90478515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 342   6934.89794921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 343   6934.89501953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 344   6934.90234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 345   6934.92529296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 346   6934.89892578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 347   6934.92138671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 348   6934.908203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 349   6934.90771484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 350   6934.92431640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 351   6934.9130859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 352   6934.87939453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 353   6934.90966796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.1975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 354   6934.87744140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 355   6934.921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 356   6934.90087890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 357   6934.91015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 358   6934.89697265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.2801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 359   6934.884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 360   6934.90576171875\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 361   6934.953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 362   6934.904296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.3714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 363   6934.921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 364   6934.86083984375\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 365   6934.9228515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 366   6934.93994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 367   6934.8828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 368   6934.92529296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 369   6934.90869140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.5894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 370   6934.87353515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 371   6934.91162109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 372   6934.85986328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 373   6934.892578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 374   6934.88525390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 375   6934.90380859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 376   6934.92041015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 377   6934.896484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 378   6934.8798828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 379   6934.89501953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 380   6934.93896484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 381   6934.8701171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 382   6934.9013671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 383   6934.912109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 384   6934.8828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 385   6934.90087890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 386   6934.9052734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 387   6934.8994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 388   6934.90234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 389   6934.900390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 390   6934.884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 391   6934.916015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 392   6934.89990234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 393   6934.9140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 394   6934.90087890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 395   6934.93505859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 396   6934.919921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 397   6934.88232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 398   6934.88525390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 399   6934.892578125\n",
      "eval loss 3.4320144653320312\n",
      "Number training steps total: 40\n",
      "eval loss 45.328285217285156\n",
      "loss 0     44.91571807861328\n",
      "loss 1     30.868947982788086\n",
      "loss 2     19.80207633972168\n",
      "loss 3     15.53866958618164\n",
      "loss 4     5.639863014221191\n",
      "loss 5     2.2660720348358154\n",
      "loss 6     1.0071213245391846\n",
      "loss 7     2.424870252609253\n",
      "loss 8     2.7761030197143555\n",
      "loss 9     4.563668251037598\n",
      "eval loss 6.184124946594238\n",
      "loss 10    6.210068702697754\n",
      "loss 11    6.751412868499756\n",
      "loss 12    7.868800640106201\n",
      "loss 13    7.66220235824585\n",
      "loss 14    6.931751251220703\n",
      "loss 15    5.542818069458008\n",
      "loss 16    4.4958953857421875\n",
      "loss 17    3.224013090133667\n",
      "loss 18    2.1557095050811768\n",
      "loss 19    2.044647216796875\n",
      "eval loss 1.0074394941329956\n",
      "loss 20    0.9341372847557068\n",
      "loss 21    0.7981010675430298\n",
      "loss 22    0.9135246276855469\n",
      "loss 23    2.7136411666870117\n",
      "loss 24    1.5106709003448486\n",
      "loss 25    1.8369669914245605\n",
      "loss 26    2.0368008613586426\n",
      "loss 27    3.966846466064453\n",
      "loss 28    1.9777544736862183\n",
      "loss 29    1.7034450769424438\n",
      "eval loss 1.6458945274353027\n",
      "loss 30    1.5034055709838867\n",
      "loss 31    2.4557583332061768\n",
      "loss 32    0.988986074924469\n",
      "loss 33    0.8070629835128784\n",
      "loss 34    0.7453613877296448\n",
      "loss 35    1.9318674802780151\n",
      "loss 36    0.8273570537567139\n",
      "loss 37    0.9577515125274658\n",
      "loss 38    1.078543782234192\n",
      "loss 39    1.6553664207458496\n",
      "eval loss 1.251722812652588\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 400   6934.875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 401   6934.921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 402   6934.91650390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 403   6934.88525390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 404   6934.92333984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 405   6934.90771484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 406   6934.88623046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 407   6934.91015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 408   6934.8974609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 409   6934.8994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 410   6934.89794921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 411   6934.89697265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 412   6934.92626953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 413   6934.869140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 414   6934.8837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 415   6934.9150390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 416   6934.88818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 417   6934.91259765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 418   6934.90771484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 419   6934.83935546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 420   6934.89501953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 421   6934.90576171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 422   6934.8837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 423   6934.8564453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 424   6934.87890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 425   6934.88330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 426   6934.8779296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 427   6934.8720703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 428   6934.89892578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 429   6934.87060546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.8988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 430   6934.8837890625\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 431   6934.90478515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 432   6934.86669921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(4.9862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 433   6934.89404296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.0128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 434   6934.89404296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.0353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 435   6934.8681640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.0519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 436   6934.86572265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.0673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 437   6934.84619140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.0766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 438   6934.88720703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.0836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 439   6934.88037109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 440   6934.865234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 441   6934.87939453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 442   6934.88427734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 443   6934.91650390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 444   6934.908203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 445   6934.8427734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 446   6934.87158203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 447   6934.8662109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 448   6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.1968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 449   6934.90625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 450   6934.890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 451   6934.88134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 452   6934.8369140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 453   6934.86669921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 454   6934.85009765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 455   6934.86474609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 456   6934.87646484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 457   6934.85888671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.2885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 458   6934.876953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.3082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 459   6934.82275390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.3255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 460   6934.87109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.3354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 461   6934.8642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.3456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 462   6934.87255859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.3443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 463   6934.875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.3576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 464   6934.87060546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.3736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 465   6934.880859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.3880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 466   6934.8544921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.4077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 467   6934.875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.4236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 468   6934.8466796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.4417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 469   6934.8701171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.4671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 470   6934.83349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.4863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 471   6934.8349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.5106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 472   6934.82275390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.5172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 473   6934.861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.5252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 474   6934.8486328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.5408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 475   6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.5577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 476   6934.88916015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.5881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 477   6934.85498046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.6139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 478   6934.841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 479   6934.861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.6433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 480   6934.87353515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.6720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 481   6934.8857421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 482   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 483   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 484   6934.84765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 485   6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 486   6934.873046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 487   6934.84912109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 488   6934.8486328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 489   6934.873046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 490   6934.83056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 491   6934.8544921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 492   6934.86279296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 493   6934.81591796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 494   6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 495   6934.84326171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 496   6934.84521484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 497   6934.85986328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 498   6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 499   6934.84033203125\n",
      "eval loss 3.377016544342041\n",
      "Number training steps total: 40\n",
      "eval loss 15.469330787658691\n",
      "loss 0     15.190585136413574\n",
      "loss 1     7.3432488441467285\n",
      "loss 2     2.7102150917053223\n",
      "loss 3     1.885204553604126\n",
      "loss 4     1.2512240409851074\n",
      "loss 5     2.7465200424194336\n",
      "loss 6     4.12947416305542\n",
      "loss 7     4.737872123718262\n",
      "loss 8     4.428744316101074\n",
      "loss 9     3.53702449798584\n",
      "eval loss 2.456549644470215\n",
      "loss 10    2.4762394428253174\n",
      "loss 11    1.9692199230194092\n",
      "loss 12    0.9163581728935242\n",
      "loss 13    0.7509542107582092\n",
      "loss 14    0.9155958294868469\n",
      "loss 15    2.463392734527588\n",
      "loss 16    1.6026067733764648\n",
      "loss 17    1.7364428043365479\n",
      "loss 18    1.6735601425170898\n",
      "loss 19    2.7382259368896484\n",
      "eval loss 1.2987098693847656\n",
      "loss 20    1.1870331764221191\n",
      "loss 21    0.8896867036819458\n",
      "loss 22    0.7331321835517883\n",
      "loss 23    1.3314568996429443\n",
      "loss 24    0.8080185651779175\n",
      "loss 25    0.9470285773277283\n",
      "loss 26    1.0889348983764648\n",
      "loss 27    1.6886811256408691\n",
      "loss 28    1.1708475351333618\n",
      "loss 29    1.0752450227737427\n",
      "eval loss 0.9698303937911987\n",
      "loss 30    0.9338518381118774\n",
      "loss 31    1.2098703384399414\n",
      "loss 32    0.7159274816513062\n",
      "loss 33    0.6456555724143982\n",
      "loss 34    0.6761881709098816\n",
      "loss 35    1.7001632452011108\n",
      "loss 36    0.7688145041465759\n",
      "loss 37    0.7552754282951355\n",
      "loss 38    0.741629421710968\n",
      "loss 39    1.3606762886047363\n",
      "eval loss 0.744304895401001\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGeCAYAAAA0WWMxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABclElEQVR4nO3dd3xUVf7/8ddMJpkUUgglBRJ6LyGCIGKBBQVsYFkbdldXxbWuq+xv1V3d/aLuruta1rq7NgR1FewFUUAUlBY6oQUIJYSaXmfu74/JTBIIJCEzuVPez8fjPnKZ3Mz9XK4475xz7jkWwzAMRERERFqJ1ewCREREJLQofIiIiEirUvgQERGRVqXwISIiIq1K4UNERERalcKHiIiItCqFDxEREWlVCh8iIiLSqhQ+REREpFXZzC7gaE6nkz179hAbG4vFYjG7HBEREWkCwzAoKioiNTUVq7WRtg2jmRYsWGBccMEFRkpKigEYs2fPPuaY9evXGxdeeKERFxdnREdHG8OGDTN27NjRpPfPzc01AG3atGnTpk1bAG65ubmNftY3u+WjpKSEjIwMbrrpJi655JJjvr9161bOOOMMbr75Zv70pz8RFxfHunXriIyMbNL7x8bGApCbm0tcXFxzyxMRERETFBYWkpaW5vkcPxGLYZz8wnIWi4XZs2czefJkz2tXXnkl4eHhvPXWWyf1noWFhcTHx1NQUKDwISIiEiCa8/nt1QGnTqeTzz77jN69ezN+/Hg6duzIiBEjmDNnznF/pqKigsLCwnqbiIiIBC+vho/8/HyKi4t54oknmDBhAl9//TUXX3wxl1xyCQsWLGjwZ6ZPn058fLxnS0tL82ZJIiIi4me82u2yZ88eOnXqxFVXXcU777zjOe6iiy4iJiaGmTNnHvMeFRUVVFRUeP7s7jNSt4uIiEjgaE63i1cftW3fvj02m43+/fvXe71fv34sWrSowZ+x2+3Y7XZvliEiIiJ+zKvdLhEREZx66qlkZ2fXe33Tpk106dLFm6cSERGRANXslo/i4mK2bNni+XNOTg5ZWVkkJiaSnp7OAw88wBVXXMFZZ53FmDFj+PLLL/nkk0+YP3++N+sWERGRANXsMR/z589nzJgxx7x+/fXX8/rrrwPwn//8h+nTp7Nr1y769OnDn/70JyZNmtSk99ejtiIiIoGnOZ/fLRpw6gsKHyIiIoHHtHk+RERERBqj8CEiIiKtSuFDREREWpXCh4iIiLSq0AkfZUfgx+fh49+YXYmIiEhIC53wUVUKcx+GFW/Cwa1mVyMiIhKyQid8xKVCj7Gu/awZ5tYiIiISwkInfABkXuP6mvUOOB3m1iIiIhKiQit89JkIUYlQtBe2fmt2NSIiIiEptMKHzQ6Dr3Dtr3zL3FpERERCVMiEj2qHkxU7D7O07UTXCxs/h5KD5hYlIiISgkImfFRUO7nkXz/yyznFOJIzwFkFa943uywREZGQEzLhIzoiDJvVAkBJvytdL658C/xrXT0REZGgFzLhw2KxEBcVDkB+1wsgzA771sLeVSZXJiIiElpCJnwAxEXaADhitIF+F7heXPm2iRWJiIiEntAKHzUtHwVlVbVzfqx5D6rKTaxKREQktIRU+IivCR+F5VXQ7WyIT4PyAtj4qcmViYiIhI6QCh9xkTXho6warGEw5GrXNzTduoiISKsJrfAR5RrzUVhW5XrBHT62fgdHck2qSkREJLSEVviIrDPmA6BtV+h6JmDAqpmm1SUiIhJKQit81B3z4ZZ5revryrfB6TShKhERkdASmuGjrLr2xX4Xgj0OjuyAHYtMqkxERCR0hFb4qJnno17LR0Q0DLzUta85P0RERHwutMJHQ90uUNv1sv5j16O3IiIi4jOhFT6OHnDq1ukU6NAPqstg7YcmVCYiIhI6Qip8xDc05gPAYoHMKa59db2IiIj4VEiFD/c8H0XlVTidR61mO/gKsNpg9zLI32BCdSIiIqEhtMJHTbeL04CSyqNaP9p0hN4TXPtq/RAREfGZkAofkeFhRNhcl3zMuA+oXWxu1SxwNPB9ERERabGQCh9w1PouR+t5DrRJgtIDsOmrVq5MREQkNIRc+IiPamCuD7cwG2Rc6drXYnMiIiI+EXLho3aW0+N0qwyp6XrZ9BUU7WulqkREREJH6IUPd7dLeQPdLgAdekPn4WA4YPWsVqxMREQkNIRe+Ig6zkRjdbkHnq58Gwzj+MeJiIhIszU7fCxcuJALL7yQ1NRULBYLc+bMOe6xt912GxaLhWeeeaYFJXqXZ8zHicLHgIshPBoObIJdS1upMhERkdDQ7PBRUlJCRkYGL7zwwgmPmz17NkuWLCE1NfWki/OF2m6XE4SPyDjoP9m1v/It3xclIiISQpodPiZOnMif//xnLr744uMes3v3bn7zm98wY8YMwsPDW1Sgt8Udb4r1o7m7XtbOhsoSH1clIiISOrw+5sPpdHLttdfywAMPMGDAAG+/fYsdd3G5o3U5Hdp2g8oi12q3IiIi4hVeDx9PPvkkNpuNu+66q0nHV1RUUFhYWG/zpbgTzfNRlxabExER8Qmvho/ly5fzz3/+k9dffx2LxdKkn5k+fTrx8fGeLS0tzZslHSO+sXk+6sq4GrDAjkVwcKtP6xIREQkVXg0f33//Pfn5+aSnp2Oz2bDZbOzYsYP777+frl27Nvgz06ZNo6CgwLPl5uZ6s6RjuLtdio43z0dd8Z2g51jXftY7PqxKREQkdNi8+WbXXnst48aNq/fa+PHjufbaa7nxxhsb/Bm73Y7dbvdmGSfU6AynR8u8BrZ84wofY34P1jAfViciIhL8mh0+iouL2bJli+fPOTk5ZGVlkZiYSHp6Ou3atat3fHh4OMnJyfTp06fl1XpBXKTrkosqqnE4DcKsjXQP9TkPotpC0R7Y9h30HHfi40VEROSEmt3tsmzZMjIzM8nMzATgvvvuIzMzk0ceecTrxfmCu+UDoKixQacANjsMvsK1r4GnIiIiLdbslo/Ro0djNGPK8e3btzf3FD4VHmYlOiKM0koHhWXVJERHNP5DQ6bATy/Bxs+g9BBEJ/q+UBERkSAVcmu7QBNnOa0rZTAkDwZHJax534eViYiIBL/QDB81c300OtFYXZnXur5qunUREZEWCc3wEdnMJ14ABl0GYRGQtwb2rvJRZSIiIsEvJMOHZ6Kxpna7gGucR98LXPsrZ/igKhERkdAQkuGjyYvLHc292Nzqd6Gq3MtViYiIhIbQDB+RTVzf5WjdR0NcJyg/Atmfe70uERGRUBCa4SOqiSvbHs0aBkOudu1rzg8REZGTEpLho1mLyx3NHT62fgsFu7xYlYiISGgIyfBRO89HM8d8ACR2h65nAgZkzfRuYSIiIiEgNMNHzTwfJ9XyAbUDT7PeBqfTS1WJiIiEhtAMH5EnOebDrd9FEBELh7fDzh+9V5iIiEgICM3wcTLzfNQVEQ0DL3Hta+CpiIhIs4Rk+Ig/2Xk+6nJPt75uDpQXtrwoERGREBGS4cPd7VJW5aCy+iTHbHQeBu37QHUZrPvQi9WJiIgEt5AMH21qJhkDKDrZrheLpXbgqbpeREREmiwkw0eY1UKs/SRWtj1axpVgCYNdS2F/tpeqExERCW4hGT6g7qDTFoz7aNMRek9w7av1Q0REpEkUPlrS8gGQOcX1ddUscLTwvUREREJA6IaPk11c7mi9zoWYDlCSD5vneqEyERGR4Ba64eNkF5c7Wli4a+wHqOtFRESkCUI2fHhlrg+3ITVPvWz6Eor2tfz9REREgljIho/axeW8ME6jY1/ofCoYDlj9bsvfT0REJIiFbvho6eJyR/MsNjcDDMM77ykiIhKEQjd8RHrhUdu6BlwCtijYvxF2L/fOe4qIiASh0A0f3hpw6hYZB/0nufZXvuWd9xQREQlCIRs+4r01z0dd7q6XNR9AZan33ldERCSIhGz48No8H3V1GQVtu0JlEWz42HvvKyIiEkRCN3x481FbN6u19rFbzfkhIiLSIIWPsioMbz6dMuQqwALbv4dDOd57XxERkSARsuHDPeaj0uGkotrpxTfuDD1+4drPesd77ysiIhIkQjZ8xESEYbW49r066BRqF5vLegecDu++t4iISIAL2fBhsVhqu168OegUoM/5EJkAhbtg23zvvreIiEiAC9nwAbUTjRV4c9ApQHgkDL7cta+BpyIiIvWEdvjw9hTrdbnn/Nj4KZQe8v77i4iIBKiQDh/xvup2AUjJgORB4KiENf/z/vuLiIgEqGaHj4ULF3LhhReSmpqKxWJhzpw5nu9VVVXx4IMPMmjQIGJiYkhNTeW6665jz5493qzZazzru/ii5QMg81rX1yx1vYiIiLg1O3yUlJSQkZHBCy+8cMz3SktLWbFiBQ8//DArVqzgww8/JDs7m4suusgrxXqb1xeXO9qgX0JYBOxdBXtX++YcIiIiAcbW3B+YOHEiEydObPB78fHxzJ07t95rzz//PMOHD2fnzp2kp6efXJU+4h7z4bXF5Y4WnQh9zoP1cyBrBqQM9s15REREAojPx3wUFBRgsVhISEho8PsVFRUUFhbW21qLTxaXO5q762X1u1Bd4bvziIiIBAifho/y8nIefPBBrrrqKuLi4ho8Zvr06cTHx3u2tLQ0X5ZUj8/m+airxxiITYWyw5D9ue/OIyIiEiB8Fj6qqqq4/PLLMQyDF1988bjHTZs2jYKCAs+Wm5vrq5KOUTvg1EdjPgCsYTDkate+5vwQERHxTfhwB48dO3Ywd+7c47Z6ANjtduLi4uptrcUzz4cvWz6gNnxs/RYKdvv2XCIiIn7O6+HDHTw2b97MN998Q7t27bx9Cq+pneHUx+GjXQ/ocgYYTlg107fnEhER8XPNDh/FxcVkZWWRlZUFQE5ODllZWezcuZOqqiouu+wyli1bxowZM3A4HOTl5ZGXl0dlZaW3a2+xVhlw6uZebG7l22AYvj+fiIiIn2p2+Fi2bBmZmZlkZmYCcN9995GZmckjjzzC7t27+fjjj9m1axdDhgwhJSXFs/34449eL76lagecVmP4OhD0nwQRbeBwDuzwv78LERGR1tLseT5Gjx59wg9qn3+Ie5G728XhNCitdBBjb/ZfR9NFxMDAS2DFm67Wj66jfHcuERERPxbSa7tEhlsJD7MArTDuA2rn/Fg/ByqKfH8+ERERPxTS4cNisfh2cbmjdT4V2veGqlJYN9v35xMREfFDIR0+oJXm+nCzWCDzGte+5vwQEZEQFfLhI7Y1n3gBGHwlWMIg9yfYv6l1zikiIuJHQj58xEW20kRjbrFJ0Otc136WWj9ERCT0KHxEtdJEY3W5u16yZoKjFc8rIiLiB0I+fNRONNYKYz7ceo+HmA5Qkg9bvmm984qIiPiBkA8fngGnrdXtAhAWDoOvcO1r4KmIiIQYhQ/34nKt2e0CtV0vm76E4v2te24RERETKXy01uJyR+vYDzoNBWc1rH63dc8tIiJiopAPH606ydjRPHN+vKXF5kREJGSEfPiIM2PAqdvAS8EWCfs3wu4VrX9+EREREyh8tPY8H3VFxrtWuwVX64eIiEgIUPho7RlOj+bueln7AVSWmlODiIhIK1L4qBlwWlRRjdNpwriLLmdAQheoKISNn7b++UVERFqZwkfNo7aG4Qogrc5qhSFTXPvqehERkRAQ8uHDbgsjMtz112Ba18uQqwAL5CyEw9vNqUFERKSVhHz4AJNmOa0rIR26j3btZ71jTg0iIiKtROEDkxaXO5pnzo8Z4HSYV4eIiIiPKXxg0uJyR+t7gevR28JdkLPAvDpERER8TOEDk+f6cAuPhEGXu/ZXzjCvDhERER9T+MAP5vpwc3e9bPgEyg6bW4uIiIiPKHxQd8Cpid0uACkZkDQQHBWw5n/m1iIiIuIjCh/UzvVhesuHxVJn4Onb5tYiIiLiIwof1B1wanL4ANe4D2s47M2CvDVmVyMiIuJ1Ch/4wTwfdcW0g77nufY18FRERIKQwgd1B5yaPObDLfNa19fV70J1pbm1iIiIeJnCB7UtH6ZOMlZXj19AbCqUHYJNX5hdjYiIiFcpfFBnzIc/dLsAWMMg40rXvgaeiohIkFH4wI+edqnL/dTLlm+gcI+5tYiIiHiRwge13S4llQ6qHU6Tq6nRrgeknw6GE1bNNLsaERERr1H4AGJrplcHKDJ7orG66s75YRjm1iIiIuIlCh+ALcxKTEQY4EeDTgH6T4KINnBoG+xcYnY1IiIiXqHwUcPvBp0C2NvAgItd+xp4KiIiQaLZ4WPhwoVceOGFpKamYrFYmDNnTr3vG4bBI488QkpKClFRUYwbN47Nmzd7q16f8bu5PtzcXS/rZkNFkbm1iIiIeEGzw0dJSQkZGRm88MILDX7/qaee4tlnn+Wll17ip59+IiYmhvHjx1NeXt7iYn3Jr2Y5rSttBLTrCVUlsG6O2dWIiIi0WLPDx8SJE/nzn//MxRdffMz3DMPgmWee4Q9/+AOTJk1i8ODBvPnmm+zZs+eYFhJ/437c1q/GfIAWmxMRkaDj1TEfOTk55OXlMW7cOM9r8fHxjBgxgsWLFzf4MxUVFRQWFtbbzBDnT4vLHS3jKrCEQe4SOOD/XVgiIiIn4tXwkZeXB0BSUlK915OSkjzfO9r06dOJj4/3bGlpad4sqcn8ttsFIDYZep3j2lfrh4iIBDjTn3aZNm0aBQUFni03N9eUOvx2wKmbu+tl1Sxw+GmNIiIiTeDV8JGcnAzAvn376r2+b98+z/eOZrfbiYuLq7eZIa5mojG/bPkA6DUeottDcR5snWd2NSIiIifNq+GjW7duJCcnM29e7YdjYWEhP/30EyNHjvTmqbzOPc+H3w04dbNFwOArXPsr3zK3FhERkRawNX5IfcXFxWzZssXz55ycHLKyskhMTCQ9PZ177rmHP//5z/Tq1Ytu3brx8MMPk5qayuTJk71Zt9f59YBTt8xrYMkLkP0FlByAmPZmVyQiItJszQ4fy5YtY8yYMZ4/33fffQBcf/31vP766/zud7+jpKSEW2+9lSNHjnDGGWfw5ZdfEhkZ6b2qfaB2wKkfj6dI6g+pp8CeFbD6XRg51eyKREREmq3Z4WP06NEYJ1jkzGKx8Nhjj/HYY4+1qLDW5p7nw69bPsDV+rFnheupl9PucM0DIiIiEkBMf9rFX7hbPvx2zIfbwEvBFgn562HPSrOrERERaTaFjxrx0a7wUVHtpLzKYXI1JxCVAP0ucu1rzg8REQlACh812kTYPD0YRf487gMgc4rr65r/QVWZubWIiIg0k8JHDavVQqzdz+f6cOt6FsSnQ0UBbPjU7GpERESaReGjjoB43BbAaq1t/dCcHyIiEmAUPurw+4nG6hpyNWCBnAVweIfZ1YiIiDSZwkcdATHXh1tCOnQ/27W/aqa5tYiIiDSDwkcdATPXh1vmta6vK2eA02luLSIiIk2k8FFHbctHgISPvueDPR4KdsL2hWZXIyIi0iQKH3XEBdKYD4DwKBh0mWtfc36IiEiAUPioI97ztEsAjPlwy7zG9XX9x1B22NxaREREmkDho464yACZ56Ou1EzoOAAcFbD2A7OrERERaZTCRx0BM89HXRZLbevHyhnm1iIiItIECh91BNSjtnUNvhys4a7VbvetM7saERGRE1L4qMO9uFxAtXwAxLSHPhNc+2r9EBERP6fwUYen5SPQwgfUzvmxehZUV5pbi4iIyAkofNThmWSsvArDMEyuppl6jIU2yVB6EDZ9aXY1IiIix6XwUYe75aPKYVBeFWAzhobZYMhVrn3N+SEiIn5M4aOO6IgwwqwWIIAmGqtrSM1TL1vmQuFec2sRERE5DoWPOiwWS+1EY4E014db+56QPhIMp2vsh4iIiB9S+DiKZ6KxQGz5gDpzfrwNgTZuRUREQoLCx1HiArnlA6D/ZAiPgYNbIPcns6sRERE5hsLHUWoftw2wicbc7G1gwMWu/ZVvmVuLiIhIAxQ+jhIfaCvbNsTd9bJ2NlQUm1uLiIjIURQ+juKZ6yOQw0f6aZDYA6pKYP0cs6sRERGpR+HjKLXruwRw+NBicyIi4scUPo5Su7JtgI75cMu4CixW2PkjHNhidjUiIiIeCh9HcT9qG9BjPgDiUqDnONd+llo/RETEfyh8HCXgH7Wty931smomOAK8JUdERIKGwsdRgip89J4I0e2gaC9s/dbsakRERACFj2ME/DwfddkiYPAVrn3N+SEiIn5C4eMo8e5HbYOh5QNqu16yv4CSg+bWIiIigsLHMWqfdqnC6QyCtVGSBkBqJjirYM17ZlcjIiKi8HE0d7eL04CSyiDoegEYMsX1dcVbWmxORERM5/Xw4XA4ePjhh+nWrRtRUVH06NGDxx9/HCNAPvQiw8OIsLn+WgrLgyR8DLoMwuyQvw72ZpldjYiIhDivh48nn3ySF198keeff54NGzbw5JNP8tRTT/Hcc895+1Q+UzvoNEjGfUS1hX4XuvZXvm1uLSIiEvK8Hj5+/PFHJk2axPnnn0/Xrl257LLLOPfcc/n555+9fSqfca/vEvATjdXlHni65n2oKjO3FhERCWleDx+nn3468+bNY9OmTQCsWrWKRYsWMXHiRG+fymfio4Ks5QOg29kQnwblBbDxM7OrERGREGbz9hs+9NBDFBYW0rdvX8LCwnA4HPzlL39hypQpDR5fUVFBRUWF58+FhYXeLqnZaheXC5IxHwBWq2vg6YInXF0vgy4zuyIREQlRXm/5eO+995gxYwbvvPMOK1as4I033uBvf/sbb7zxRoPHT58+nfj4eM+Wlpbm7ZKaLS4YWz4Ahlzt+rptPhzZaWopIiISurwePh544AEeeughrrzySgYNGsS1117Lvffey/Tp0xs8ftq0aRQUFHi23Nxcb5fUbO7F5YJmojG3tl2g21mAAVkzza5GRERClNfDR2lpKVZr/bcNCwvD6XQ2eLzdbicuLq7eZjb3mI+gGnDqlnmt62vW23CceyIiIuJLXh/zceGFF/KXv/yF9PR0BgwYwMqVK3n66ae56aabvH0qn6ntdgmiMR9u/S4Ee7yr22X799D9bLMrEhGREOP1lo/nnnuOyy67jDvuuIN+/frx29/+ll//+tc8/vjj3j6Vz9QOOA3Clo/wKBh0qWtfc36IiIgJvN7yERsbyzPPPMMzzzzj7bduNe55PoJuwKlb5jWw7D+w4WMo/xtExptdkYiIhBCt7dIAd8tHUI75AEg9BTr2h+pyWPuB2dWIiEiIUfhogHvAaVEwzfNRl8VSu9icul5ERKSVKXw0IGjn+ahr8BVgtcHu5bBvvdnViIhICFH4aIB7no+iimoczsBYjbfZ2nSA3hNc+1kzzK1FRERCisJHA9wtHwDFwdr1ArVzfqyaBY4gbuURERG/ovDRgPAwK9ERYUAQDzoF6DkO2iRB6QHY9JXZ1YiISIhQ+DiOoJ7rwy3MBhlXufY18FRERFqJwsdxBP1cH26Z17i+bv4aivLMrUVEREKCwsdxuFs+jgR7+GjfC9JGgOFwjf0QERHxMYWP4+gYZwcgv7Dc5Epagbv1Y+XbYATp0z0iIuI3FD6OIykuEoC9oRA+BlwM4dFwcDPk/mx2NSIiEuQUPo4jJd4VPvYVhED4sMe6AghAlgaeioiIbyl8HIen5SMUwgfUdr2s/RAqS8ytRUREgprCx3GkxEcBsC8Uul0A0kdCYneoLIb1H5ldjYiIBDGFj+NIrtPyYYTCIEwtNiciIq1E4eM43E+7VFQ7g3uW07oyrgKLFXb8AAe3ml2NiIgEKYWP44gMDyMxJgKAvFDpeonvBD3Guva12JyIiPiIwscJJIfaoFOoHXiaNROcDnNrERGRoKTwcQLJofS4rVufiRCVCEV7YOt3ZlcjIiJBSOHjBELucVsAmx0GX+HaX/mWubWIiEhQUvg4Ac9EY6Ey5sMts+apl42fQclBc2sREZGgo/BxAiE55gMgeRCkZICzCta8b3Y1IiISZBQ+TiA5VFs+ADKvdX1d+ZYWmxMREa9S+DgBd/gIuZYPgIGXQpgd9q2FvavMrkZERIKIwscJuMNHQVkVZZUh9thpdCL0u8C1rzk/RETEixQ+TiDWbiM6IgwIoYnG6nLP+bH6PagKwesXERGfUPg4AYvF4mn9yAvFrpduZ0NcZyg/AtmfmV2NiIgECYWPRrifeMkrLDO5EhNYw2DI1a59LTYnIiJeovDRiNqWjwqTKzGJO3xs/Q6O5Jpbi4iIBAWFj0Z4Wj4KQrDlAyCxG3Q9EzBg1UyzqxERkSCg8NEI9yynITng1M0950fWDHA6za1FREQCnsJHI5LiQnjAqVu/C8EeB4e3w44fzK5GREQCnMJHI1Lio4AQb/mIiIaBl7j2NfBURERaSOGjEUnxdgD2F1VQ7QjhLgd318v6j6C8wNxaREQkoCl8NKJ9jB2b1YLTgP3FIfrEC0CnodChL1SXwdoPza5GREQCmE/Cx+7du7nmmmto164dUVFRDBo0iGXLlvniVD5ntVo84z5Cco0XN4uldsZTdb2IiEgLeD18HD58mFGjRhEeHs4XX3zB+vXr+fvf/07btm29fapW41ndNpTDB8DgK8Bqg93LIH+j2dWIiEiAsnn7DZ988knS0tL473//63mtW7du3j5Nq0pWy4dLm47QewJs/BSy3oZz/2x2RSIiEoC83vLx8ccfM2zYMH75y1/SsWNHMjMzefXVV497fEVFBYWFhfU2f+Np+QjlJ17c3F0vq2aBo8rcWkREJCB5PXxs27aNF198kV69evHVV19x++23c9ddd/HGG280ePz06dOJj4/3bGlpad4uqcXU8lFHz3MgpiOU7IfNX5tdjYiIBCCvhw+n08kpp5zC//3f/5GZmcmtt97KLbfcwksvvdTg8dOmTaOgoMCz5eb63/ohSZrltFaYDTKudO1r4KmIiJwEr4ePlJQU+vfvX++1fv36sXPnzgaPt9vtxMXF1dv8TYq6Xepzd71s+gqK9plbi4iIBByvh49Ro0aRnZ1d77VNmzbRpUsXb5+q1dTtdjEMw+Rq/ECHPtB5OBgOWD3L7GpERCTAeD183HvvvSxZsoT/+7//Y8uWLbzzzju88sorTJ061dunajUd41yznFZWOzlSqkGWQJ05P2aAApmIiDSD18PHqaeeyuzZs5k5cyYDBw7k8ccf55lnnmHKlCnePlWrsdvCaBcTAWjQqceAiyE8Gg5kw67AnEBORETM4fV5PgAuuOACLrjgAl+8tWmS4yM5WFLJvsJy+qf637iUVhcZB/0nwaqZsPItSDvV7IpERCRAaG2XJtLjtg1wd72s/RAqS8ytRUREAobCRxMl63HbY3UZBW27QWURrP/Y7GpERCRAKHw0kbvlI6+gzORK/IjFApk1Y3k054eIiDSRwkcT1bZ8VJhciZ/JuBqwwI5FcGib2dWIiEgAUPhoIk/4UMtHffGdoOdY137WO+bWIiIiAUHho4lSPOFDYz6OMaSm6yXrHXA6zK1FRET8nsJHEyXVjPkoLK+mtLLa5Gr8TN/zIaotFO6Gbd+ZXY2IiPg5hY8mio0Mp43dNS2KWj+OYrPDoMtd+xp4KiIijVD4aIakmmnWFT4a4J7zY+NnUHrI3FpERMSvKXw0Q0p8FKC5PhqUMhiSB4OjEtb8z+xqRETEjyl8NEOSZjk9scxrXV9XvmVuHSIi4tcUPprB/cTLPrV8NGzQZRAWAXmrYe8qs6sRERE/pfDRDEnxavk4oehE15MvACtnmFuLiIj4LYWPZkiJU8tHo9wDT1e/C1X6exIRkWMpfDRDslo+Gtd9DMR1gvIjkP252dWIiIgfUvhoBveA0wPFFVQ5nCZX46esYTDkatd+lrpeRETkWAofzdAuJoLwMAuGAflFWmDuuNzhY8s8KNhlbi0iIuJ3FD6awWq10DFWa7w0KrE7dD0TMGDVTLOrERERP6Pw0UxaYK6J3IvNrXwbnOqiEhGRWgofzeR+3FaznDai/0UQEQuHt8POH82uRkRE/IjCRzO5H7fNKygzuZLWtXV/MbmHSpv+AxExMPAS174WmxMRkToUPpop2dPyEToDTn/ccoDx/1jImL/N54kvNlJW6WjaD7qnW183B8oLfVafiIgEFoWPZnKHj30hMuZj58FS7nhnBdVOg2qnwUsLtnLOPxbw3cb8xn+48zBo3weqy2DdbN8XKyIiAUHho5mS3YvLFQZ/t0txRTW/enMpR0qryEhL4F9TTiE1PpJdh8u48fWl3DFj+Ylne7VYamc8VdeLiIjUUPhoptqWjwoMwzC5Gt9xOg3ufTeLTfuK6Rhr55Vrh3LeoBTm3nc2vzqjG2FWC5+vyWPs3xfwxo/bcTiP83cx+AqwhMGun2F/dutehIiI+CWFj2Zyz/NR6XByqKTS5Gp85x/fbGLu+n1E2Ky8fO1Qz+yuMXYbf7igPx/fOYqMtASKK6p59ON1XPKvH1i7u+DYN4pNgt7jXftq/RARERQ+mi3CZqV9GzsQvI/bfrZ6L899uwWA6RcPIjO97THHDEiN58PbT+fxSQOItdtYtauAi55fxGOfrKe4orr+we6ul1WzwFHl6/JFRMTPKXychOT4mvARhINO1+0p4LfvrwLgljO7cenQzsc9Nsxq4dqRXZl3/9lcMDgFpwH/+SGHc55ewNz1+2oP7HUuxHSAknzYPNfXlyAiIn5O4eMkJMdFAcHX8nGguIJb31xOWZWDs3p34KGJ/Zr0cx3jInn+6lN4/cZTSUuMYm9BObe8uYwfthxwHRAWDhlXuva12JyISMhT+DgJwdjyUVnt5Pa3l7P7SBnd2sfw3JWZhFktzXqP0X068vU9ZzNpSCoAf/5sQ+1A1CE1XS+bvoTiJjymKyIiQUvh4ySkxNe0fARJ+DAMg0c/XsfS7YeJtdt49bphxEeHn9R7RUWE8ccLBxAXaWPD3kI+WFGzqm3HvtBpGDirYfW7XqxeREQCjcLHSXA/+REs3S5vL9nBzJ93YrHAs1dl0rNjmxa9X9uYCH7zi14A/O2rbEorawag1p3zI4gfUxYRkRNT+DgJwbSy7Y9bD/DHT9YD8OCEvozp29Er73vd6V1IS4wiv6iCVxZuc7048BKwRcH+jbB7uVfOIyIigUfh4yR4Wj4CPHzkHipl6owVOJwGk4ek8uuzunvtve22MB6c0BeAlxdsI7+wHCLjof8k1wEr3/LauUREJLD4PHw88cQTWCwW7rnnHl+fqtW4Zzktqqg+dk6LAFFSUc0tby7jcGkVgzvH88Slg7FYmjfAtDHnD0ohMz2BsioHf/96k+tFd9fL2g+hshmr5IqISNDwafhYunQpL7/8MoMHD/blaVpdG7uNWLsNCNzWj5k/72RjXhEdYu28cu0wIsPDvH4Oi8XCH853Pa773vJcNuwthC6joG1XqCiEDZ94/ZwiIuL/fBY+iouLmTJlCq+++ipt2x47Q2agS3Kv8RKgg04/XLEbgLvH9vK05PjC0C6JnD8oBcOA//t8A4bFAkOmuL6prhcRkZDks/AxdepUzj//fMaNG3fC4yoqKigsLKy3BQL3oNO9AdjykZ1XxPq9hYSHWbhgcIrPz/fghL5EhFn5fvMBFmzaDxlXARbY/j0cyvH5+UVExL/4JHzMmjWLFStWMH369EaPnT59OvHx8Z4tLS3NFyV5nXvQaSC2fMzJcrV6jOnTkYToCJ+fL71dNNef3gVwtX5Ux3aCHmNc38x6x+fnFxER/+L18JGbm8vdd9/NjBkziIxsvDl/2rRpFBQUeLbc3Fxvl+QTtS0fZSZX0jxOp8FHK13h4+LMTq123jvH9CIhOpxN+4p5b9mu2oGnWe+A09FqdYiIiPm8Hj6WL19Ofn4+p5xyCjabDZvNxoIFC3j22Wex2Ww4HPU/aOx2O3FxcfW2QFD7uG2FyZU0z8/bD7GnoJzYSJvX5vRoivjocO6qmXjs6bnZFHcbD5EJULgLcha0Wh0iImI+r4ePsWPHsmbNGrKysjzbsGHDmDJlCllZWYSFef+pCjN4JhorDKyWjzk1rR7nD0rxyRMuJ3LNaV3o2i6aA8WVvLRoNwy+3PWNlW+3ah0iImIur4eP2NhYBg4cWG+LiYmhXbt2DBw40NunM00gtnyUVzn4bM1eACa3YpeLW4TN6lkp99Xvt7G/1y9d39jwKZQeavV6RETEHJrh9CS5Wz4OFFdQWe00uZqm+W5jPkXl1aTGRzK8a6IpNYwfkMTwrolUVDuZvjICkgaBowLWfmBKPSIi0vpaJXzMnz+fZ555pjVO1WoSYyKICHP99eUXBcYTL7NrulwmZXbCavXubKZNZbFY+H81E499uGI3e7pf6vqG5vwQEQkZavk4SRaLhaR4OxAYs5weKa3ku+x8oHWfcmlIRloCk4akAvBITn+MsAjYuwr2rja1LhERaR0KHy2Q7B73EQBzfXy2Zi9VDoP+KXH0Too1uxweGN+HCJuVb7ZXk58y1vVi1gxzixIRkVah8NECyfFRQGC0fMxe0fpze5xI57bR3DSqGwBPHxzuenH1e1AdOAN4RUTk5Ch8tEByXGB0u+w8WMqyHYexWOCimu4Of3DHmB4kxkTw/uFelNg7QtkhyP7C7LJERMTHFD5awNPy4efdLh/VTKc+qkd7zyPC/iAuMpzf/KInTqx84DjT9aLm/BARCXoKHy3gGfPhxy0fhmEwuyZ8mDG3R2OuPDWdxJgI/l0yyvXC1nlQsNvcokRExKcUPlogOd7/B5yu2V3Atv0lRIZbGT8gyexyjhEVEcaNp3dlh5HM6rABYDhh1UyzyxIRER9S+GgBd/jYV1iO02mYXE3D3HN7nNM/mdjIcJOradh1I7sSExHGG2U1XS9ZM8Dwz79PERFpOYWPFugYa8digSqHwaHSSrPLOUa1w8knq/YAcHGm/ww0PVp8dDhTTuvC587hlFmi4NA22LnY7LJERMRHFD5aIDzMSvs2/vvEy6ItBzhQXEm7mAjO7NXB7HJO6OYzuuEIi2ZO1WmuFzTwVEQkaCl8tJA/Dzp1r2B7YUYq4WH+fauT4iK55JROvO842/XCutlQUWRuUSIi4hP+/YkUANzjPvb62aDTkopqvlq3D/DPp1wacutZ3VlJL7Y6U6Cq1BVAREQk6Ch8tJC75WOfn7V8fL0+j7IqB93ax5DROd7scpqke4c2TByYwnuO0a4X1PUiIhKUFD5ayNPy4WfhY/ZK10DTyUM6YbGYs4Ltybjt7B586DiDasMKuT/B/k1mlyQiIl6m8NFCnpYPP+p2yS8qZ9Hm/QBM9uOnXBoyuHMCfXr24jvnENcLWmxORCToKHy0UIqn5aPM5EpqfbJqL04DTklPoEu7GLPLabbbR/fwDDx1Zr0DjmqTKxIREW9S+GihJM9EY/6zGqv7KRd/WcG2uU7v0Y79KaPZb8RhLcmHLd+YXZKIiHiRwkcLubtdiiuqKSqvMrka2JJfxJrdBdisFs4fHFhdLm4Wi4VbR/dhjuMMAKqXv2lyRSIi4k0KHy0UY7cRG2kD/GPch3s69dF9OpAYE2FyNSfv3AHJLI6dAIB181dQvN/kikRExFsUPrwgxU+eeHE6Dea4n3IJ0C4XtzCrhfG/GEOWswdWo5rqLC02JyISLBQ+vCDJT2Y5XbbjMLuPlNHGbmNcP/9bwba5Jmd24svwcQCULHlDi82JiAQJhQ8vcLd8mB0+5mS5ulwmDkwmMjzM1Fq8wW4LI3nUFMqNcOKLt+DYtcLskqQBj360lnFPL+BAsf8MuhYR/6bw4QUp8VEAZOUeMa2GaoeTL9fmAXDRkMAcaNqQy0YNYK7Ftdjc7u9eMbkaOVp2XhFvLN7BlvxiPsraY3Y5IhIgFD684LxBKYRZLczbmM/CTeYMjFyy7RCHSipJjIlgZPd2ptTgC23sNsoGXAlAu5yPMSpLTK5I6np5wVbP/lc14VdEpDEKH17QJzmW60d2BeDRj9dRUe1o9Ro+W7MXgPEDkrD5+Qq2zTV2wqXsMjoQY5SyecEss8uRGrsOl/LRqtrWjqU7DrG/SF0vItK44PqUMtE95/SiQ6ydnAMlvPZ9Tqueu9rh5Kt1rt86zxuU0qrnbg3tYqPYlHIRAFXLNOeHv3jt+xwcToNRPduR0Tkew4C56/eZXZaIBACFDy+JiwznD+f3A+C5bzeTe6i01c79U46ry6VtdHhQdbnU1XfCr3EaFgZUZLFhw2qzywl5h0oqmbV0J+BaDHD8wGQAvlynrhcRaZzChxddlJHKiG6JlFc5efzT9a123toul+Sg63JxS+3ah81thgJw+KM/UJnzA1QHXxP/6z/k8MhHa6msdppdygm98eN2yqucDOwUxxk92zNhgCt8/LjlAAVl5s/0KyL+LTg/qUxisVh4fPJAbFYLX6/fx3cb831+zmqH0zPQ7/zBwdflUlf86TcBcHr5AiLeOA9jemf493iY+yhkfwGlh0yusGUOlVTy+GcbeHPxDt5cvN3sco6rpKKaN2rqu+3sHlgsFrp3aEPvpDZUOw2+3aiuFxE5MYUPL+udFMtNZ3QD4I+frKO8yreDT3/KOcTBIO9ycUseeRVbTn2cr5zD2W/EYXFUQu4S+OEZmHklPNUNnh8OH98FWTPh0LaAmpjsm/X7cDhd9f5z3ma/nTdj1tJcjpRW0aVdNBMH1gZed+vHl3rqRUQaofDhA3eN7UVSnJ0dB0t5ecE2n54rFLpcPKxWep5/F/YpMxhV/TJnVzzNW0kP4sy8Dtr3dh1zIBtWvAFzboNnM+HvfeDda2Hxv2D3CnD4b5eAe7yE1QJF5dX8/etNJld0rMpqJ//+3vXf9K/P6kGY1eL53oSaILJg035KK6tNqU9EAkOQf1qZo43dxh/O7w/Av+ZvYedB3ww+rdvlEoxPuRzP6D4defGaoeyxpvDwjgzuLbsJxx0/wwPb4MqZcPpdkDYCrOFQvA82fAxfTYNXx8AT6fDGhfDtX2DLPCgvNPtyACgqr2LR5gMAPD55IACzlu5k3Z4CM8s6xser9rCnoJz2bexcckr99YP6pcSSnhhNeZXTtPluRCQwKHz4yAWDUxjVsx0V1U7+9Mk6n5zj55oul4TocEb2CO4ul6ON7ZfEC1efgs1q4aOsPfzuf6txRiVC3/Pg3Mfh5q9hWi7c+AWMfRR6jYfIBKgqhZyFsPApePsSeLILvHQGfP4ArPkfFOw25Xq+y95PpcNJ9w4xXD08nQsGp2AY8Ngn6zH8pOvI6TQ8k4rdfEa3Y6bwt1gsTBiorhcRaZzCh49YLBb+dNFAwsNcM59+44P5DzxdLv2TCQ/2LpcGnDsgmeeuyiTMauGDFbuY9uEanM46H9ThUdDldDjzPpjyHvwuB+5YAhf8AwZfCQldwHBC3hr4+RX44Gb4R3/4xyD44Few9DXIWwtO308a9+Va172cMCAZi8XCtPP6YbdZ+SnnEF/4yQf5vI35bM4vJtZuY8pp6Q0eM75m3Me8DfmmTLYnIoHB659Y06dP59RTTyU2NpaOHTsyefJksrOzvX2agNCzYxtuPqM74P3Bp3XXcjkvyJ9yOZGJg1J45oohWC3w7rJc/vDR2uO3FFit0LEfDLsJLnkZ7lkN922EX74OI26DlCFgsULBTljzPnx2P7w0Cp7sBm9fBgv/CtsXQaV3u9HKqxx8t9HVTeFuOeiUEMVtZ/cA4C+fbfD5wOXGGIbBi/O3ADDltC7ERYY3eFxmWgIdY+0UVVTz49aDrVmiiAQQr4ePBQsWMHXqVJYsWcLcuXOpqqri3HPPpaQkNNfkuGtsT1LjI9l1uIx/zd/a+A80Ud0ul9NDrMvlaBdmpPL3yzOwWOCdn3by6Mfrmt5VEZcCAy6GiU/CrxfAQ7lw3Ucwehp0Hw0RbaCiALbMhW//DK+fD0+kwatj4av/Bxs+geKWjW9YuGk/ZVUOOiVEMahTvOf1287uQUp8JLuPlPHqQt8OXG7M0u2HWbHzCBFhVm4a1fW4x1mtFk/rh9Z6EZHjsXn7Db/88st6f3799dfp2LEjy5cv56yzzvL26fxedISNhy/oz+0zVvDSgq1cktmJru1jWvy+od7lcrSLMztT7TD43QereXPxDmxWKw9f0A+LxdL4D9dlb+MKHd1Hu/7sqIZ9a2HnEtdjvTuXQNFe2L3MtS1+3nVcYg9IHwnpI1xf2/WEJp7b/ZTL+JouF7eoiDCmndePu2au5F/zt3LZsM6eFZRb20s1Yz0uHdqZjnGRJzx2wsBk3lqyg6/X7+MvFxv1nogREQEfhI+jFRS4RusnJib6+lR+a8LAZM7s1Z7vNx/gj5+s4783nNr8D8U6HE6jdi2XEO5yOdovh6XhcBo89OEa/vNDDuFhFh6a2LdFf9eE2SB1iGs77TbXvCFHdtYPI/nr4dBW15b1tuvnottB2mmQXrOlDAFbxDFvX1nt9IwHcne51HXh4BTe/HE7y3Yc5skvNvLMlZknfy0nacPeQr7dmI/VAr8+q3ujxw/vlkhCdDiHSipZuv0QpwX5/DMi0nw+DR9Op5N77rmHUaNGMXDgwAaPqaiooKKidjKlwkL/ePTRmywWC49NGsj4fyxkfvZ+vl6/z9M0fTJ+yjnIgWJ1uTTkyuHpVDsN/jBnLS8v3EaEzcr95/bx3gksFmjbxbVlXOF6reww5C6FnYsh9yfYtQxKD0L2Z64NwBYJnYa6HgFOHwlpp0JUW5ZsO0hheTXt20QwtEvbBk5n4dELB3DRC4uYk7WHa0d2bfA4X3I/4TJxYEqTWu3Cw6yM65fE/5bv4su1eQofInIMn7bXT506lbVr1zJr1vGXQZ8+fTrx8fGeLS0tzZclmaZb+xhurfmt8bFP1rdoEqbPa7pczu2fpC6XBlxzWhf+dNEAAJ77dovv58qIagu9z4Vxj8KNn7se8b15LpzzOPQ539UKUl0OO36ARU/DO7+EJ7vCv0Zi/+q3TLYu4pc9DcKO00AzqHM8lw91/bt47JN19Z/o8bHcQ6V8str135t7AGxTuGc7/Wpdnt88Kiwi/sNnn1x33nknn376Kd999x2dO3c+7nHTpk2joKDAs+Xm5vqqJNNNHdOTTglR7D5SxnPfbjmp93A4jdqnXEJoYrHmuv70rlxQ0yX1ohcH+jaJzQ5pw2HUXXDVO/DAVrhzGVz0HAy5xjU+BCB/PSMOzuGZiH/x4MZfwtP94P0b4KeXYU+Wa7xJjd+O70Mbu41Vuwr4cGXrzUXy2vfbcDgNzujZnkGd4xv/gRpn9GpPdEQYewvKWb3LvyZKExHzeT18GIbBnXfeyezZs/n222/p1q3bCY+32+3ExcXV24JVVEQYj17omvn05QVbPTNaNoe7yyU+KpxRPdt7u8Sgcvto14f852v2sv2AiU9bWSzQvhecch1MfgHuWgG/3czm0S/xavV5rKYXhtXmGsi6bjZ88Tt45WzXBGhvToL5T9Ah/0fuPSsVgCe/3Ehxhe+nLz9YXMG7y1y/DLj/LpsqMjyMMX07ArUDakVE3LwePqZOncrbb7/NO++8Q2xsLHl5eeTl5VFWVubtUwWkcwckc/mwzjgN+M3MFew+0ry/l889a7moy6UxA1LjGd2nA04DXjb5UdVjtOnIzKIM/lJ9Da/3ew3LQ7lw/afwiz9Az3Fgj4PKYtg2H+ZPh7cmc9Ois/kq+mHuKHuFb/73MhTu9WmJb/y4nfIqJ4M6xZ/U2KK6C82p60VE6vL6gNMXX3wRgNGjR9d7/b///S833HCDt08XkB6bNJANe4tYs7uA299eznu/HnnMVNUNcXW5uJ6MUJdL09wxuifzs/fzwfJd3DOuF0mNPCbaWgyj9oml8QOTISIaup3p2sA1q2r+htpBrDuXYCnIpY+xlT62rbD5K3j6965ZWus+4tu+j2sytaOUVlazelcBbew20tpGExdlO+FTQCUV1byxeAfgavU4mSeGxvTtSITNSs6BEjbnF9M7KbbZ7yEiwcnr4UO/4TQuMjyMf005hQufX8TqXQX88eN1PHHp4EZ/7uecQxworlCXSzMM75bIsC5tWbbjMP9elMPvz+tndkkArN1dyO4jZUSFh3F27w7HHmANg+SBrm34La7XCnZh7FzCN199RGrhKvpZd2I9sgOO7IDVNYO6IxMgbQTOtNPYGjWQbwpSmb+1iBU7D1PlqP23GWu30Tkxms5to0hr6/rauW0UaTWvvbs0l4KyKrq1jznpJ7Pa2G2c1as932zI58u1eQofLWQYBvuLK+gY6x8BOliVVzn4OGsP4wckEx/d8Ey+0nI+n+dDGpaWGM2zV2Zy/X9/ZtbSXIakJXDl8IbXy3D7bM0eQE+5NNcdY3pw0+vLmLFkB1NH9/SL/6F8UbOWy5i+HZrU6gVAfGcsgy6ja8fxTPjn90Q5S5h1no2B1eth52Kcu5ZhLT8Cm7/CuvkregHpho3hRjeWWvqwtc1AVhi92VoSSVFFNRv2FrJhb8OPtrsbOm49q3uLJgkbPyDZEz7uGtvrpN8n1DmdBlPfWcEXa/O4e2wv7j2nt9klBa2nvszmPz/k8NW6PP59w6lmlxO0FD5MdFbvDvz23D789atsHvloHf1S4shIS2jw2HpdLppYrFnG9OlI3+RYNuYV8cbi7aZ/CBpG7RNLJ9Oq0CsplmtP68LrP27n7qUxDO92EYvyR7K3uIj+lh0Ms25imDWb4WHZtLcUMNSymaHWzVD9KQDOTr0o6jiMPbEZZEcMYENFe3KPlLHrsGs7VFKJYUBaYhQXZ3Zq0bWO65dEmNXC+r2F7DxYSnq76Ba9X6j669fZngUG/zlvM5HhYc0eBCyN219UwTs/u7ob523MZ+n2Q5zaNXQnyPQlhQ+T3X52D7JyjzB3/T5uf3s5n/zmDNq1sR9znLvLJS7Sxqge6nJpDovFwu2je3D3rCz++0MOvzqzG9ER5v2nvyW/mG0HSogIs/KLmidCmuvecb35KGs3W/eXsHW/60kemzWcyPRTSeg1keRe7UlIjYPCHa5ZWN3bgWysBzcTf3Az8cykHzA5poNrFtZTToP0kRQn9mdPUTVJcZFNb5U5jrYxEZzWPZEfthzky3V7ufUsfWA21+yVuzyPi48fkMRX6/bx5JcbiQq3csOoEz9NKM3z70U5lFc5sVhckxk/8cVG/nfbyJbNkiwNUvgwmdVq4e+XZzD5+R/YdqCEu2at5M2bRhzT1O2ZWGxAMhE2dbk01/mDUvj715vYeaiUWT/nctMZ5v1P293qcUav9sQeZ3XYxsRHh/PkpYN5ZeE2BnaK58xe7RnRvR1t7Ef9k07s7tqGXO36c+mhmgGsi11hZM9KKNnvWiBvwycAtLFF0bvzsNqp4TufCpFNn+PjaBMGJLvCx9o8hY9mWrHzMA9+sAaAO0b34HcT+vL019k8++0W/vjJeiLDwxrtrpWmOVxSyVuLtwPwl8mDeOzTdSzfcZhvNuRzTv8kc4sLQgoffiAuMpyXrh3KpOd/4IctB/nb19k8OKGv5/sOp+Fpcj1fXS4nxRZm5ddnd+f/zV7Lq99v45rTupgW4tz3ckILptgHVxA9t7nvEZ0IfSa6NoCqclcAya3TOlJ+BLZ/79oAsEDSwNonatJGQELTZyI+d0AyD3+0jhU7j7CvsNxvnjjyd3uOlHHrm8uprHZyTv8kfluzTMC95/SmrMrBq9/nMG32GiLDw5jcwu4xgf/+uJ2SSgf9UuK4angauYdLeXH+Vv761UZ+0bejFkj0Mv0K7Sd6J8Xy1GWuJ15enL/V89sxwNLt6nLxhktP6UyHWDt7C8qZk9V6s4TWtfNgKev3FmK1wDh/+G0qPBK6jIQz7oWr34Xf5cAdP8EFz0DGVdC2K2DAvjWw9DX44GZ4ZiA8PQD+dzP8/CrkrXE9GnwcSXGRnJKeAMDXmnCsSUorq7nlzWUcKK6gb3Isz1wxBGvNh5/FYuH35/XjmtPSMQy4//1VfLHGt3O+BLvC8ipe/yEHgN/8oicWi4Xbzu5BfFQ4m/YVM7sVZxUOFQoffuTCjFRurukO+O37q9iSXwzAZ6vV5eINkeFh/Krm7/elBVtxtOIaKW7uuT1GdGtHYsyxq9yazmqFjn1h2I1w8Utw9yq4Pxt++QaMuB1SM8ESBoW7YO3/4PPfwktnuNaqeesSWPBXyFkIlfVnlHWv2KvZThvndBrc/94q1u0ppF1MBK9dP4yYo7rTLBYLj100kMuGdsbhNLhr1kq+25hvUsWB763FOygsr6ZnxzaeFsn4qHDPoN5/zN1EedXxA7Y/aMl6YWbQJ5mfeWhiX4Z3S6S4oprb3l5OYXlVbZeLJhZrsatHpBMXaWPb/hJTfgt3f/hOHNSyLpdWFZsMAybDxCfg1vnw0E647iMY/XvoPgYi2kBFIWydB9/9Gd64EJ5Ih1fGwJe/h/UfM7Gba+Dqkm2HOFxSaerluFVU++eHyT/nbeaLtXmEh1l46dqhdG7b8BNCVquFJy8dzAWDU6hyGPz67eX8sKX5SzaEutLKal773jUD8p1jenpamABuOL0ryXGR7D5SxttLdphVYqN2HCzhrKfmM+vnnWaX0mQKH34mPMzKC1efQlKcnS35xVzx8pLaLhdNLNZisZHhXDeyKwD/mr+1VSfFyy8sZ/mOwwCc2z+AwsfR7G2g+2gY/SBcNwce3AG/XggTn4IBl0BsKjirYc8KWPICvHctaf/O4Ifo+3ky7EW2ffkcbPwcdvwI+9ZD4R6oLHU9XtAKHDVzZmQ+NtfTqugvPl29h3/O2wzA/108qNHHPMOsFv5xxRDO6Z9EZbWTX72xjGXbD7VGqUHjnZ92cri0ii7toj2LUbpFhodxzzjXo/kvfLeFovIqM0o8oZKKam59czkHatZiqnY4zS6pSTTg1A91iLXzrylDufKVxZ5JoM7pry4Xb7lxVFdeW7SNNbsLWLTlAGf2amCGUR9wd7lkpieQHB9Egy7DbJCS4dpG/NoVIgpyawawLoadP0H+ejo593JZ2F5YsxDWNPQ+Ea6naiITICqheV8jYmpnRmvEU19u9ISOu2etJCrCyi/6mj/+ZvWuI9z/3ioAbjmzG78c1rRBveFhVp6/OpNfvbGM7zcf4Ib/LmXGr0Ycd84gqVVe5fCs+3TH6B7YGpi88bKhnXnl+21s21/Cqwu3cV/NwF9/YBgGv31/Fdn7iugQa+ela4Y2eA3+SOHDTw3t0paHL+jPIx+tAzgmkcvJa9fGzpWnpvP6j9t5cf7WVgsfni6XgQHc6tEUFgskpLu2wZe7Xis7wq41C5jz8QcMtm5nVCcrYRUFUF4AZUfAcICj0vXYb8n+5p/TamtScPlxdzWrFx+gvyWGTikpLN7j4La3l/P6jcM53cTB3PsKy7nlzWVUVDsZ3acDD01s3jIAdlsYr1w7jBv++zM/5Rziuv/8zKxbT6NfirmrhBeVV7Fy5xFO697OL395em9ZLvuLKuiUEMXFmZ0bPMYWZuWBc/tw+4wVvLYoh2tHdqVD7LFzMZnhX/O31nbRXTM0oJ4kU/jwY9ee1oXDJVXsLSjjzF7qcvGmW87qzttLdvDj1oNk5R5hiI9/SzxcUsmSba7m8JNdKyWgRSXQ6dSL+GBhPH87UMK9PXrzm1/U9K8bhmsF37Ijrsd8m/rVHVycVa5untKDru0ETgdOd4/zPQREgsOwUPRmDOVx7YiMTWxGi0s82OMbXMivOcqrHNz65jL2FVbQs2Mbnr0q86Qe64yKCOPfN5zKtf/+iZU7j3DNaz/xx4sGMLhzPOmJ0a06UVaVw8msn3fyzDebOVhSyZm92vPqdcNaPGmdN1VWO3mpZvK2287ufsJwNGFgMhlpCazKPcLz327mT5MGtlaZx/Xdxnz+9nU24FqsdGiXtiZX1DwWw89WgissLCQ+Pp6CggLi4sxN7RLc7n9vFR+s2MW5/ZN45bphPj3X+8tyeeB/q+mXEscXd5/p03P5sxe+28Jfv3L9DzOjczyPTRrYsu4Bw4Cq0kaDSknBAVZmbyfKWUSqvZJkezmWsiPgqGjZBWGByLiT6yqKjMewWLl7VhYfr9pDQnQ4H00dRZd2MS2qqKCsiqtfXcK6PbXr9sRG2uifEseA1HgGpMYxoFMcPTu08XoTvWEYfLMhnye+2OCZedftjJ6uABIV4R8B5N2lO3nwgzV0jLWz8HdjGg1GP249wNWv/kR4mIV59402damAbfuLmfTCDxSVVzNlRDp/uXiQabXU1ZzPb4UPCVlb8os45x8LMQyYe+9Z9PLhqqs3v76UeRvzuXdcb+4eF7oLrDmcBq//uJ1/zN1EcUU1FgtceWoaD4zv67NHj0sqqrn0xR/ZmFdE/5Q4/nf7yNrp9avKKCs8wLR3FrFrzx46R1UybXQySRHljbe4VJe1uLZyawwHHFEUGq5uoPjEDicILG1rW1wiE1xjbY7jcEkl/5y3meU7DpOdV0RlA4MQ7TYrfZNj6V8TSIZ2aUvf5NiTbiFZs6uAv3y+3tPClxgTwT3jetGzYxt+9cYySisdnN6jHf++/lTTA0i1w8kv/r6AnYdK+cP5/fjVmd2b9HPX/ednFm7az6QhqfzzykwfV9mwovIqLv7Xj2zJL2ZYl7a8c8tpftOlpfAh0kS/fmsZX63bxyWndOLpy4f45BzFFdWc8thcKh1Ovr73LC0tD+QXlfPE5xv5sGbypoTocH57bh+uGp7u1ZkknU7XI6hz1++jfRs7H985itSEqGOOKyx3tRas3V1Iclwk7982krTERn6zrSp3BZEmdhU5Sg9TWXIYa3kBdqPlwYWINk1qYam2x5Fbaie7wMKag1ZW5BusySujuOLYeSGS4uyc3bsDo/t0ZFTP9sRHNT79/+4jZfztq2zPRFwRNis3n9GN20f3IK5m+YCl2w9xw39+pqTSwcju7fj3DcNMXV9p9spd3PvuKhJjIlj04Jgm17J2dwEXPLcIgM/uOoMBqSe/7MDJcDoNbnt7OV+v30dyXCQf/2YUHWP9Z5yHwodIE63KPcKkF37AZrUw/4HRx51ToSU+WbWH38xcSff2Mcy7/2wtUlXH0u2HeHjOWjbmFQEwqFM8f5o0gFPSvdN//eSXG3lx/lYibFZm3XraCd/3UEklV7y8mM35xaQlRvH+r09v0VNJTqfBuj2FfJedz/zsfLJyj+Ce1y6capIjyjk7PYIJPe2c0Sm8kQBTJ+RUFp10TW5GeDSOiHhKw9pQYMSQXxXFztIIDjmjKTBiKCCGIksMHdon0btrZwb37EKPtM5Yo9u6ZsXFFdhenL+Vfy/KobLa1bJycWYn7j+3d4P/jpbvOMT1/1lKcUU1p3VP5D83nGpKAHE6Dc75xwK27i/hgfF9mDqmZ7N+/jczV/LJqj2M7tOB128c7qMqG/bPbzbzj282ERFm5b3bRvp8rFpzKXyINMOU15bww5aDXD+yi08Gkk19ZwWfrd7L7aN71FuzR1yqHU7eXrKDv3+9iaKa38YvH9aZByf0bXCF56Zy/3YL8MwVQ5q0/sm+wnIuf3kxOw6W0qNDDO/9emSzajhcUsn3Ww4wPzufhZv2c6C4/oRqvZPaMLpPR0b37sCwrokn11zuqD6qxeVwE4NLAVQUNP98R5/eaqfCFsuBShvFTjsl2AmPiqVbSkfi4xMgPNr16HNEG4io2Q+PgYgYNh0x+NOX2zlQaaNn52Seuuo0YtrEQ3hUkx+VbqnP1+zljhkriIu08cNDv2j24o7bD5Qw7ukFVDsNZt16Gqd1b+ejSuubu34ft7y5DICnLhvM5U18FLs1KXyINMMPWw4w5bWfsNusPHHpIMb1Szrp1Wbrqqh28P2mA9w1ayWllQ4+mjpKcy+cwP6iCp74YiMfrNgFQFykjd+O78OUEV2a3RWzYudhrnxlCZXVTs9qsE2Ve6iUy19ezN6CcvqnxDHz1tOO2/1Q7XCyatcRFmw6wIJN+1m960i9udJiIsIY1bM9o/t05Ow+HejUQJdPq3I6mtxVVF50iJKCAzhKj2CvKiSWUqwWX31cWGoCS0xNeKkTXOqEl3qb57iYmmPbHBt8wqPrhRrDMDjv2UVs2FvI3WN7ce85vU+q2ofnrOWtJTsYkpbA7DtO93lr5pb8Yia/8APFFdU++yXJGxQ+RJrBMAwuffFHVuw8AkBEmJWzenfg/MHJjO2X5Om3boryKgcLN+3n8zV7mbch3/ObfFpiFAsfGKMulyZYvuMQD89Zx/qaCfbat7FzTv8kxg9IYmSPdthtJx6suPtIGZOe/4EDxRWc0z+Jl68ZWm/K7KbYtr+Yy19ezIHiSk5JT+Ctm0d41lfZW1DGwk37WbBpP4s2H6CwvP7Yib7JsZzduwNn9+nAsC4n2brhZyqqHSzLOcji9Tms2rydiOpifpnRjnE9YrBVl7pmqK0sdj15VFlSf6uq+V5liee4qvISqsqKiLa09GmjxljqBJIYipwRZB82qLBEcmrvNCKiYuuEnDb1jj1R8Mkvt3D2XxdSVuXgpWuGetYu8oXC8iomP/8D2w6UMLxbIjN+NYJwP51ITOFDpJkOlVTy3x9y+GzNXrbVeUTQFUTac96gFMb1bziIlFc5mJ+9ny/WugJH3YF8SXF2Jg5M4ZrTutCzY5tWuZZg4HAavPPTDv4+dxNHSmuntI612xjdtyPjByQxuk9H2hy14FppZTWXvbiY9XsL6Zscywe3n37MomxNtWFvIVe+soSCsipO657IwNR4Fm7ez6Z9xfWOi48K54xe7Tm7dwfO6tUhuGav9aGs3CNc9+/FVJeXcnpnO/+8tDcxlooGwktJveBSG2hOcFxVSeMFtFClNYoCRwRV1ihSOrTDcnRoOV7rTIOtOzXBJzy63rwxTqfBLW8uY97GfFLjI/n4N2fQvgVdkb6m8CFykgzDIHtfEZ+v3stna/bWm6ugbhA5o1d7Vuw4zGdr8vh2wz5KKmsXKUuJj2TiwBTOH5xMZlrbZv/WLbUqq50s3naQr9fl8fX6fewvqv1NOSLMyqie7Rg/IJlx/ZNIjI7gjhkr+HJdHu3bRDBn6qgWDyDOyj3ClFeX1Lu/VgtkpCW4wkbvDmR0TvDqEzqhZPUu12RoheXVDO3SltdvPNUrXZ44na6A4ml1KSVr627+/tkK4sMqmX5Bd2KtlScXcHytTuvL/gobO4stlBPJwG6pjY6pOW7wOSrU+IrCh4gXGIbBpn3FfLZmL5+v2cuW/OLjHtspIYqJA5OZOCiFzLQEBQ4fcDoNsnYd4at1eXy9bh85B2o/CCwW6NY+hm37S4gIszLz1hEM7XLiRdma6uecQzzxxQZ6dGjD2X06cEbP9iRE+2ZOklC0ZlcB1/z7JwrKqshMT+DV64b55Lf7y19azM/bD3HTqG48cmH/k3sTp9M1v0tNSPlwSTZvf7+BaEsF0ZQTTQUxlnKiqCCGcqIsrq/RlprveV6rc1zNVys+/ih2t6x4gksM3Py1Vwf6KnyI+MCmfUV8uro2iHRKiOL8wSlMHJjMkLQEjedoRYZhsCW/mK/W5fHVun2s2V37FMfffpnBZUMbXqdD/NPa3QVMec0VQADaRofTpV0MXdtF07V9DF3bxdClXTRd28WQEB3epH9rFdUOCsuqKSqvYvWuAu55N4uIMCvfPzjGa2ugVFQ7+OPH68k5UExltZNKh9P11b05nFTU2T/+p61BJJX1AwsVRFvKuahfPFdktPO04LhaYY43vqZuC07NcccLNeHR8P+8u6qzwoeIjx0prSQ+qmn/ExTf23OkjHkb80mMjuB8LcIYkNbuLuDuWSuPmZb9aHGRNrq2j6FLuxja2MMoLK+msKyKovJqCsurPIGjovrYWV2vOS2dP082ZypywzCodhr1gklldf1wUvs9B5XVThKiIxjRLfHk/z9jGFBd3nBIcVRBr3O8eo0KHyIiEpBKKqrZcbCUHQdLyDlYwo4DpWw/WMKOg6XkFZY3670sFmhjtxEXGU6ntlE8d1VmQK38Gmia8/mtVW1FRMRvxNht9E+No3/qsR9eZZUOdh5yhZHtB0oor3ISH2UjNjKcuKhw4iLd+zbiosJpE2HT+Cs/pfAhIiIBISoijD7JsfRJ1vpIgc4/ZyoRERGRoKXwISIiIq1K4UNERERalcKHiIiItCqFDxEREWlVCh8iIiLSqhQ+REREpFUpfIiIiEir8ln4eOGFF+jatSuRkZGMGDGCn3/+2VenEhERkQDik/Dx7rvvct999/Hoo4+yYsUKMjIyGD9+PPn5+b44nYiIiAQQn4SPp59+mltuuYUbb7yR/v3789JLLxEdHc1//vMfX5xOREREAojXw0dlZSXLly9n3LhxtSexWhk3bhyLFy8+5viKigoKCwvrbSIiIhK8vB4+Dhw4gMPhICkpqd7rSUlJ5OXlHXP89OnTiY+P92xpaWneLklERET8iOmr2k6bNo377rvP8+eCggLS09PVAiIiIhJA3J/bhmE0eqzXw0f79u0JCwtj37599V7ft28fycnJxxxvt9ux2+2eP7uLVwuIiIhI4CkqKiI+Pv6Ex3g9fERERDB06FDmzZvH5MmTAXA6ncybN48777yz0Z9PTU0lNzeX2NhYLBaLV2srLCwkLS2N3Nxc4uLivPre/iDYrw+C/xp1fYEv2K8x2K8Pgv8afXV9hmFQVFREampqo8f6pNvlvvvu4/rrr2fYsGEMHz6cZ555hpKSEm688cZGf9ZqtdK5c2dflOURFxcXlP9BuQX79UHwX6OuL/AF+zUG+/VB8F+jL66vsRYPN5+EjyuuuIL9+/fzyCOPkJeXx5AhQ/jyyy+PGYQqIiIiocdnA07vvPPOJnWziIiISGgJqbVd7HY7jz76aL0BrsEk2K8Pgv8adX2BL9ivMdivD4L/Gv3h+ixGU56JEREREfGSkGr5EBEREfMpfIiIiEirUvgQERGRVqXwISIiIq0qpMLHCy+8QNeuXYmMjGTEiBH8/PPPZpfkFX/84x+xWCz1tr59+5pd1klbuHAhF154IampqVgsFubMmVPv+4Zh8Mgjj5CSkkJUVBTjxo1j8+bN5hR7khq7xhtuuOGYezphwgRzij0J06dP59RTTyU2NpaOHTsyefJksrOz6x1TXl7O1KlTadeuHW3atOHSSy89ZlkGf9WU6xs9evQx9/C2224zqeLme/HFFxk8eLBnIqqRI0fyxRdfeL4fyPcPGr++QL9/R3viiSewWCzcc889ntfMvIchEz7effdd7rvvPh599FFWrFhBRkYG48ePJz8/3+zSvGLAgAHs3bvXsy1atMjskk5aSUkJGRkZvPDCCw1+/6mnnuLZZ5/lpZde4qeffiImJobx48dTXl7eypWevMauEWDChAn17unMmTNbscKWWbBgAVOnTmXJkiXMnTuXqqoqzj33XEpKSjzH3HvvvXzyySe8//77LFiwgD179nDJJZeYWHXTNeX6AG655ZZ69/Cpp54yqeLm69y5M0888QTLly9n2bJl/OIXv2DSpEmsW7cOCOz7B41fHwT2/atr6dKlvPzyywwePLje66beQyNEDB8+3Jg6darnzw6Hw0hNTTWmT59uYlXe8eijjxoZGRlml+ETgDF79mzPn51Op5GcnGz89a9/9bx25MgRw263GzNnzjShwpY7+hoNwzCuv/56Y9KkSabU4wv5+fkGYCxYsMAwDNc9Cw8PN95//33PMRs2bDAAY/HixWaVedKOvj7DMIyzzz7buPvuu80rygfatm1rvPbaa0F3/9zc12cYwXP/ioqKjF69ehlz586td01m38OQaPmorKxk+fLljBs3zvOa1Wpl3LhxLF682MTKvGfz5s2kpqbSvXt3pkyZws6dO80uySdycnLIy8urdy/j4+MZMWJE0NxLt/nz59OxY0f69OnD7bffzsGDB80u6aQVFBQAkJiYCMDy5cupqqqqdx/79u1Lenp6QN7Ho6/PbcaMGbRv356BAwcybdo0SktLzSivxRwOB7NmzaKkpISRI0cG3f07+vrcguH+TZ06lfPPP7/evQLz/w36bHp1f3LgwAEcDscxa8skJSWxceNGk6rynhEjRvD666/Tp08f9u7dy5/+9CfOPPNM1q5dS2xsrNnleVVeXh5Ag/fS/b1gMGHCBC655BK6devG1q1b+f3vf8/EiRNZvHgxYWFhZpfXLE6nk3vuuYdRo0YxcOBAwHUfIyIiSEhIqHdsIN7Hhq4P4Oqrr6ZLly6kpqayevVqHnzwQbKzs/nwww9NrLZ51qxZw8iRIykvL6dNmzbMnj2b/v37k5WVFRT373jXB8Fx/2bNmsWKFStYunTpMd8z+99gSISPYDdx4kTP/uDBgxkxYgRdunThvffe4+abbzaxMjlZV155pWd/0KBBDB48mB49ejB//nzGjh1rYmXNN3XqVNauXRvQ45BO5HjXd+utt3r2Bw0aREpKCmPHjmXr1q306NGjtcs8KX369CErK4uCggL+97//cf3117NgwQKzy/Ka411f//79A/7+5ebmcvfddzN37lwiIyPNLucYIdHt0r59e8LCwo4Zxbtv3z6Sk5NNqsp3EhIS6N27N1u2bDG7FK9z369QuZdu3bt3p3379gF3T++8804+/fRTvvvuOzp37ux5PTk5mcrKSo4cOVLv+EC7j8e7voaMGDECIKDuYUREBD179mTo0KFMnz6djIwM/vnPfwbN/Tve9TUk0O7f8uXLyc/P55RTTsFms2Gz2ViwYAHPPvssNpuNpKQkU+9hSISPiIgIhg4dyrx58zyvOZ1O5s2bV69/L1gUFxezdetWUlJSzC7F67p160ZycnK9e1lYWMhPP/0UlPfSbdeuXRw8eDBg7qlhGNx5553Mnj2bb7/9lm7dutX7/tChQwkPD693H7Ozs9m5c2dA3MfGrq8hWVlZAAFzDxvidDqpqKgI+Pt3PO7ra0ig3b+xY8eyZs0asrKyPNuwYcOYMmWKZ9/Ue+jzIa1+YtasWYbdbjdef/11Y/369catt95qJCQkGHl5eWaX1mL333+/MX/+fCMnJ8f44YcfjHHjxhnt27c38vPzzS7tpBQVFRkrV640Vq5caQDG008/baxcudLYsWOHYRiG8cQTTxgJCQnGRx99ZKxevdqYNGmS0a1bN6OsrMzkypvuRNdYVFRk/Pa3vzUWL15s5OTkGN98841xyimnGL169TLKy8vNLr1Jbr/9diM+Pt6YP3++sXfvXs9WWlrqOea2224z0tPTjW+//dZYtmyZMXLkSGPkyJEmVt10jV3fli1bjMcee8xYtmyZkZOTY3z00UdG9+7djbPOOsvkypvuoYceMhYsWGDk5OQYq1evNh566CHDYrEYX3/9tWEYgX3/DOPE1xcM968hRz/BY+Y9DJnwYRiG8dxzzxnp6elGRESEMXz4cGPJkiVml+QVV1xxhZGSkmJEREQYnTp1Mq644gpjy5YtZpd10r777jsDOGa7/vrrDcNwPW778MMPG0lJSYbdbjfGjh1rZGdnm1t0M53oGktLS41zzz3X6NChgxEeHm506dLFuOWWWwIqKDd0bYDx3//+13NMWVmZcccddxht27Y1oqOjjYsvvtjYu3eveUU3Q2PXt3PnTuOss84yEhMTDbvdbvTs2dN44IEHjIKCAnMLb4abbrrJ6NKlixEREWF06NDBGDt2rCd4GEZg3z/DOPH1BcP9a8jR4cPMe2gxDMPwffuKiIiIiEtIjPkQERER/6HwISIiIq1K4UNERERalcKHiIiItCqFDxEREWlVCh8iIiLSqhQ+REREpFUpfIiIiEirUvgQERGRVqXwISIiIq1K4UNERERalcKHiIiItKr/Dy5XpXYN5VNyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 500   6934.85107421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 501   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 502   6934.84619140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 503   6934.8095703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 504   6934.8486328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 505   6934.85400390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 506   6934.85400390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 507   6934.841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 508   6934.84423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 509   6934.8359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 510   6934.8505859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 511   6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 512   6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 513   6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 514   6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 515   6934.873046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 516   6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 517   6934.826171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 518   6934.85888671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 519   6934.841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 520   6934.828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 521   6934.87060546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 522   6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 523   6934.84375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 524   6934.83642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 525   6934.80224609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 526   6934.837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 527   6934.85986328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 528   6934.84375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 529   6934.83740234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 530   6934.85302734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 531   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 532   6934.8515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 533   6934.83642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 534   6934.84765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 535   6934.8310546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 536   6934.87060546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 537   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 538   6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 539   6934.837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 540   6934.83251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 541   6934.8603515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 542   6934.78564453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 543   6934.841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 544   6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 545   6934.81884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 546   6934.85302734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 547   6934.85107421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 548   6934.8642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 549   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 550   6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 551   6934.83740234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 552   6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 553   6934.8466796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 554   6934.826171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 555   6934.83837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 556   6934.81005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 557   6934.8564453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 558   6934.8369140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 559   6934.77783203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 560   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 561   6934.84228515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 562   6934.84765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 563   6934.837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 564   6934.85498046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 565   6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 566   6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 567   6934.86328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 568   6934.8466796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 569   6934.83740234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 570   6934.865234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 571   6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 572   6934.84130859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 573   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 574   6934.853515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 575   6934.81787109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 576   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 577   6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 578   6934.853515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 579   6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 580   6934.84716796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 581   6934.84912109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 582   6934.8359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 583   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 584   6934.8525390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 585   6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 586   6934.8388671875\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 587   6934.89404296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.7757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 588   6934.8544921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 589   6934.85107421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 590   6934.8359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 591   6934.82373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 592   6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.8843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 593   6934.849609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 594   6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 595   6934.83056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 596   6934.8427734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 597   6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 598   6934.83642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(5.9927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 599   6934.837890625\n",
      "eval loss 3.363651990890503\n",
      "Number training steps total: 40\n",
      "eval loss 20.177404403686523\n",
      "loss 0     19.742000579833984\n",
      "loss 1     9.954048156738281\n",
      "loss 2     3.714132308959961\n",
      "loss 3     1.6206592321395874\n",
      "loss 4     0.8956887722015381\n",
      "loss 5     2.5569307804107666\n",
      "loss 6     4.367677688598633\n",
      "loss 7     4.893536567687988\n",
      "loss 8     5.369350433349609\n",
      "loss 9     4.508989334106445\n",
      "eval loss 3.20037579536438\n",
      "loss 10    3.2292675971984863\n",
      "loss 11    2.3273818492889404\n",
      "loss 12    1.055046558380127\n",
      "loss 13    0.6057007908821106\n",
      "loss 14    0.6260429620742798\n",
      "loss 15    1.7215694189071655\n",
      "loss 16    1.4480056762695312\n",
      "loss 17    1.7890708446502686\n",
      "loss 18    1.9096918106079102\n",
      "loss 19    2.893868923187256\n",
      "eval loss 1.566821813583374\n",
      "loss 20    1.4508914947509766\n",
      "loss 21    1.0791528224945068\n",
      "loss 22    0.7349414229393005\n",
      "loss 23    1.4026658535003662\n",
      "loss 24    0.5662827491760254\n",
      "loss 25    0.7001082897186279\n",
      "loss 26    0.884526252746582\n",
      "loss 27    1.2636404037475586\n",
      "loss 28    1.152536392211914\n",
      "loss 29    1.1193561553955078\n",
      "eval loss 1.0149719715118408\n",
      "loss 30    0.9919449090957642\n",
      "loss 31    1.380678653717041\n",
      "loss 32    0.6694521903991699\n",
      "loss 33    0.5656970739364624\n",
      "loss 34    0.5433787107467651\n",
      "loss 35    1.2415122985839844\n",
      "loss 36    0.6371995806694031\n",
      "loss 37    0.6046543121337891\n",
      "loss 38    0.6376259326934814\n",
      "loss 39    1.630067229270935\n",
      "eval loss 0.6702311635017395\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 600   6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 601   6934.84326171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 602   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 603   6934.8515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 604   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 605   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 606   6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 607   6934.84814453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 608   6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.0904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 609   6934.85693359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 610   6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 611   6934.86181640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 612   6934.830078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 613   6934.82177734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 614   6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 615   6934.86181640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 616   6934.83984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 617   6934.80517578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 618   6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 619   6934.837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 620   6934.841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 621   6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 622   6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 623   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 624   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 625   6934.8349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 626   6934.8056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 627   6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 628   6934.80078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 629   6934.837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 630   6934.80859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 631   6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 632   6934.8349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 633   6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 634   6934.841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 635   6934.83251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 636   6934.8125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 637   6934.8115234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 638   6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 639   6934.8271484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 640   6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 641   6934.82763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 642   6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 643   6934.80126953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 644   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 645   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 646   6934.82373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 647   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 648   6934.845703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 649   6934.83544921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 650   6934.8291015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 651   6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 652   6934.8125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 653   6934.81005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 654   6934.85791015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 655   6934.8271484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 656   6934.8212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 657   6934.80029296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 658   6934.814453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 659   6934.81396484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 660   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 661   6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 662   6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 663   6934.80029296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 664   6934.7939453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 665   6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 666   6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 667   6934.830078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 668   6934.7861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 669   6934.81591796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 670   6934.81884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 671   6934.75634765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 672   6934.80322265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 673   6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 674   6934.80126953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 675   6934.8564453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.1978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 676   6934.8271484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 677   6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 678   6934.81884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 679   6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 680   6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 681   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 682   6934.796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 683   6934.830078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 684   6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 685   6934.8037109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 686   6934.84423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 687   6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 688   6934.7802734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 689   6934.7978515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 690   6934.837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 691   6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 692   6934.8388671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 693   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 694   6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 695   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 696   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 697   6934.80908203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.3966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 698   6934.8017578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 699   6934.791015625\n",
      "eval loss 3.350749969482422\n",
      "Number training steps total: 40\n",
      "eval loss 14.098998069763184\n",
      "loss 0     13.70347785949707\n",
      "loss 1     5.485711097717285\n",
      "loss 2     1.3985035419464111\n",
      "loss 3     1.4493274688720703\n",
      "loss 4     2.5778250694274902\n",
      "loss 5     4.377145767211914\n",
      "loss 6     4.879174709320068\n",
      "loss 7     3.750208616256714\n",
      "loss 8     3.0816807746887207\n",
      "loss 9     1.8021466732025146\n",
      "eval loss 0.9620959162712097\n",
      "loss 10    0.9236763715744019\n",
      "loss 11    1.2216781377792358\n",
      "loss 12    0.9056775569915771\n",
      "loss 13    1.416243553161621\n",
      "loss 14    1.768447995185852\n",
      "loss 15    2.865206480026245\n",
      "loss 16    1.7226611375808716\n",
      "loss 17    1.417137622833252\n",
      "loss 18    0.9932727813720703\n",
      "loss 19    1.2508316040039062\n",
      "eval loss 0.6990215182304382\n",
      "loss 20    0.6501457691192627\n",
      "loss 21    0.7730203866958618\n",
      "loss 22    0.9956313967704773\n",
      "loss 23    1.4311145544052124\n",
      "loss 24    1.2974616289138794\n",
      "loss 25    1.2302212715148926\n",
      "loss 26    1.0509142875671387\n",
      "loss 27    1.1800696849822998\n",
      "loss 28    0.716286301612854\n",
      "loss 29    0.6330019235610962\n",
      "eval loss 0.7021970152854919\n",
      "loss 30    0.6190578937530518\n",
      "loss 31    1.749479055404663\n",
      "loss 32    0.7570618987083435\n",
      "loss 33    0.7899740934371948\n",
      "loss 34    0.7328428030014038\n",
      "loss 35    1.3252146244049072\n",
      "loss 36    0.6286765336990356\n",
      "loss 37    0.624312698841095\n",
      "loss 38    0.6200085878372192\n",
      "loss 39    1.139427900314331\n",
      "eval loss 0.7483411431312561\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWKklEQVR4nO3deXhU5d3/8fcsyWQPO0lI2PdVlEXcF1yoKIhWrdSqbbVVbF2qrfT3qE/tgvZpfaitVVufFtsqriDWHVFQyyZg2PctYQkhYHayzZzfHyczWciemTmzfF7XNVcOMycz32GUfHLf3/s+NsMwDERERESCxG51ASIiIhJdFD5EREQkqBQ+REREJKgUPkRERCSoFD5EREQkqBQ+REREJKgUPkRERCSoFD5EREQkqJxWF9CYx+PhyJEjJCcnY7PZrC5HRERE2sAwDEpKSsjIyMBub3lsI+TCx5EjR8jKyrK6DBEREemA3NxcMjMzWzwn5MJHcnIyYBafkpJicTUiIiLSFsXFxWRlZfl+jrck5MKHd6olJSVF4UNERCTMtKVlQg2nIiIiElQKHyIiIhJUCh8iIiISVAofIiIiElQKHyIiIhJUCh8iIiISVAofIiIiElQKHyIiIhJUCh8iIiISVAofIiIiElQKHyIiIhJUCh8iIiISVO0OH5999hlXX301GRkZ2Gw23nrrrWbP/eEPf4jNZmP+/PmdKNFPio/C8idh6WNWVyIiIhLV2h0+ysrKGDduHM8880yL5y1evJjVq1eTkZHR4eL8quQoLP8NrP0LVJVZXY2IiEjUcrb3G6ZNm8a0adNaPOfw4cP86Ec/4sMPP+Sqq67qcHF+lTEeug6Ar/fDzvdhzPVWVyQiIhKV/N7z4fF4uOWWW3jooYcYNWpUq+dXVlZSXFzc4BYQNltd4NjyZmBeQ0RERFrl9/Dx5JNP4nQ6+fGPf9ym8+fNm0dqaqrvlpWV5e+S6oy+zvy6eymc+jpwryMiIiLN8mv4WL9+PX/4wx9YsGABNputTd8zd+5cioqKfLfc3Fx/ltRQrxHQayR4qmHHu4F7HREREWmWX8PH559/Tn5+Pn379sXpdOJ0Ojl48CA/+clP6N+/f5Pf43K5SElJaXALqNGzzK+aehEREbFEuxtOW3LLLbcwderUBvddccUV3HLLLdx+++3+fKmOGzULPvkV7FsBpcchqafVFYmIiESVdoeP0tJS9uzZ4/vz/v37yc7Oplu3bvTt25fu3bs3OD8mJoa0tDSGDRvW+Wr9ofsgc+XLka9g+xKY+H2rKxIREYkq7Z52WbduHePHj2f8+PEAPPDAA4wfP55HH33U78UFjLfxdMsia+sQERGJQjbDMAyri6ivuLiY1NRUioqK/Nr/cejrcn7x723EOuw8M70X/O8owAb3b4XUPn57HRERkWjUnp/fUXNtlxq3wdJtx/hs13FIzYS+5wAGbF1sdWkiIiJRJWrCR1Kc2d5SWlWDx2No1YuIiIhFoid8uMzwYRhQXu2GkTPBZocjG+DkPmuLExERiSJREz5cTjsxDnPjs5KKanOJ7YALzQfVeCoiIhI0URM+bDabb/SjtKLGvFOrXkRERIIuasIH1PV9lFTWho8R08EeA/lbIX+7hZWJiIhEj+gKH64YoN7IR3xXGFy7I6tGP0RERIIiqsJHsnfaxTvyATDmevPrljfMblQREREJqKgKH77lthX1wsfQK8EZb654OZptTWEiIiJRJLrCh6tRzweAKwmGXWkea88PERGRgIuu8NHUyAfUW/WyGDyeIFclIiISXaIqfCR7w0dldcMHBl8GsclQfAgOrbWgMhERkegRXeGjqYZTgJg4c9ktaOpFREQkwKIqfPh6PhpPu0Dd1MvWxeBu4nERERHxi+gKH3HmPh9Nho+BF0F8Nyg7Dge/CG5hIiIiUSS6wkdz0y4AjhgYOcM83vxGEKsSERGJLlEVPpKbW+3i5Z162f421FQFqSoREZHoElXho8WRD4B+50BSGlQUwd5PgliZiIhI9Iiu8OG9sFxFddMn2B0w6lrzWKteREREAiKqwkf9pbZGc9dx8U697HwPqsqDVJmIiEj0iKrw4R358Bhwqtrd9EmZEyC1L1SVwu6PglidiIhIdIiq8BEf48BuM4+bbTq12WD0LPNYUy8iIiJ+F1Xhw2azNX1xuca8Uy+7P4KK4iBUJiIiEj2iKnwAJNduNNbsyAdA2hjoMRRqKszeDxEREfGbKAwfrSy3hdqpF++VbjX1IiIi4k9RFz7qru/SzHJbr1G1fR97P4HykwGuSkREJHpEX/iIa+HicvX1HGpOv3hqzB1PRURExC+iL3y0tstpfZp6ERER8buoCx+tXt+lPu/Uy/7PoSQvgFWJiIhEj6gLH+0a+ejaDzInAgZsWxLYwkRERKJEFIYPc6lti/t81Df6evPr5jcCVJGIiEh0ib7w0Z5pF4BRMwEbHFoLXx8MWF0iIiLRIurCR3J7pl0AktOg/3nm8dbFAapKREQkekRd+Gj3yAdo1YuIiIgfRV/4aMu1XRobcQ3YnZC3CQp2B6gyERGR6BB14aNue/VWdjitL7E7DLzYPN6yKABViYiIRI/oDR/tmXaBelMvb4Bh+LkqERGR6BF14cO31LaiBqM9IWL4VeBwQcEuOLY1QNWJiIhEvugLH7UjHzUeg8oaT9u/MS4Fhl5uHm/Rnh8iIiId1e7w8dlnn3H11VeTkZGBzWbjrbfe8j1WXV3Nz372M8aMGUNiYiIZGRl85zvf4ciRI/6suVMSYhzYbOZxqxeXa6z+qhdNvYiIiHRIu8NHWVkZ48aN45lnnjntsfLycjZs2MAjjzzChg0bWLRoETt37uSaa67xS7H+YLfbSIpt514fXkOugJhEKMyBw+sDUJ2IiEjkc7b3G6ZNm8a0adOafCw1NZWlS5c2uO9Pf/oTkyZNIicnh759+3asSj9LinNSUlnT/qbT2AQY/g3Y/Lo5+pE5ITAFioiIRLCA93wUFRVhs9no0qVLk49XVlZSXFzc4BZodXt9tGO5rZdv6mUReNx+rEpERCQ6BDR8VFRU8LOf/YxvfetbpKSkNHnOvHnzSE1N9d2ysrICWRLQwV1OvQZdAnGpUJoHOav8XJmIiEjkC1j4qK6u5oYbbsAwDJ599tlmz5s7dy5FRUW+W25ubqBK8klq7/Vd6nO6YMTV5rG2WxcREWm3gIQPb/A4ePAgS5cubXbUA8DlcpGSktLgFmh1u5x2IHxA3dTLtiXg7sDUjYiISBTze/jwBo/du3fz8ccf0717d3+/RKf5ej46Mu0C0P8CSOwJ5Sdg3wo/ViYiIhL52h0+SktLyc7OJjs7G4D9+/eTnZ1NTk4O1dXVXH/99axbt46XXnoJt9tNXl4eeXl5VFVV+bv2DkuOM3c57fDIh8MJI2eax5p6ERERaZd2h49169Yxfvx4xo8fD8ADDzzA+PHjefTRRzl8+DBvv/02hw4d4owzziA9Pd13W7lypd+L76i6kY9OTJl4p152vAPVFX6oSkREJDq0e5+Piy66qMVrorTreikW6fDF5erLmgwpfaD4MOz5GEZM91N1IiIikS3qru0CnVzt4mW3w6hrzWNNvYiIiLRZdIaPuE42nHp5p152fQBVZZ2sSkREJDpEZ/jwx8gHQMZ46DoAqsth5/t+qExERCTyRWX46PQ+H142G4y53jzW1IuIiEibRGX4SHLVLrXt7LQL1E297F4Kp77u/POJiIhEuOgMH96ej86OfAD0GgG9RoKnGna82/nnExERiXDRGT5qez6qajxU1vjhyrSjZ5lfNfUiIiLSqqgOHwBllX4IH6Nqw8e+FVB6vPPPJyIiEsGiMnw47DYSYh2An/o+ug8yV74Ybti+pPPPJyIiEsGiMnxA3YqX4s5ssV6ft/F0yyL/PJ+IiEiEitrw4be9Pry8u50eXAlFh/3znCIiIhEoesNHnB+X2wKkZkLfcwADti72z3OKiIhEoKgNH8n+HvkArXoRERFpg6gNH95pF7/s9eE1cibY7HBkA5zc57/nFRERiSDRGz68W6z7a9oFIKknDLjQPFbjqYiISJOiN3z4pl38tNrFS6teREREWhS14SM5ECMfACOmgz0G8rdC/nb/PreIiEgEiNrwEZCeD4D4rjB4qnms0Q8REZHTRG/4CNTIB9SbenkTDMP/zy8iIhLGojd8BGKprdewaeCMh5N74Wi2/59fREQkjEVt+PD1fAQifLiSYNiV5rH2/BAREWkgisOHucNpSSCmXaDe1Mti8HgC8xoiIiJhKGrDh6/hNFDhY/BlEJsMxYfg0NrAvIaIiEgYivrw4fd9Prxi4sxlt6CpFxERkXqiNnx4ez4qqj1UuwM0LeKdetm6GNwBGmEREREJM1EbPhJrRz4AygLRdAow8CKI7wZlx+HgF4F5DRERkTATteEjxmEnLsZ8+wHr+3DEwMgZ5vHmNwLzGiIiImEmasMHQJLLXPESkOW2Xt6pl+1vQ01V4F5HREQkTER1+AjoXh9e/c6BpDSoKIK9nwTudURERMJEVIcP34qXQE27ANgdMOpa81irXkRERBQ+IAAXl2vMO/Wy8z2oKg/sa4mIiIS46A4fgby4XH2ZEyC1L1SVwu6PAvtaIiIiIS6qw0eyb5fTAG005mWzwehZ5rGmXkREJMpFd/gIRsOpl3fqZfdHUFEc+NcTEREJUVEdPrzTLgHb56O+tDHQYyjUVJi9HyIiIlEqusNHMPb58LLZ6l3pVlMvIiISvaI7fASr4dRrVG3fx95PoPxkcF5TREQkxER1+Eh2BbHnA6DnUHP6xVNj7ngqIiIShdodPj777DOuvvpqMjIysNlsvPXWWw0eNwyDRx99lPT0dOLj45k6dSq7d+/2V71+FbR9PurT1IuIiES5doePsrIyxo0bxzPPPNPk47/97W95+umnee6551izZg2JiYlcccUVVFRUdLpYf6ubdgnwUtv6vFMv+z+Hkrzgva6IiEiIcLZ+SkPTpk1j2rRpTT5mGAbz58/nv/7rv5gxw7ya6z/+8Q969+7NW2+9xU033dS5av0sKdjTLgBd+0HmRDj0JWxbApN/ELzXFhERCQF+7fnYv38/eXl5TJ061XdfamoqkydPZtWqVf58Kb9IDnbDqZemXkREJIr5NXzk5ZnTCL17925wf+/evX2PNVZZWUlxcXGDW7B4Rz7Kqty4PUbQXte80JwNctdAYU7wXldERCQEWL7aZd68eaSmpvpuWVlZQXttb88HBHnqJTkN+p9nHm9ZFLzXFRERCQF+DR9paWkAHDt2rMH9x44d8z3W2Ny5cykqKvLdcnNz/VlSi1xOB7FO868gqOEDNPUiIiJRy6/hY8CAAaSlpbFs2TLffcXFxaxZs4YpU6Y0+T0ul4uUlJQGt2Dy7fUR7L6PEdeA3Ql5m6AgNJcii4iIBEK7w0dpaSnZ2dlkZ2cDZpNpdnY2OTk52Gw27rvvPn71q1/x9ttvs3nzZr7zne+QkZHBzJkz/Vy6f/iW21YGcbktQGJ3GHixeaypFxERiSLtXmq7bt06Lr74Yt+fH3jgAQBuvfVWFixYwE9/+lPKysq48847KSws5LzzzuODDz4gLi7Of1X7kW+jsWCPfIA59bJnKWx5Ay78qXn9FxERkQjX7vBx0UUXYRjNrwyx2Ww8/vjjPP74450qLFgs2evDa/hV4HBBwS44thXSRge/BhERkSCzfLWL1Szb6wMgLgWGXm4eq/FURESiRNSHD0tHPqDhqpcWRpREREQihcJHnIU9HwBDroCYRCg8CIfXW1ODiIhIECl8uGIAC0c+YhNg+DfMY029iIhIFIj68GFpz4eXb+plEXjc1tUhIiISBFEfPizv+QAYdAnEpUJpHuSE3gX4RERE/EnhozZ8FFcEeZOx+pwuGHG1eaypFxERiXBRHz580y5WjnxA3dTLtiXgtjAIiYiIBFjUh4+kUOj5AOh/AST2hPITsG+FtbWIiIgEUNSHj2SrV7t4OZwwcqZ5rKkXERGJYFEfPkJm5APqpl52vAPVFdbWIiIiEiAKH97VLlU1eDwW7zCaNRlS+kBlMez52NpaREREAiTqw4e34dQwoLza4j027HYYda15rKkXERGJUFEfPlxOO067eSn7kJp62fUBVJVZW4uIiEgARH34sNlsdX0flSGwxDVjPHQdANXlsPN9q6sRERHxu6gPH1DX92HZxeXqs9kabrcuIiISYRQ+CJEt1usbc735dc9SOFVoaSkiIiL+pvBBXdNpSIx8APQaAb1GgrvKXHYrIiISQRQ+qDfyESrhA2D0LPOrVr2IiEiEUfgAkuPMXU5LQmXaBWBUbfjYtwJKj1tbi4iIiB8pfBBiu5x6dR9krnwx3LB9idXViIiI+I3CB5DsCqGltvVp1YuIiEQghQ9CcLWLl3e304MroeiwtbWIiIj4icIHddMuIbPaxSs1E/qeAxiw7S2rqxEREfELhQ9CeOQD6la9bH7D2jpERET8ROGDun0+Qqrh1GvkTLDZ4cgGOLnP6mpEREQ6TeEDSHKZS21DcuQjqScMuNA8VuOpiIhEAIUPQrjnw0urXkREJIIofFD/wnIhttTWa8R0sMdA/lbI3251NSIiIp2i8EG9no/KGgzDsLiaJsR3hcFTzWONfoiISJhT+KBu5MNjwKlqt8XVNMM39fImhGJAEhERaSOFDyAh1oHdZh6H5IoXgGHTwBkPJ/fC0WyrqxEREekwhQ/AZrPV9X2E4ooXAFcSDLvSPNaVbkVEJIwpfNTyXtk2ZEc+oN7Uy2LweKytRUREpIMUPmqF9C6nXoMvg9hkKD4Eh9ZaXY2IiEiHKHzUCvm9PgBi4sxlt6CpFxERCVsKH7XCYuQD6qZeti4Gd4jXKiIi0gSFj1pJvuu7hOhGY14DLzL3/Sg7Dge/sLoaERGRdlP4qJUcLiMfjhgYOcM81tSLiIiEIb+HD7fbzSOPPMKAAQOIj49n0KBB/PKXvwzNnUPrCfmltvWNvt78uu1tqKmythYREZF2cvr7CZ988kmeffZZXnzxRUaNGsW6deu4/fbbSU1N5cc//rG/X85vwqLh1KvfOZCUBqV5sPeTuv0/REREwoDfRz5WrlzJjBkzuOqqq+jfvz/XX389l19+OWvXhvbSUF/DaTiED7sDRl1rHmvqRUREwozfw8c555zDsmXL2LVrFwAbN27kiy++YNq0af5+Kb+qf3G5sOBd9bLzPagqt7YWERGRdvD7tMvDDz9McXExw4cPx+Fw4Ha7+fWvf83s2bObPL+yspLKykrfn4uLi/1dUpuExQ6n9WVOgNS+UJQDuz+CUTOtrkhERKRN/D7y8dprr/HSSy/x8ssvs2HDBl588UV+97vf8eKLLzZ5/rx580hNTfXdsrKy/F1Sm4RVwymAzQajZ5nHmnoREZEw4vfw8dBDD/Hwww9z0003MWbMGG655Rbuv/9+5s2b1+T5c+fOpaioyHfLzc31d0lt4tvnozLE9/mozzv1svsjqLBmxEhERKS9/B4+ysvLsdsbPq3D4cDTzIXQXC4XKSkpDW5WSA6nhlOvtDHQYyjUVMDO962uRkREpE38Hj6uvvpqfv3rX/Puu+9y4MABFi9ezFNPPcW1117r75fyq6R6DaehvieJj81W70q3b1hbi4iISBv5PXz88Y9/5Prrr+fuu+9mxIgRPPjgg/zgBz/gl7/8pb9fyq+8PR/VboPKmjC6XP2o2r6PvZ9A+UlraxEREWkDv692SU5OZv78+cyfP9/fTx1QibF1fxWllTXExTgsrKYdeg41p1/yNsP2t+Gs26yuSEREpEW6tkstu90WXhuN1eebetGqFxERCX0KH/X4ltuGW/jwTr3s/xxK8qytRUREpBUKH/X4ru8STsttAbr2g8yJgAHbllhdjYiISIsUPuoJ22kX0NSLiIiEDYWPesLu+i71jboWsEHuGijMsboaERGRZil81BPW4SM5DfqfZx5vWWRtLSIiIi1Q+KgnbBtOvTT1IiIiYUDho54kV+2VbcNx5ANgxDVgd0LeJijYbXU1IiIiTVL4qMe3xXq4jnwkdoeBF5vHmnoREZEQpfBRj+/icuE68gENr/USLteoERGRqKLwUY9vn49wHfkAGP4NcLigYBcc22p1NSIiIqdR+KjHt89HuG0yVl9cKgy5zDxW46mIiIQghY96ImLkA2DM9ebXLW9q6kVEREKOwkc9EdHzATDkCohJhMKDcHi91dWIiIg0oPBRT9ivdvGKTTB7P0BTLyIiEnIUPurxbTIW7iMfUG/VyyLwuK2tRUREpB6Fj3qSazcZq6rxUFkT5j+wB11iNp+W5kHOKqurERER8VH4qMc77QJQVhnm4cPpghFXm8eaehERkRCi8FGPw24jIdYBREDfB9RNvWxbAu4wXj4sIiIRReGjkbq+jwj4Yd3/AkjsCeUnYP8Kq6sREREBFD5OEzErXgAcThg50zzerKkXEREJDQofjUTMXh9e3qmXHe9AdYW1tYiIiKDwcRrfyEekhI+syZDSByqLYc/HVlcjIiKi8NGYr+cjEqZdAOx2GHWteaxVLyIiEgIUPhpJqt3rI2LCB9RNvez6AKrKrK1FRESinsJHI8lxEXBl28YyxkPXAVBdDjvft7oaERGJcgofjXinXSJitYuXzdZwu3URERELKXw04m04jYjru9Q35nrz656lcKrQ0lJERCS6KXw0khxJ+3zU12sE9BoJ7ipz2a2IiIhFFD4aSYq0fT7qGz3L/KpVLyIiYiGFj0aSI22fj/pG1YaPfSug9Li1tYiISNRS+GjEu9Q24qZdALoPMle+GG7YvsTqakREJEopfDRSd2G5CAwfoFUvIiJiOYWPRiK24dTLu9vpwZVQdNjaWkREJCopfDTiHfk4Ve2mxu2xuJoASM2EvlMAA7a9ZXU1IiIShRQ+GkmsDR8QoU2nUDf1svkNa+sQEZGopPDRSKzTjstp/rVE1PVd6hs5E2x2OLIBTu6zuhoREYkyCh9NiOjltgBJPWHAheaxGk9FRCTIFD6aENEbjXlp1YuIiFgkIOHj8OHDfPvb36Z79+7Ex8czZswY1q1bF4iXCoikSF/xAjBiOthjIH8r5G+3uhoREYkifg8fX3/9Neeeey4xMTG8//77bNu2jd///vd07drV3y8VMMm1G41F7F4fAPFdYfBU81ijHyIiEkTO1k9pnyeffJKsrCz+/ve/++4bMGCAv18moKJi5APMqZdd75vXern452CzWV2RiIhEAb+PfLz99ttMmDCBb37zm/Tq1Yvx48fz17/+tdnzKysrKS4ubnCzWrKv56Pa4koCbNg0cMbDyb1wdKPV1YiISJTwe/jYt28fzz77LEOGDOHDDz/krrvu4sc//jEvvvhik+fPmzeP1NRU3y0rK8vfJbVb1Ix8uJJg2JXm8Rbt+SEiIsHh9/Dh8Xg488wz+c1vfsP48eO58847ueOOO3juueeaPH/u3LkUFRX5brm5uf4uqd0i/vou9flWvSwGTwTu6CoiIiHH7+EjPT2dkSNHNrhvxIgR5OTkNHm+y+UiJSWlwc1qUTPyATD4MohNhuJDcGit1dWIiEgU8Hv4OPfcc9m5c2eD+3bt2kW/fv38/VIBkxwN+3x4xcSZy27BbDwVEREJML+Hj/vvv5/Vq1fzm9/8hj179vDyyy/zl7/8hTlz5vj7pQLGO/IRsdurN+adetm6GNxR8p5FRMQyfg8fEydOZPHixSxcuJDRo0fzy1/+kvnz5zN79mx/v1TAJEXDPh/1DbzI3Pej7Dgc/MLqakREJML5fZ8PgOnTpzN9+vRAPHVQ+LZXr4jwpbZejhgYOQPWLzCnXgZeZHVFIiISwXRtlyZE/IXlmjL6evPrtrehpsraWkREJKIpfDShbuQjisJHv3MgKQ0qCmHvJ1ZXIyIiEUzhownekY+yKjduj2FxNUFid8Coa81jrXoREZEAUvhogne1C0BZVRSNfnhXvex8D6rKra1FREQilsJHE1xOB7EO868mqqZeMidAal+oKoXdH1ldjYiIRCiFj2YkRWPTqc0Go2eZx5p6ERGRAFH4aEaXeHOvjxOlUbbywzv1svsjqLD+CsMiIhJ5FD6akZYaB0Be8SmLKwmytDHQfQjUVMDO962uRkREIpDCRzO84eNoUYXFlQSZzQZjavf82PKGtbWIiEhEUvhoRrp35CPawgfAqNq+j72fQPlJa2sREZGIo/DRjPTUeACOFEZh+Og51Jx+8dTA9retrkZERCKMwkcz0qO158PL23iqVS8iIuJnCh/NSIvmaReom3rZ/zmU5Flbi4iIRBSFj2Zk1E67FJRWUVnjtrgaC3TtB5kTAQO2LbG6GhERiSAKH83okhCDy2n+9RwrqrS4Goto6kVERAJA4aMZNpvN1/dxtChK+z5GXQvYIHcNFOZYXY2IiEQIhY8WRO1eH17JadD/PPN4yyJraxERkYih8NECb99H1IYP0NSLiIj4ncJHC+pWvETptAvAiGvA7oS8TVCw2+pqREQkAih8tMDb83Ekmkc+ErvDwIvNY029iIiIHyh8tMC7y2kk7vWx5XARd7+0ni2Hi1o/2Tf18gYYRmALExGRiKfw0YJIbTjdd7yU7/xtLe9tzmPe+9tb/4bh3wCHCwp2wbGtgS9QREQimsJHC7zTLgWllRGz0Vh+cQXf+dtaTpZVAfCfPSc4UFDW8jfFpcKQy8xjNZ6KiEgnKXy0oFtiLLG1G43lF4f/RmPFFdXc+vcvOfT1Kfp3T2Bi/64ALPyyDXt4jLne/LrlTU29iIhIpyh8tKDhRmPhPfVSWePmzn+sY/vRYnokufjHdyfz/fMHAvDGukNU1XhafoIhV0BMIhQehMPrg1CxiIhEKoWPVqSlhP8up26PwQOvbmT1vpMkuZwsuH0ifbsncOnwXvROcXGirIqPtrVy8bjYBLP3AzT1IiIinaLw0YqMLuG90ZhhGDz+7628u/koMQ4bz337LEb3SQXA6bBz44QsAF5e04apF9+ql0XgiYweGBERCT6Fj1bUbTQWnuHjz8v38uKqgwD8/oYzOG9IjwaP3zAxC5sNVu49wf7WGk8HXWI2n5bmQc6qQJUsIiIRTuGjFb6NxgrDb9rltXW5/M+HOwF4dPpIrhmXcdo5mV0TuGhoTwBeWdvK6IfTBSOuNo819SIiIh2k8NEK30ZjxeE18vHJjmPMXbQZgB9cOJDvnjeg2XO/NakvAK+vP9T6kmLv1Mu2JeCu9kutIiISXRQ+WhGOq1025HzN3S9twO0xmHVmHx6+cniL519S23h6sqyKj7Yea/nJ+18AiT2h/ATsX+HHqkVEJFoofLQird5GY60uRw0Be/JL+e6CL6mo9nDh0J48ed1YbDZbi99Tv/F0YWtTLw4njJxpHm/W1IuIiLSfwkcruifGEuuwYxhwLMSnXo4VV3Dr39ZSWF7NuMxU/jz7TGIcbfuIb5zUF3tbG0+9Uy873oHq0P47ERGR0KPw0QqbzVa34iXEw8fPF23mcOEpBvRI5G+3TSTR5Wzz9/bpEs9Fw3oBbWg8zZoMKX2gshj2fNyZkkVEJAopfLRBWhiseKmodvP5ngIA/nTzeLonudr9HG1uPLXbYdS15rFWvYiISDspfLRBRhjs9ZGdW0hVjYeeyS5Gpqd06DkuHtaTtJQ4TpZV8WFrjafeqZddH0BVK9M0IiIi9Sh8tEFaaujvcrp63wkAzh7YvdUG0+Y4HXZumFjbeNrajqcZ46HrAKguh53vd+j1REQkOil8tEHdctvQnXZZtdcMH1MGdu/U89w4MQu7DVbtO8G+46XNn2izNdxuXUREpI0UPtogPcSnXSqq3XyVWwjA2QO7deq5GjSefpnb8sljrje/7lkKpwo79boiIhI9Ah4+nnjiCWw2G/fdd1+gXypg0kN82uWrHLPfo1eyiwE9Ejv9fDfXNp6+0Vrjaa8R0GskuKvMZbciIiJtENDw8eWXX/L8888zduzYQL5MwHlXuxwP0Y3GVtX2e0wZ1PF+j/ouGtaT9NS2Np7OMr9q1YuIiLRRwMJHaWkps2fP5q9//Stdu3YN1MsERf2NxvJLQm/0o36zqT84HXZuqN3x9OU1B1s+eVRt+Ni3AkqP++X1RUQksgUsfMyZM4errrqKqVOntnheZWUlxcXFDW6hxm630TvV3Dcj1Po+KqrdZOcUAv4LH1DXeLp638mWG0+7DzJXvhhu2L7Eb68vIiKRKyDh45VXXmHDhg3Mmzev1XPnzZtHamqq75aVlRWIkjotPcXs+zgSYuFjw8GvqXJ7SEuJo3/3BL89b0aXeC6ubTxt9XovWvUiIiLt4PfwkZuby7333stLL71EXFxcq+fPnTuXoqIi3y03t5UVFhZJ7+Jd8RJay23rply6+aXfo76bJ7ex8dS72+nBlVB02K81iIhI5PF7+Fi/fj35+fmceeaZOJ1OnE4nK1as4Omnn8bpdOJ2N/wh5nK5SElJaXALRWm+vT5Ca+Rj9b6TgNls6m8XDjUbT78ur+aDLXnNn5iaCX2nAAZse8vvdYiISGTxe/i49NJL2bx5M9nZ2b7bhAkTmD17NtnZ2TgcDn+/ZFCkp9SGj8LQCR+nqtx8lfs14N9+Dy+nw86N3h1P2zz1olUvIiLSMr+Hj+TkZEaPHt3glpiYSPfu3Rk9erS/Xy5o0rvU7vURQle23ZDzNdVug/TUOPp281+/R331G0/3ttR4OnIm2OxweD2c3BeQWkREJDJoh9M2qtvlNHR6Prz9HlM6cT2X1qSnxnPJ8NrG05au95LUEwZcaB6r8VRERFoQlPCxfPly5s+fH4yXChhvz0d+SSXV7tDYaMx7PZdATLnU5208/deagy0vu9WqFxERaQONfLRRj0QXMQ5b7UZjlVaXQ3lVDRsPFQKBDx8XD+vFuYO7U1Ht4cHXN+L2GE2fOGI62GMgfyvkbw9oTSIiEr4UPtrIbrfROyV0pl42HCyk2m3Qp0s8Wd3iA/paNpuN314/jiSXkw05hbzweTM9HfFdYXDtpnIa/RARkWYofLSDt+/jSAiseFm1rwCAyQHY36MpfbrE88j0EQD8fukudh8rafrE+qtejGZGSEREJKopfLSD9+q2obDFund/j0BPudR3w4QsLh7Wk6oaDz95fWPTvS/DpoEzHk7uhaMbg1abiIiED4WPdkgPkY3Gyqtq2JhbCJgrXYLFZrPxxHVjSY2PYdOhIp5dvvf0k1xJMOxK83jLG0GrTUREwofCRzvU7XJqbc/HugNfU+Px9nsEZn+P5vROieMX14wC4Ollu9l6pOj0k3xTL4vBExorg0REJHQofLSDd9rF6pGPuuu5BG/Uo74ZZ2Rwxaje1HgMfvLaRqpqGgWMwZdBbDIUH4JDay2pUUREQpfCRzvUbTQWGuEjENdzaQubzcavrx1Dt8RYduSV8PSy3Q1PiIkzl92CtlsXEZHTKHy0Q7pvo7EKaizaaKyssoZNh8ypjskDullSA0CPJBe/nmlul//sir1k1/ag+HinXrYuBndNcIsTEZGQpvDRDj2SXDjtNjwWbjS27qDZ75HZNfj9Ho1NG5PONeMycHsMfvJaNhXV9a5YPPAic9+PsuNw8AvLahQRkdCj8NEO9Tcas6rvo/71XELB4zNG0TPZxd7jZfz+o511DzhiYOQM81hTLyIiUo/CRzulW7ziJVjXc2mrLgmxPDFrDAAvfLGfLw+crHtw9PXm121vQ02VBdWJiEgoUvhop/Qu1m00VlpZw+bDZr/H2RY1mzbl0hG9+eZZmRgGPPj6Rsqrans8+p0DSWlQUQh7P7G0RhERCR0KH+1k5UZj6w6cxO0x6NstgT5dAns9l/Z65OqRZKTGcfBEOU++v8O80+6AUdeax5p6ERGRWgof7ZSWYt20yyrf/h7WrXJpTkpcDE9ePxaAF1cd5D97zGvP+Fa97HwPqsotqk5EREKJwkc7ZXSxbuTDez0Xq/b3aM35Q3oye3JfAH76xiZz9UvmBEjtC1WlsPsjiysUEZFQoPDRTmkWXVyupKKaLYe9+3uEZvgA+Pk3RtA7xcXhwlMs35kPNhuMnmU+qKkXERFB4aPdvD0fx4qDu9HYugNf4/YY9OueQEaI9XvUl+hyMnN8HwCWZB8x7/ROvez+CCqKLapMRERChcJHO9XfaOx4afA2Ggu1/T1aMmOcGT6W7cinuKIa0sZA9yFQUwE737e4OhERsZrCRzs5LNpozOqLybXHiPRkhvZOoqrGwwdb8syplzG1e35o6kVEJOopfHRAmne5bWFwwkdxRXXd/h5hED5sNhszzvBOvRw27xxV2/exdxmUn2zmO+WjrXl8suOY1WWIiASUwkcHBHuX03UHTuIxYECPRF/wCXXXjMsAYOXeE+QXV0DPoeb0i6cGtr9tcXWhaU9+KXf+cz3ff3Edh77WsmQRiVwKHx3gDR/BWvHiXWIbivt7NCerWwJn9euKYcDbGxs1nmrqpUkvrTkIgMeA19YdsrgaEZHAUfjoAO9y26PFwQkfoXY9l7aaeYY5+uELH96pl/2fQ0meRVWFpvKqGt5YXxc4Xl+XG9TVVCIiwaTw0QEZvp6PwE+7FJ2qZuuR8On3qO8bY9Jx2G1sOlTEvuOl0LUfZE4EDNi2xOryQsq/Nx6hpKKGrG7xdE2I4WhRBSt2Hbe6LBGRgFD46IC0IE67ePs9BvZI9K2yCRfdk1ycP6QH0MSeH5p68TEMg3+uNqdcvj25H9edmQnAwrW5VpYlIhIwCh8dkF477XKspBK3xwjoa3mnXCaH2aiH18x6q14Mw4CRMwEb5K6BwhxLawsVGw8VseVwMbFOO9+ckMVNk7IA+HRnviVXTxYRCTSFjw7omezCYbfh9hgcLwnsRmOr99duLhai13NpzWUjexMf4+DAiXI2HSqClHTof5754NbF1hYXIv65yhz1mD4mnW6JsQzulcyk/t1wewxeX6fRDxGJPAofHeCw2+id7AICu9w2v7iCrUfM7cjPHhA+K13qS3Q5uWxkbwDe8u754Z162fyGRVWFjq/Lqvj3JnNK6ttT+vnu945+vLouF0+AR9dERIJN4aODgtH38dq6XAwDJvTrSq8w6/eob0btqpd/bzxqTlONuAbsTsjbBAW7La7OWm+sP0RVjYeR6SmMz+riu/8bY9JJiXNy6OtTfLGnwLoCRUQCQOGjg9JrL+52JEDhw+MxfA2HN9depj5cXTC0J10TYigorWTl3gJI7A4DLzYf3LLI2uIs5PEY/Kt2b49bpvTDZrP5HouLcTDL13iq3hgRiSwKHx2UnuId+QjMtMtnu49zuPAUqfExfGNMekBeI1hiHHbfezh91csbYETntMIXewo4eKKcZJfTNzpUn3fqZem2YwHvLRIRCSaFjw7yXd8lQCMf3t92Z53Zh7gYR0BeI5hmjjdXvXywJY+KajcM/wY4XFCwC45ttbg6a3iX1153ViYJsc7THh+elsIZWV2o8Ri8uUE7nopI5FD46KCM2mmXQISPY8UVfLw9H4CbJ4X3lIvXWX270qdLPKWVNXyyIx/iUmHIZeaDUbjnx5HCUyzbbl5AbnYL02rez/+VtTnmUmURkQig8NFBgWw4fe3LXNweg4n9uzKkd7Lfn98KdruNa2qnFt76qnbVy5jrza9b3oy6qZeFa3PwGOb1elr6jKePSyfJ5eTAiXJW7TsRxApFRAJH4aODvBeXO1Zc4deNxtweg1e+NBtNvxUhox5e3r6G5TuPU1ReDUOugJhEKDwIh9dbXF3wVNV4fM3Et5zdv8VzE2KdvtD2inY8FZEIofDRQb2S43DYbdR4DApK/dcMGEmNpo0NT0theFoyVW4P7285CrEJZu8HRNXUy0fb8igoraRnsovLR/Vu9Xzv1MsHW/I4WVYV6PJERAJO4aODHHYbvXwbjflv6mXhGrPR9LozMyOi0bQx72/xp696WQQet0VVBZd3R9NvTcwixtH6/4Kj+6Qyuk8KVW4Pi9R4KiIRQOGjE+r6Pvyz3PZYcQXLdtQ2mk7O8stzhpprxpnhY/X+E2a/zKBLzObT0jzIWWVxdYG3+1gJa/afxG6Dm9oxrXbTxNrG0y9z1XgqImHP7+Fj3rx5TJw4keTkZHr16sXMmTPZuXOnv18mJGTUXmDuSKF/Rj5erW00ndS/G4N7RUajaWOZXROY2L8rhmFeRh6nC0ZcbT4YBVMv/6pdXjt1RG/fiqm2mHFGBvExDvbkl7L+4NeBKk9EJCj8Hj5WrFjBnDlzWL16NUuXLqW6uprLL7+csrIyf7+U5XwjH8WdDx9uj8Gr3kbTCB318Lqm9kq3p13rZdsScFdbVFXglVXWsGiD+Z6/fXa/Vs5uKDkuhqvHmT1AL2vHUxEJc34PHx988AG33XYbo0aNYty4cSxYsICcnBzWr4+81Qzpftxo7LNddY2m00ZHVqNpY1eNScdpt7H1SDF78kug/wWQ2BPKT8D+FVaXFzBLso9QUllD/+4JnDe4R7u/3ztN897moxSdityQJiKRL+A9H0VFRQB069b0VVkrKyspLi5ucAsX6bXTLkcLO9/z4f1tNlIbTevrlhjLBUN7ArWNpw4njJxpPhih13oxDMO3o+nsyf2w222tfMfpxmd1YXhaMhXVHpZ4R41ERMJQQMOHx+Phvvvu49xzz2X06NFNnjNv3jxSU1N9t6ys8Jly8NcW63lFFeaun0Ruo2ljM+qtejEMo27qZfu/oTpwVwq2yoacQrYfLcbltHP9WZkdeg6bzcZNE83/Pl5eox1PRSR8BTR8zJkzhy1btvDKK680e87cuXMpKiry3XJzw2cjpfobjXk6sdGYr9F0QOQ2mjZ22cjeJMQ6yDlZzle5hZA1GVL6QGUx7PnY6vL8zttoOn1sBl0TYzv8PNeOz8TltLMjr4SNh4r8VZ6ISFAFLHzcc889vPPOO3z66adkZjb/m57L5SIlJaXBLVz0SnZht9GpjcbMRlNzyiVSruPSFgmxTi4faW6w9Xb2EbDbYdS15oMRturlZFkV7246CsAtU9rXaNpYakIMV9VuPveKGk9FJEz5PXwYhsE999zD4sWL+eSTTxgwYIC/XyJkOB12eiV3buplxa58jhRV0CUhhitHp/mzvJA3o3bVyzubjlDj9tRNvez6AKoiZ3XUa+tyqXJ7GNMnlXGZqZ1+Pm/j6dsbj1BaWdPp5xMRCTa/h485c+bwr3/9i5dffpnk5GTy8vLIy8vj1Cn/bMQVajrb9/FyhO9o2pLzhvSgW2IsBaVVfLb7OGSMh64DoLocdr5vdXl+4fEYvLTGnHL59tl9sdna32ja2MT+XRnUM5HyKrc5aiQiEmb8Hj6effZZioqKuOiii0hPT/fdXn31VX+/VEjI6OINH+0PV0eLTvkaTSPtInJtEeOwM2u8Ofrx9LI9GNBwu/UwV+328Pg728g9eYrkOCfXjOvjl+e12Wy+/15e+VJTLxK6Vu4t4IFXs/16/SuJDAGZdmnqdtttt/n7pUJCWoq53DavAyMfr36Zi8egttE0yd+lhYU7LxxIfIyD7NxCPt2ZXxc+9iyFU4WW1tYZ+cUVzP7rGhasPADAA5cNJT7WfyNbs87MJNZhZ9OhIp5bsdevV1YW8QePx+Dnizaz6KvDzP94l9XlSIjRtV06qaMbjdXf0XT25Ogb9fDqlRzHref0B+D3H+3C03ME9BoJ7irY8a61xXXQ2v0nueqPX7D2wEmSXU6ev+Usbj/Xv71P3RJjmX22+d/NE+/v4MbnV3GgIHL6ZCT8rd53ggMnygF4fd0hTmj0Q+pR+Oik9A5Ouyzfmc/Rogq6JsRwxajoajRt7AcXDCTJ5WTrkWI+3JoHo2eZD2x5w9rC2skwDF74fB/f+utqjpdUMrR3EkvuOTdgn++j00cyb9YYEmMdrDv4NdP+8DkvrjzQqWXfIv5S/zIAlTUe3yZ7IqDw0WkdHfmI5kbTxromxvLd88yRgaeW7sI9sjZ87FsBpcctrKztyipruGfhV/zq3e24PQbXjMvgrTnnMrBn4KbTvL0fH9x3AVMGdudUtZvH3t7K7BfWkHuyPGCvK9KagtJK8xcJ4IcXDgLgH6sOUlHttrIsCSEKH52UVrvFens2GjtSeMrsbwC+FcVTLvV977wBpMbHsDu/lH/nxpkrXww3bF9idWmt2pNfyoxn/sO7m47itNv476tH8oebziAh1hmU18/qlsBL35/M4zNGER/jYNW+E1w5/zPtgiqWeXP9IardBuMyU3nw8qFkdo3nZFkVb6w/ZHVpEiIUPjrJu9FYtdugoKxtc5reRtPJA7oxKIC/GYeT1PgY7rxgIADzP643+hHiq17e23yUGX/6gj35pfROcfHqD87mtnMH+GVJbXvY7Ta+M6U/7997PhP7d6Wsys3PF2/m1r9/2aGVWCId5fEYLKydcrl5cl+cDjvfqx3ZfOHzfWqOFkDho9NiHHZ6JruA1le8VNa4yTlRzmvrzEbTmzXq0cBt5/Sne2IsB06U857nbPPOgyuhKPQuolbj9vDrd7dx90sbKKtyM3lAN9750fmc1a/pCygGS/8eibxy5xT+66oRxDrtfLbrOJf/72e8sf6QRkEkKLyNpkkuJ9PHmtdwumFCFqnxMRw4Uc7SbccsrlBCQXDGhSNcWmo8x4or2XSoiMoaD0cKT5FXVMHRogqOFJ7iaFEFR4tOUVBa5fuerlG4o2lrEl1O7rpoEL96dztPrCzlqqyzseeuhm1vwZQ5VpfnU1BayZyXNrBm/0nAbJh96IphOB2hkeUddhvfP38gFw3rxU9e38jG3EIefH0jH2w5ypPXjaV7ksvqEi3l8RjM/3gXX+UWct7gHlw6oheDeiYFfbQqUnkbTWeckUGiy/wRk+hy8u2z+/LMp3v5y2d79W+fYDNC7Neh4uJiUlNTKSoqCpvrvNz1r/W8vyWvTee6nHb6dInn7osHd/jqppGsotrNBb/9lPySSl4dv4XJ238Dfc6COz6xujQASiqqufH51Ww7WkySy8n/XD+WabXXWglFNW4Pz3+2j/kf76LabTCgRyL/+v5k+nSJt7o0S7hr9554dV3DC1hmdYvn0uG9uXh4LyYP6Bb1TeAdVVBayZR5y6h2G7z74/MYlVF3OYH8kgrOe+JTqtwe3vjhFCb0t3aUUPyvPT+/NfLhBxcO7ckHW/Nw2m2kpcaRnhpPRmoc6V3Mr2mp8aSnxpHRJZ6uCTH6DasFcTEOfnTJYB5ZspVHdw/mA5sd2+H1cHIfdBtoaW1VNR7ufmkD244W0yMpllfuPDvkr0LsdNiZc/FgLhnei++/uI79BWV889mV/PP7k6Ou36jG7eHB1zfyVvYR7Db47rkD2J1fyqp9J8g9eYoFKw+wYOUBEmIdnDe4B5cM78XFw3vROyXO6tLDRv1G0/rBA8w9fa4d34dX1+Xyl8/2hWz4MAyD46WVvut2SWBo5MNPyqtqiHM6sNsVLDqrssbNJb9bweHCU3yR8TSZJ1fDJY/ABQ9aVpNhGPzk9Y0s2nCYhFgHr945hTF+uEhcMB0pPMW3/28N+46X0T0xln98b9JpPyAiVVWNh3tf+Yr3t5i/JMy/6QxfP0J5VQ3/2XOCT3Yc45Md+Rwrbtg4PrpPChcP68XwtBQG9EhkQI9Ev+5WGyk8HoNLfr+cAyfKefK6Mdw48fSetj35JUx96jNsNlj2wIUBXYreUf/99lYWrDzAL2eO5pazO3cV6mjTnp/fCh8Skl77MpefvrmJ2+M/5zHjWeg1Cu5eaVk9v/twJ3/6dA8Ou40Xbp3AxcN6WVZLZ5woreQ7f1vL1iPFJMc5+fttEzv9G+ihr8t9UzqhqKLazd0vbeCTHfnEOuz86ebxXN7Mxm+GYbD1SDGf7Mhn2Y58Nh0qpKl/ITNS4xjQM7E2jCQxsDaUZHaND5nen2BbuaeAm19YQ5LLyZqfX+rr92js+y9+ycfb87l5cl9+c+2YIFfZsre+Osx9r2YDEB/j4MP7LqBv9wRriwojCh8S9mrcHqY+tYKTJ/L5Kv5uHEYN3L0aeo1o0/dXVLv556qD9Epxcc24jE5Ndb205iD/b/EWAH573VhumJjV4ecKBcUV1XxvwZd8eeBr4mMcPH/LWVwwtGe7n+dkWRXzP97FS2tysNvglTvPtny1T2PlVTXc+Y/1fLGnAJfTzl++M4EL2/Fej5dUsnxnPqv2nWB/QRn7jpdRdKq62fNjHDb6dkvg/CE9+dakvgxLC+1pOX+65+UNvLPpKLMn9+XXLYSKNftOcONfVhPrtLPy4UvoESIN0LuPlXDNn/7DqWo3qfExFJ2q5tzB3fnX9yZrqryNFD4kInh/C1kQ93suYj1c8FO45P+1+n3rD57koTc2se+4ea2TqSN688R1Yzr0j9zSbcf4wT/X4THgvqlDuG/q0HY/Ryg6VeXmh/9az4pdx4lx2Hj6pvFtbpytqt0q+w8f76K4osZ3f0ZqHO/++Hy6JsYGqux2Kamo5nsL1rH2wEkSYh38360TmTKoe6ef9+uyKvYVlNWGkVL21x7vLyijssbT4Nwz+3bhW5P6Mn1sRqemavKLK1i+6zhF5dXcMqVfyDXEttRo2phhGMz880o25hby40sG88Dlw4JYadPKKmuY8cx/2JNfyjmDuvPLmaP5xh8+p7LGExG/cASLwodEBLfH4Mr5nzGi4EOejn0Gug2CH62HZn4LKa+q4X8+3MmClQcwDOiRFEvxqRqq3B56JMXy5HVjuXRE7za//oacr7n5r6upqPZw08Qs5s0aE1G/AVXVeLj/1Wze3XwUuw2euG4sN0xo/h9ZwzD4ZEc+v353O/tqL2I3PC2Zh64Yxq/e3c7+gjIuGd6LF74zwfLep6Lyar7z97VszC0k2eVkwXcncVa/rgF9TY/H4GhxBVsPF/HmhkN8vD3ft6FWssvJzPF9uGlSVpv6bGrcHr7KLWT5znw+3XGcbUeLfY9dOrwXz377LGKdoTO98/yKvcx7fwfjMlNZcs95rZ7/3uaj3P3SBrokxLDq4Ust7aExDIP7Xs1mSfYReiW7ePfH59Mz2cVfPtvLb97bQXKck48fuDCkG4+PFVfw0Bub+PXM0WR1s26aSOFDIsb7m4/yk5dWst71Q+JtVXDnCsg447TzVu09wc/e3ERO7TVNvnlWJv911UiOFJ3ivley2XmsBIBvTerLI9NHtLr1+f6CMq57diUny6q4eFhP/vqdCRE5l9946ekj00f6dqOsb0deMb96Zztf7CkAzGD34OXD+OaELBx2G9uOFHPtn/9DZY2Hh6cN913PwwonSiu55f/Wsu1oMV0SYvjndydb0hycX1zB6+sP8eqXub7/LgHGZaZy06S+XD0ug6R6fRHe0Y0VO4/z+e7jDUaVAMb0SWXXsRIqazxcMao3f7r5TGJC4L/JtjSaNub2GFz8u+XknCzn8Rmj+M6U/oEvtBn/Wn2Q/3prCw67jYV3nM2kAebUYY3bw6xnV7LpUBGXj+zN87ecFZK/fJRV1nDD86vYeqSYSQO68doPplhWi8KHRAyPx2D6H7/g7oJfMd2xGs75MVz+S9/jpZU1PPn+Dt8VM9NT45g3awwX1WsIrah287sPd/LCF/sB6N89gf+98QzG9236N+HjJZVc9+xKck6WMzYzlYV3nN1s81wkMAyD37y3nb9+bv793HvpEO6bOgSbzcaJ0kqeWrqLhWtz8BgQ67Dz3fMGMOfiQSTHxTR4noVrc5i7aDMOu41X7jybiRYspcwvrmD2C2vYnV9Kj6RY/vX9yQxPs/bfEY/HYOXeEyz8MoePtuZR7Tb/yU2MdXDNGRl0TYhl+c6GoxsAXRJiOH9ITy4a2pMLhvakZ7KLFbuOc8eL66hye5g+Np35N55heShua6NpY/9YdYBHl2ylb7cEPn3wIhwWjJZtOlTI9c+uosrtYe604fygUWjekVfM9Ke/oMZj8MzNZ3LV2NDa06fG7eGOf6zj053H6Z4Yy+K7z7W0QVbhQyLKsu3HeO2fz/J87P/iTu6D4/4tYLfz+e7jPPzmZg4XmtcuuXlyX+ZOG37aD0WvlXsK+MnrGzlaVIHDbuOeiwdzzyWDG/z2WF5Vw01/Wc2mQ0X07ZbAm3ed49s+P5IZhsEzn+7hdx/tAuD2c/uTkRrP08t2U1Jp/gb+jTFpPHzliGb/cTMMg/tfzeat7COkpcTx7o/PC+puqkcKTzH7hTXsLygjLSWOl+4Ivb1MCkorWbThEAvX5rK/duqqvrGZqVw0tCcXDuvFGVldmvyBvGz7MX74r/VUuw2uHd+H331znCU/uL28jabfPrsvv5rZ9tUrp6rcnPPEMr4ur+bPs8/kG0HerK+ovJqr/vg5h74+xWUje/OXZkY2nlq6i6eX7aZHUixL778wZHqaDMPg/721hZfX5BAXY2fhHWc3+wtVsCh8SEQxDIMbnlnO345/i2TbKcpuepNfbenOwnVHAMjsGs+T143l3ME9Wn2uovJqHn17C0uyze8dl9WF+TeewYAeiQ1+i+iaEMObd50TkvsQBNKLKw/w2NtbG9w3KiOFR6ePZPLA1ps1yypruPpPX7DveBkXDO3JgtsmBrz/o6rGw6INh5j/8W7yiivI7BrPy98/O6SXSBqGwZr9J3lz/SFqPAbnD+nBBUN7trkp+sOtecx5aQM1HoMbJmTyxKyxlvTZtKfRtClPfbSTpz/Zw7isLrx19zlBm9bweAzu/Oc6Pt6eT1a3eN750fmkxjf9S0tljZvpT3/B7vxSZp3Zh6duOCMoNbbmuRV7eeL9Hdhs8Ny3z+KKZpaPB5PCh0ScL3YXcOwft3Gd43PffaVGHJ7YZJJSumKPTwVXCsSl1PuaWvdnV3KDxz7Yc4qfv3eAkxXmev7/mj6CLYeLWLg2l7gYOy/fcTZnWvxbhFXeXH+In725ia6JsTx0xTCuOzOzXb9Z78grZuYz/6Gi2sNDVwxjzsWDA1JnZY2b19cd4tnle32jXwNrt4/PiILt49/ddJQfLdyAx4DZk/vyq5mjg96T0N5G08YKSis594lPqKzx8NoPpvj6LQLN+4M71mln0V3nMLpPy6FpQ87XXPfsSgwDFtw+scG0rhX+vfEIP1r4FQCPTh/Jd5vo07KCwodEHMMw+Pmf/sGDBf+P7rYSvz1vpc1FkSeeEiOeEuIpJYEhffvQu2fPhuElrjbANBVsYkK3C76jCkorSXI5O7yk07tJnN0GC+84u02jJm1VUe3m1S9zeXb5XvKKzStJ90x28YMLBnLz5L6tNhNHkre+Osz9r2VjGOZVoR+7emRQRw/a22jalJ8v3szLa3KYOqIXL9w60c9Vnm7NvhPc/MIa3B6DX187mtmT27aL6eP/3sbf/rOfPl3i+fD+Cxo0CwfTlwdOMvuva6hye7j93P48dvUoS+poiq7tIhHHZrNxy3XXcsvrA7lgUCr3ntubeE8pVBZDRTFUltQ7LoaKokZ/bnROtTnf7jIq6WWrpJetsO7FDm2BQ+0ozhHbxOhKUyMx9c9pFGxiEppdQmyFzm789M0Jmazef4JFGw7zo4Vf8d6953f6OU9VuVm4NofnVuwlv8TcAr13iou7LhzETZP6htzeF8Ewc3wfqt0eHnpjEwtWHiDWaWfutOFBCSCr953gwIlyklxO31b1HfH98wawcG0OH2/PZ09+SUCvl3S8pJIfLfwKt8fsl7l5UtsD04NXDGXp9jxyT57itx/s4PEZowNWZ3P2Hi/ljn+YDceXj+zNf101Mug1+IvCh4SNkRkpvHfv+fXuafueHadx15hBpDaM5B/Pp7joBINTaCG8NAoxlbWrE9xVUF5g3jrK5qg3utJ4xKWpENPEfbFJYLd+6SWYYfFXM0ez6VARe/JLuf/VbBbcPqlDjZHlVTW8tDqH5z/bR0GpGToyUuO46+LBfPOszKgMHfV9c0IW1W6Dny/ezF8+20eMw8aDlw8LeAB5eW0OADPHZ3RqNdjAnklcNqI3H207xguf7+eJ68b6q8QG3B6De1/5ivySSob0SuLX17Zvmioh1skTs8Yy+4U1/GPVQaaPzQjaNBGYo5G3//1LCsurGZfVhT/cNN7SRuPOUviQ6ORwQkI38wb0Sod2z+J6PFBV0kxAaea+ps4xPGC44dTX5q3DbM1MEbUxvHi/2v3zwzwh1smfZ5/JjD/9h893F/DnT/fwo0uHtOl7DcPg4Ily3t18lP/7Yj8ny6oAs7l4zsWDue7MzJDaZMtqN0/uS7Xbw2Nvb+WZT/cS63Bw79S2/V13REFpJR9uzQPMvXM66wcXDuSjbcdYtOEwd1wwEBtQeKqawvIqCsur+bq8/nEVRaeqKSyvJj7GQWbXePPWLYHMrvFkdU0gPTXutCXI8z/excq9J0iIdfDst8/s0PTcuYN7cOOELF5dl8vDb27ivXvPD0r4PVXl5vsvriPnZDlZ3eL5v1snhP3FDdXzIWIlw4CqsiaCSVG9gNJUwGk0MuOpaf212io2qckm3bY08voec9StHHhj/SEefH0jdhv86/uTOWdQ06uSisqrWbm3gM92F/DFnuPknjzle6xf9wTmXDyYa8f3CYmNtULVC5/v41fvbgfgp1cO4+6LAtPs29lG06bM+vN/2JBT2IHvNLBj4MCDvfYWY4f05Fgyu8TSJzWOlDgbr63NwYGHx68ZwWXDe9SGfg943Gb4b3Bs1B7X/mJQ77isoppHFm+k5FQl3xjdm2vHpTV6rtO/p+753E2c56l33uk1eDw1fLbzGIdPluFywuUjepISa2/xe06voYn3mpoFN7zol8/OSw2nItHEMKCmovnwclqIaeKximJwV7b+Wm3ljG8wArOryM6eYjvVziQuO2MQCbFO3IbB8ZJKjhSe4nDhKQpKKho8hd1mo1dyLEN6JzOwRyL2BkPkTfyz1ew/Zc3c3+T57TnXD3W0u+bW79yeV8yWQ0XYbJAS5yQ1PoYuCbGkxseQmhBDfFMjRu2owzAMPt6WR0VVFeMyU+jbxdXCD9dGP2ib/EFp3n+qsorjJRXY8eDEg9Nm4PDe8NSGCwM7Hmx4sBkebIYbW3N/V9Ky7oPNy1X4kcKHiLRfTWVtQGmp36WVaaTq8tZfRyTIPNgwbHbsdgc2m8OcWrTZ6252h9l35Tu2mX/2nedoeL/Nzr6TFZworyE+NoaRfbpit9tP/x6b3ezDavDc9e9v+Xs2Hi5mxZ6TGNi5YkwGw9O7tPo9da/TdN2+GmITYcD5rf7dtYdWu4hI+zld5i2x9c3amuWubmLlkfn1eEE+L6/YgtNTN51iztknkNUtnqxuic0sX2yiqa7JRsFmmu/aem6zzYedPbeN5zX7vB17/dLKGvKKK8gvqeJYcQX5JRWcLKvCMMBo9JwOu42EWAcOux2n3YbTYfMdOxx2nHY7TocNp83G0eIKjhVXMr5/d6aPy2r6B1tLP8Tb+oPytO+pFxhO+56WgoS90aiZfySXVDLrf1dQWFrNoJPmf7t2uw27zYbDZsNmM0fvHHbz2FH7mHlr+jGbDRy159R4DBbtPIRhmFNowwM0hWYVhQ8R8R9HTING3vp6AmMz81m4Jocz+nbhgiE9GZmeYvkVcCNVEjC49uZVXlXDzrwSth8tYfvRYrYfLWZHXgmllTVQ3b7nf/eq86CdO5pGkp7JLv776lHc92o2e4+fvlW+v3xrUl/usvBCjYGiaRcRkSjm8RgcLjxF0alqKms8VNa4za/V9Y5rPFR5H6v2MKR3Uqf29ogkG3MLOVlWhccw8Bjmkl7DMHDX/tkwDNwe89jjMfDUe8z758aPGbXP06dLPDPOyLD84oFtpWkXERFpE7vdRla3BLKsLiRMjcvqYnUJYSk84pSIiIhEDIUPERERCSqFDxEREQkqhQ8REREJKoUPERERCSqFDxEREQkqhQ8REREJKoUPERERCSqFDxEREQmqgIWPZ555hv79+xMXF8fkyZNZu3ZtoF5KREREwkhAwserr77KAw88wGOPPcaGDRsYN24cV1xxBfn5+YF4OREREQkjAQkfTz31FHfccQe33347I0eO5LnnniMhIYG//e1vgXg5ERERCSN+Dx9VVVWsX7+eqVOn1r2I3c7UqVNZtWrVaedXVlZSXFzc4CYiIiKRy+9XtS0oKMDtdtO7d+8G9/fu3ZsdO3acdv68efP4xS9+cdr9CiEiIiLhw/tz2zCMVs/1e/hor7lz5/LAAw/4/nz48GFGjhxJVpYu8CwiIhJuSkpKSE1NbfEcv4ePHj164HA4OHbsWIP7jx07Rlpa2mnnu1wuXC6X789JSUnk5uaSnJyMzWbza23FxcVkZWWRm5tLSkqKX587FET6+4PIf496f+Ev0t+j3l/4C9R7NAyDkpISMjIyWj3X7+EjNjaWs846i2XLljFz5kwAPB4Py5Yt45577mn1++12O5mZmf4uq4GUlJSI/Y8KIv/9QeS/R72/8Bfp71HvL/wF4j22NuLhFZBplwceeIBbb72VCRMmMGnSJObPn09ZWRm33357IF5OREREwkhAwseNN97I8ePHefTRR8nLy+OMM87ggw8+OK0JVURERKJPwBpO77nnnjZNswSTy+Xisccea9BjEkki/f1B5L9Hvb/wF+nvUe8v/IXCe7QZbVkTIyIiIuInurCciIiIBJXCh4iIiASVwoeIiIgElcKHiIiIBFXUhI9nnnmG/v37ExcXx+TJk1m7dq3VJfnNf//3f2Oz2Rrchg8fbnVZHfbZZ59x9dVXk5GRgc1m46233mrwuGEYPProo6SnpxMfH8/UqVPZvXu3NcV2UGvv8bbbbjvtM73yyiutKbYD5s2bx8SJE0lOTqZXr17MnDmTnTt3NjinoqKCOXPm0L17d5KSkrjuuutO2xk5VLXl/V100UWnfYY//OEPLaq4fZ599lnGjh3r24RqypQpvP/++77Hw/mz82rtPYbz59eUJ554ApvNxn333ee7z8rPMSrCx6uvvsoDDzzAY489xoYNGxg3bhxXXHEF+fn5VpfmN6NGjeLo0aO+2xdffGF1SR1WVlbGuHHjeOaZZ5p8/Le//S1PP/00zz33HGvWrCExMZErrriCioqKIFfaca29R4Arr7yywWe6cOHCIFbYOStWrGDOnDmsXr2apUuXUl1dzeWXX05ZWZnvnPvvv59///vfvP7666xYsYIjR44wa9YsC6tuu7a8P4A77rijwWf429/+1qKK2yczM5MnnniC9evXs27dOi655BJmzJjB1q1bgfD+7Lxae48Qvp9fY19++SXPP/88Y8eObXC/pZ+jEQUmTZpkzJkzx/dnt9ttZGRkGPPmzbOwKv957LHHjHHjxlldRkAAxuLFi31/9ng8RlpamvE///M/vvsKCwsNl8tlLFy40IIKO6/xezQMw7j11luNGTNmWFJPIOTn5xuAsWLFCsMwzM8sJibGeP31133nbN++3QCMVatWWVVmhzV+f4ZhGBdeeKFx7733WleUn3Xt2tV44YUXIu6zq8/7Hg0jcj6/kpISY8iQIcbSpUsbvCerP8eIH/moqqpi/fr1TJ061Xef3W5n6tSprFq1ysLK/Gv37t1kZGQwcOBAZs+eTU5OjtUlBcT+/fvJy8tr8HmmpqYyefLkiPo8AZYvX06vXr0YNmwYd911FydOnLC6pA4rKioCoFu3bgCsX7+e6urqBp/j8OHD6du3b1h+jo3fn9dLL71Ejx49GD16NHPnzqW8vNyK8jrF7XbzyiuvUFZWxpQpUyLus4PT36NXJHx+c+bM4aqrrmrweYH1/w8GbIfTUFFQUIDb7T5ta/fevXuzY8cOi6ryr8mTJ7NgwQKGDRvG0aNH+cUvfsH555/Pli1bSE5Otro8v8rLywNo8vP0PhYJrrzySmbNmsWAAQPYu3cvP//5z5k2bRqrVq3C4XBYXV67eDwe7rvvPs4991xGjx4NmJ9jbGwsXbp0aXBuOH6OTb0/gJtvvpl+/fqRkZHBpk2b+NnPfsbOnTtZtGiRhdW23ebNm5kyZQoVFRUkJSWxePFiRo4cSXZ2dsR8ds29Rwj/zw/glVdeYcOGDXz55ZenPWb1/4MRHz6iwbRp03zHY8eOZfLkyfTr14/XXnuN733vexZWJh110003+Y7HjBnD2LFjGTRoEMuXL+fSSy+1sLL2mzNnDlu2bAnrPqSWNPf+7rzzTt/xmDFjSE9P59JLL2Xv3r0MGjQo2GW227Bhw8jOzqaoqIg33niDW2+9lRUrVlhdll819x5HjhwZ9p9fbm4u9957L0uXLiUuLs7qck4T8dMuPXr0wOFwnNbBe+zYMdLS0iyqKrC6dOnC0KFD2bNnj9Wl+J33M4umzxNg4MCB9OjRI+w+03vuuYd33nmHTz/9lMzMTN/9aWlpVFVVUVhY2OD8cPscm3t/TZk8eTJA2HyGsbGxDB48mLPOOot58+Yxbtw4/vCHP0TMZwfNv8emhNvnt379evLz8znzzDNxOp04nU5WrFjB008/jdPppHfv3pZ+jhEfPmJjYznrrLNYtmyZ7z6Px8OyZcsazO1FktLSUvbu3Ut6errVpfjdgAEDSEtLa/B5FhcXs2bNmoj9PAEOHTrEiRMnwuYzNQyDe+65h8WLF/PJJ58wYMCABo+fddZZxMTENPgcd+7cSU5OTlh8jq29v6ZkZ2cDhM1n2JjH46GysjLsP7uWeN9jU8Lt87v00kvZvHkz2dnZvtuECROYPXu279jSzzHgLa0h4JVXXjFcLpexYMECY9u2bcadd95pdOnSxcjLy7O6NL/4yU9+YixfvtzYv3+/8Z///MeYOnWq0aNHDyM/P9/q0jqkpKTE+Oqrr4yvvvrKAIynnnrK+Oqrr4yDBw8ahmEYTzzxhNGlSxdjyZIlxqZNm4wZM2YYAwYMME6dOmVx5W3X0nssKSkxHnzwQWPVqlXG/v37jY8//tg488wzjSFDhhgVFRVWl94md911l5GammosX77cOHr0qO9WXl7uO+eHP/yh0bdvX+OTTz4x1q1bZ0yZMsWYMmWKhVW3XWvvb8+ePcbjjz9urFu3zti/f7+xZMkSY+DAgcYFF1xgceVt8/DDDxsrVqww9u/fb2zatMl4+OGHDZvNZnz00UeGYYT3Z+fV0nsM98+vOY1X8Fj5OUZF+DAMw/jjH/9o9O3b14iNjTUmTZpkrF692uqS/ObGG2800tPTjdjYWKNPnz7GjTfeaOzZs8fqsjrs008/NYDTbrfeeqthGOZy20ceecTo3bu34XK5jEsvvdTYuXOntUW3U0vvsby83Lj88suNnj17GjExMUa/fv2MO+64I6zCclPvDTD+/ve/+845deqUcffddxtdu3Y1EhISjGuvvdY4evSodUW3Q2vvLycnx7jggguMbt26GS6Xyxg8eLDx0EMPGUVFRdYW3kbf/e53jX79+hmxsbFGz549jUsvvdQXPAwjvD87r5beY7h/fs1pHD6s/BxthmEYgR9fERERETFFfM+HiIiIhBaFDxEREQkqhQ8REREJKoUPERERCSqFDxEREQkqhQ8REREJKoUPERERCSqFDxEREQkqhQ8REREJKoUPERERCSqFDxEREQkqhQ8REREJqv8PdbP6s0IOQcEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 700   6934.84521484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 701   6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 702   6934.80029296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 703   6934.83056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 704   6934.80029296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 705   6934.84326171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 706   6934.79638671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 707   6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 708   6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 709   6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 710   6934.82177734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 711   6934.8310546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.4923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 712   6934.791015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.5067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 713   6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.5296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 714   6934.833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.5545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 715   6934.80126953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.5702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 716   6934.833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.5926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 717   6934.8154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.6177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 718   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.6452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 719   6934.8056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.6681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 720   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.6950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 721   6934.8154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 722   6934.81591796875\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.7250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 723   6934.84619140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.7490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 724   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.7772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 725   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.8057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 726   6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.8372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 727   6934.794921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.8815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 728   6934.84521484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 729   6934.82275390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(6.9763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 730   6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.0128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 731   6934.84423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.0558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 732   6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.0866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 733   6934.7998046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.1115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 734   6934.78369140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 735   6934.8427734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 736   6934.81787109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.1770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 737   6934.8291015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 738   6934.83935546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 739   6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.2349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 740   6934.8583984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.2469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 741   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.2609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 742   6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.2776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 743   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.2943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 744   6934.84423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.3279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 745   6934.80615234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 746   6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.3745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 747   6934.8134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.3954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 748   6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 749   6934.8134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 750   6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 751   6934.8369140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 752   6934.85107421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 753   6934.83642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 754   6934.82275390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 755   6934.8515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 756   6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 757   6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.4849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 758   6934.826171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.5003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 759   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.5147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 760   6934.7958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.5359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 761   6934.80078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.5470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 762   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.5576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 763   6934.82568359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.5620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 764   6934.8291015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.5673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 765   6934.85498046875\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.5829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 766   6934.86279296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.6080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 767   6934.80224609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.6291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 768   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.6578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 769   6934.85205078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.6952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 770   6934.8037109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.7344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 771   6934.78369140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 772   6934.8486328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 773   6934.85498046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.8012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 774   6934.83056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.8369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 775   6934.8349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.8681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 776   6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.8856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 777   6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.9031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 778   6934.8232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.9385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 779   6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(7.9876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 780   6934.814453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.0372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 781   6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.0722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 782   6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.1210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 783   6934.8125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.1636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 784   6934.83349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.2153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 785   6934.81298828125\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.2634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 786   6934.86962890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.3244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 787   6934.8505859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.3835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 788   6934.79052734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 789   6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.4764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 790   6934.8349609375\n",
      "dpo_loss= tensor(0.6932, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.5332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 791   6934.84228515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.6042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 792   6934.853515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.6739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 793   6934.8310546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.7389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 794   6934.81396484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.7969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 795   6934.81396484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 796   6934.810546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.8883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 797   6934.8095703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.9330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 798   6934.82568359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(8.9988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 799   6934.85107421875\n",
      "eval loss 3.3502988815307617\n",
      "Number training steps total: 40\n",
      "eval loss 6.802669048309326\n",
      "loss 0     6.667962074279785\n",
      "loss 1     1.659214735031128\n",
      "loss 2     0.9582318067550659\n",
      "loss 3     2.3735525608062744\n",
      "loss 4     3.300790309906006\n",
      "loss 5     2.803986072540283\n",
      "loss 6     1.7606685161590576\n",
      "loss 7     1.0929328203201294\n",
      "loss 8     0.7643868327140808\n",
      "loss 9     1.0470695495605469\n",
      "eval loss 1.5774985551834106\n",
      "loss 10    1.492794394493103\n",
      "loss 11    2.1867876052856445\n",
      "loss 12    1.408266544342041\n",
      "loss 13    1.073293924331665\n",
      "loss 14    0.7854676246643066\n",
      "loss 15    1.1784889698028564\n",
      "loss 16    0.8428682684898376\n",
      "loss 17    1.0966047048568726\n",
      "loss 18    1.1931477785110474\n",
      "loss 19    1.2130409479141235\n",
      "eval loss 0.9630485773086548\n",
      "loss 20    0.9312087297439575\n",
      "loss 21    0.7443513870239258\n",
      "loss 22    0.6480779647827148\n",
      "loss 23    1.0423831939697266\n",
      "loss 24    0.7397797107696533\n",
      "loss 25    0.7854585647583008\n",
      "loss 26    0.7840516567230225\n",
      "loss 27    1.2516573667526245\n",
      "loss 28    0.6253567934036255\n",
      "loss 29    0.5777245759963989\n",
      "eval loss 0.6545842885971069\n",
      "loss 30    0.6226674318313599\n",
      "loss 31    0.8708086013793945\n",
      "loss 32    0.7197152972221375\n",
      "loss 33    0.712593674659729\n",
      "loss 34    0.6715165376663208\n",
      "loss 35    0.7352673411369324\n",
      "loss 36    0.5475541949272156\n",
      "loss 37    0.5665530562400818\n",
      "loss 38    0.5465197563171387\n",
      "loss 39    0.8812174797058105\n",
      "eval loss 0.616690993309021\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.0683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 800   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 801   6934.8095703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.1881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 802   6934.82177734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.2487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 803   6934.857421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.3117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 804   6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.3681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 805   6934.84423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.4215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 806   6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.4618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 807   6934.86181640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.5065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 808   6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.5558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 809   6934.8154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.6069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 810   6934.80908203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.6494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 811   6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 812   6934.82177734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 813   6934.8310546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.8339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 814   6934.83642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.8973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 815   6934.83837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.9421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 816   6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(9.9757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 817   6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 818   6934.8115234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.0189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 819   6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.0233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 820   6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.0314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 821   6934.81591796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.0552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 822   6934.8564453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.0799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 823   6934.8427734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.1083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 824   6934.8154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.1447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 825   6934.8447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.1855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 826   6934.82373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 827   6934.83251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.2650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 828   6934.830078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.3136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 829   6934.861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.3805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 830   6934.8056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.4455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 831   6934.814453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.4900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 832   6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.5186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 833   6934.8271484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.5341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 834   6934.80029296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.5628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 835   6934.82275390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.5952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 836   6934.8212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.6264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 837   6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.6544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 838   6934.791015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.6750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 839   6934.8427734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.6897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 840   6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 841   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 842   6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 843   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 844   6934.7958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 845   6934.85107421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 846   6934.79736328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 847   6934.826171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 848   6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 849   6934.80615234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 850   6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.7796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 851   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.8212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 852   6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.8684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 853   6934.80419921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.8890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 854   6934.8037109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 855   6934.7939453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 856   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 857   6934.841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 858   6934.82763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 859   6934.80712890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 860   6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.0182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 861   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 862   6934.8134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 863   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.0003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 864   6934.80615234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 865   6934.80224609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 866   6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 867   6934.78173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 868   6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 869   6934.8154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 870   6934.79736328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 871   6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 872   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(10.9907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 873   6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.0131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 874   6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 875   6934.7958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.0640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 876   6934.79345703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.0902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 877   6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 878   6934.82177734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.1668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 879   6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 880   6934.8232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 881   6934.84619140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 882   6934.8134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.3327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 883   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.3793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 884   6934.83251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 885   6934.833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.4802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 886   6934.8349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.5280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 887   6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.5793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 888   6934.8046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 889   6934.83349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.6891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 890   6934.83740234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.7694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 891   6934.7841796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.8331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 892   6934.80712890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.8888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 893   6934.82373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(11.9574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 894   6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.0270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 895   6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.0751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 896   6934.8466796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.1266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 897   6934.8232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.1678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 898   6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 899   6934.8291015625\n",
      "eval loss 3.356168031692505\n",
      "Number training steps total: 40\n",
      "eval loss 6.568957805633545\n",
      "loss 0     6.412354469299316\n",
      "loss 1     1.3955695629119873\n",
      "loss 2     0.9217827320098877\n",
      "loss 3     2.4015965461730957\n",
      "loss 4     3.1921262741088867\n",
      "loss 5     2.5187835693359375\n",
      "loss 6     1.3772733211517334\n",
      "loss 7     0.9990038871765137\n",
      "loss 8     0.6942309141159058\n",
      "loss 9     1.1417381763458252\n",
      "eval loss 1.5976170301437378\n",
      "loss 10    1.5324256420135498\n",
      "loss 11    2.488593101501465\n",
      "loss 12    1.163703441619873\n",
      "loss 13    0.7744649648666382\n",
      "loss 14    0.5858086347579956\n",
      "loss 15    1.0352632999420166\n",
      "loss 16    0.9428454041481018\n",
      "loss 17    1.146467685699463\n",
      "loss 18    1.1630818843841553\n",
      "loss 19    1.0957015752792358\n",
      "eval loss 0.7441421747207642\n",
      "loss 20    0.7377020120620728\n",
      "loss 21    0.5898518562316895\n",
      "loss 22    0.5749490261077881\n",
      "loss 23    1.0683095455169678\n",
      "loss 24    0.7577806711196899\n",
      "loss 25    0.758346438407898\n",
      "loss 26    0.6889315843582153\n",
      "loss 27    0.9285705089569092\n",
      "loss 28    0.5130113363265991\n",
      "loss 29    0.5824828147888184\n",
      "eval loss 0.6415603160858154\n",
      "loss 30    0.641445517539978\n",
      "loss 31    0.8454462885856628\n",
      "loss 32    0.704262912273407\n",
      "loss 33    0.638103187084198\n",
      "loss 34    0.5645330548286438\n",
      "loss 35    0.9941200017929077\n",
      "loss 36    0.5155491828918457\n",
      "loss 37    0.5281456112861633\n",
      "loss 38    0.5737673044204712\n",
      "loss 39    0.9163656234741211\n",
      "eval loss 0.5521522760391235\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.2543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 900   6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 901   6934.8125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.2811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 902   6934.80859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 903   6934.80078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 904   6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 905   6934.8291015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 906   6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 907   6934.80419921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 908   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 909   6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 910   6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 911   6934.828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.3960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 912   6934.80419921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.4161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 913   6934.8388671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.4528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 914   6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.4925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 915   6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.5219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 916   6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.5610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 917   6934.8359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.5908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 918   6934.787109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 919   6934.8056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 920   6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 921   6934.8349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 922   6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 923   6934.7978515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 924   6934.8525390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 925   6934.82373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 926   6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 927   6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 928   6934.8125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 929   6934.8310546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 930   6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 931   6934.8359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 932   6934.84814453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 933   6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 934   6934.8134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 935   6934.82568359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 936   6934.8486328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 937   6934.85205078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 938   6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 939   6934.81982421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 940   6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 941   6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 942   6934.85693359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 943   6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 944   6934.82763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 945   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 946   6934.80908203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 947   6934.8486328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 948   6934.8212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 949   6934.82373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 950   6934.8232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 951   6934.89697265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 952   6934.84326171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 953   6934.83642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 954   6934.83544921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 955   6934.84765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 956   6934.8466796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 957   6934.8212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 958   6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 959   6934.81396484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 960   6934.79638671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 961   6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 962   6934.8291015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 963   6934.837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 964   6934.8095703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 965   6934.8388671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 966   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 967   6934.81005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 968   6934.8271484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 969   6934.83251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 970   6934.80517578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 971   6934.828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 972   6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 973   6934.83349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 974   6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 975   6934.81982421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 976   6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 977   6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 978   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 979   6934.83642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 980   6934.83837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 981   6934.81884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 982   6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 983   6934.81884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 984   6934.814453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 985   6934.82763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 986   6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 987   6934.8359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 988   6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 989   6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 990   6934.83203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 991   6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 992   6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 993   6934.8056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 994   6934.8232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 995   6934.83984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 996   6934.7978515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 997   6934.79150390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 998   6934.84423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 999   6934.8134765625\n",
      "eval loss 3.3488426208496094\n",
      "Number training steps total: 40\n",
      "eval loss 4.525561809539795\n",
      "loss 0     4.400494575500488\n",
      "loss 1     0.619893491268158\n",
      "loss 2     1.4807372093200684\n",
      "loss 3     2.2374463081359863\n",
      "loss 4     2.0542235374450684\n",
      "loss 5     1.047122836112976\n",
      "loss 6     0.5249643325805664\n",
      "loss 7     1.3270295858383179\n",
      "loss 8     1.1248704195022583\n",
      "loss 9     1.2056891918182373\n",
      "eval loss 1.0090508460998535\n",
      "loss 10    0.9630488753318787\n",
      "loss 11    1.0773322582244873\n",
      "loss 12    0.5074377059936523\n",
      "loss 13    0.658698558807373\n",
      "loss 14    0.8785518407821655\n",
      "loss 15    0.9877583384513855\n",
      "loss 16    0.8444875478744507\n",
      "loss 17    0.631767749786377\n",
      "loss 18    0.46336090564727783\n",
      "loss 19    0.8144025802612305\n",
      "eval loss 0.620817244052887\n",
      "loss 20    0.5719641447067261\n",
      "loss 21    0.6337036490440369\n",
      "loss 22    0.5993194580078125\n",
      "loss 23    0.8567044138908386\n",
      "loss 24    0.4530501961708069\n",
      "loss 25    0.46894699335098267\n",
      "loss 26    0.5363353490829468\n",
      "loss 27    0.8200318217277527\n",
      "loss 28    0.5684781670570374\n",
      "loss 29    0.5137197971343994\n",
      "eval loss 0.46592283248901367\n",
      "loss 30    0.4602787494659424\n",
      "loss 31    0.7861544489860535\n",
      "loss 32    0.44510897994041443\n",
      "loss 33    0.48078322410583496\n",
      "loss 34    0.43851616978645325\n",
      "loss 35    0.9268602728843689\n",
      "loss 36    0.4203537702560425\n",
      "loss 37    0.43402594327926636\n",
      "loss 38    0.4681701362133026\n",
      "loss 39    0.6173575520515442\n",
      "eval loss 0.47129344940185547\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1000  6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1001  6934.80322265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1002  6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1003  6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1004  6934.85693359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1005  6934.83837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1006  6934.82275390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1007  6934.796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1008  6934.83544921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1009  6934.84619140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1010  6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1011  6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1012  6934.8232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1013  6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1014  6934.86865234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.6943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1015  6934.83740234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1016  6934.84423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1017  6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1018  6934.82763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1019  6934.8046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.7991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1020  6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1021  6934.83349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1022  6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1023  6934.81982421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1024  6934.8447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1025  6934.83984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1026  6934.80078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1027  6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1028  6934.85205078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1029  6934.83740234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.8859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1030  6934.81591796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1031  6934.82568359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1032  6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1033  6934.845703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(12.9804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1034  6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1035  6934.81884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1036  6934.79638671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1037  6934.8271484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1038  6934.83935546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1039  6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1040  6934.8525390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1041  6934.8544921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1042  6934.79638671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1043  6934.81884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1044  6934.85693359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1045  6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.0937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1046  6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1047  6934.79541015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1048  6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1049  6934.814453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.1751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1050  6934.7958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1051  6934.80224609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1052  6934.81396484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.2826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1053  6934.845703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1054  6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.3655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1055  6934.8212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.4198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1056  6934.833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.4659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1057  6934.81982421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1058  6934.82568359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1059  6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1060  6934.80615234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1061  6934.81005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1062  6934.80615234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1063  6934.8310546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1064  6934.8154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1065  6934.798828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1066  6934.81982421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1067  6934.8388671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1068  6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1069  6934.84228515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.5955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1070  6934.8095703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.6074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1071  6934.8369140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.6243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1072  6934.830078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.6499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1073  6934.80224609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.6578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1074  6934.81591796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.6603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1075  6934.80029296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.6721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1076  6934.83935546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.6927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1077  6934.81591796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1078  6934.830078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1079  6934.80126953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1080  6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1081  6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1082  6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1083  6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1084  6934.81396484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1085  6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1086  6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.7609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1087  6934.8447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1088  6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.8491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1089  6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.8962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1090  6934.82373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.9338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1091  6934.78125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.9393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1092  6934.8310546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1093  6934.83056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(13.9836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1094  6934.79638671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1095  6934.81787109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.0219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1096  6934.7998046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.0403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1097  6934.82373046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.0742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1098  6934.828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.1193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1099  6934.82421875\n",
      "eval loss 3.3458452224731445\n",
      "Number training steps total: 40\n",
      "eval loss 1.9524911642074585\n",
      "loss 0     1.8637381792068481\n",
      "loss 1     0.7581672072410583\n",
      "loss 2     1.5624580383300781\n",
      "loss 3     0.9480037093162537\n",
      "loss 4     0.4259272813796997\n",
      "loss 5     0.5911530256271362\n",
      "loss 6     0.8297735452651978\n",
      "loss 7     1.2675501108169556\n",
      "loss 8     0.42208132147789\n",
      "loss 9     0.4936100244522095\n",
      "eval loss 0.6905682682991028\n",
      "loss 10    0.6876773834228516\n",
      "loss 11    0.8258926272392273\n",
      "loss 12    0.5739806890487671\n",
      "loss 13    0.4203113317489624\n",
      "loss 14    0.41169777512550354\n",
      "loss 15    1.0346629619598389\n",
      "loss 16    0.5172945857048035\n",
      "loss 17    0.4086228311061859\n",
      "loss 18    0.3953183889389038\n",
      "loss 19    0.6840709447860718\n",
      "eval loss 0.532543957233429\n",
      "loss 20    0.5199946165084839\n",
      "loss 21    0.5219656229019165\n",
      "loss 22    0.4334298074245453\n",
      "loss 23    0.7772250175476074\n",
      "loss 24    0.39896082878112793\n",
      "loss 25    0.4032612442970276\n",
      "loss 26    0.41932129859924316\n",
      "loss 27    0.7250317931175232\n",
      "loss 28    0.3960454761981964\n",
      "loss 29    0.4330574870109558\n",
      "eval loss 0.4649794101715088\n",
      "loss 30    0.4474533200263977\n",
      "loss 31    0.6301919221878052\n",
      "loss 32    0.397052526473999\n",
      "loss 33    0.38049477338790894\n",
      "loss 34    0.37702447175979614\n",
      "loss 35    0.7592549324035645\n",
      "loss 36    0.3956771790981293\n",
      "loss 37    0.3732735216617584\n",
      "loss 38    0.39206570386886597\n",
      "loss 39    0.7056107521057129\n",
      "eval loss 0.42845088243484497\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.1597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1100  6934.810546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.1984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1101  6934.8232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.2299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1102  6934.8134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.2544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1103  6934.80712890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.2745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1104  6934.7998046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.2959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1105  6934.791015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1106  6934.80712890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.3117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1107  6934.830078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.3278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1108  6934.8115234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.3450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1109  6934.80908203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.3685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1110  6934.8115234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.3999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1111  6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.4361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1112  6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1113  6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.5219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1114  6934.8134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.5534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1115  6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.5884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1116  6934.81884765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.6187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1117  6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.6505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1118  6934.84619140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.6800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1119  6934.8212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1120  6934.83251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.7497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1121  6934.880859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.7783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1122  6934.8349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.8172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1123  6934.9296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.8614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1124  6934.90869140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.9005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1125  6934.912109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.9403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1126  6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.9643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1127  6934.904296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(14.9845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1128  6934.90478515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1129  6934.91650390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.0129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1130  6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.0243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1131  6934.94873046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1132  6934.89794921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1133  6934.966796875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.0683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1134  6934.84228515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.5140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.0855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1135  6934.98974609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1136  6934.85205078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1137  6934.93994140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1138  6934.888671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1139  6934.88720703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1140  6934.85986328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1141  6934.873046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1142  6934.8828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1143  6934.859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.4051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1144  6934.87646484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1145  6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1146  6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1147  6934.833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1148  6934.84375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1149  6934.84912109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1150  6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1151  6934.857421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1152  6934.8232421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1153  6934.85888671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1154  6934.83642578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.1937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1155  6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.2304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1156  6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.2614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1157  6934.82861328125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.2836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1158  6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.3038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1159  6934.8056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1160  6934.8408203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.3396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1161  6934.8056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.3528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1162  6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.3764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1163  6934.7939453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.4069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1164  6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.4317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1165  6934.83251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.4715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1166  6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.5043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1167  6934.83056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.5442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1168  6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.5879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1169  6934.8056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.6295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1170  6934.828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.6642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1171  6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1172  6934.8134765625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.7089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1173  6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.7251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1174  6934.8271484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.7526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1175  6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.7544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1176  6934.84228515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.7577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1177  6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.7631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1178  6934.8037109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.7751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1179  6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.7969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1180  6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.8240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1181  6934.79638671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.8403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1182  6934.8291015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.8590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1183  6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.8655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1184  6934.80126953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.8722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1185  6934.810546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.8840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1186  6934.83154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.8918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1187  6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1188  6934.83251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1189  6934.791015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1190  6934.80810546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1191  6934.826171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1192  6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1193  6934.79443359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1194  6934.80224609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1195  6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1196  6934.810546875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1197  6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1198  6934.82763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1199  6934.8291015625\n",
      "eval loss 3.346595048904419\n",
      "Number training steps total: 40\n",
      "eval loss 1.4049967527389526\n",
      "loss 0     1.3061624765396118\n",
      "loss 1     1.2395057678222656\n",
      "loss 2     1.1027055978775024\n",
      "loss 3     0.6417241096496582\n",
      "loss 4     0.5180269479751587\n",
      "loss 5     0.7082341909408569\n",
      "loss 6     0.552847146987915\n",
      "loss 7     0.7315799593925476\n",
      "loss 8     0.5267598032951355\n",
      "loss 9     0.702908456325531\n",
      "eval loss 0.5994454622268677\n",
      "loss 10    0.5956709980964661\n",
      "loss 11    0.6619117856025696\n",
      "loss 12    0.4039045572280884\n",
      "loss 13    0.432657927274704\n",
      "loss 14    0.4719306528568268\n",
      "loss 15    0.8191458582878113\n",
      "loss 16    0.37513217329978943\n",
      "loss 17    0.45522356033325195\n",
      "loss 18    0.49943578243255615\n",
      "loss 19    0.6903828382492065\n",
      "eval loss 0.4151007831096649\n",
      "loss 20    0.3916497230529785\n",
      "loss 21    0.38116544485092163\n",
      "loss 22    0.3927593231201172\n",
      "loss 23    0.8460501432418823\n",
      "loss 24    0.3741339445114136\n",
      "loss 25    0.3699987530708313\n",
      "loss 26    0.41759341955184937\n",
      "loss 27    0.569128155708313\n",
      "loss 28    0.4025782644748688\n",
      "loss 29    0.39413338899612427\n",
      "eval loss 0.40569913387298584\n",
      "loss 30    0.3615967929363251\n",
      "loss 31    0.6599330902099609\n",
      "loss 32    0.3760339617729187\n",
      "loss 33    0.36929410696029663\n",
      "loss 34    0.3798130750656128\n",
      "loss 35    0.6764482259750366\n",
      "loss 36    0.39792555570602417\n",
      "loss 37    0.37626540660858154\n",
      "loss 38    0.3674551844596863\n",
      "loss 39    0.6599353551864624\n",
      "eval loss 0.404167115688324\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1200  6934.82177734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1201  6934.83447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1202  6934.82421875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1203  6934.79541015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1204  6934.8427734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1205  6934.81689453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1206  6934.81787109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(15.9963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1207  6934.80712890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1208  6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.0457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1209  6934.82763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.0712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1210  6934.802734375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1211  6934.8212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.1272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1212  6934.81787109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1213  6934.80859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.1819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1214  6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.2090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1215  6934.8154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1216  6934.830078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.2763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1217  6934.8046875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1218  6934.8095703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.3471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1219  6934.79833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.3728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1220  6934.8271484375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.4007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1221  6934.814453125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1222  6934.80078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.4537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1223  6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.4946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1224  6934.80859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.5316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1225  6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.5663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1226  6934.83837890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.6050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1227  6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.6370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1228  6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.6752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1229  6934.8125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1230  6934.8212890625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1231  6934.833984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.7692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1232  6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.7953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1233  6934.81103515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1234  6934.81787109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.8634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1235  6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.9007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1236  6934.83349609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.9368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1237  6934.8017578125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.9702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1238  6934.82568359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(16.9989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1239  6934.82275390625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.0263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1240  6934.826171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.0566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1241  6934.8173828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.0943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1242  6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.1296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1243  6934.80419921875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1244  6934.849609375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.2017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1245  6934.84619140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.2445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1246  6934.84423828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.2862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1247  6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.3337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1248  6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.3722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1249  6934.82666015625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.4054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1250  6934.8447265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.4434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1251  6934.828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.4760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1252  6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.5037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1253  6934.81005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.5328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1254  6934.82763671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.5529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1255  6934.81494140625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.5694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1256  6934.822265625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.5802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1257  6934.8193359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.5961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1258  6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.6201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1259  6934.83056640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.6827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1260  6934.8154296875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.7384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1261  6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.7763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1262  6934.82080078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.8220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1263  6934.818359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1264  6934.8076171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1265  6934.8359375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1266  6934.81201171875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.9621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1267  6934.8037109375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(17.9843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1268  6934.84033203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.0093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1269  6934.82470703125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.0256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1270  6934.81640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.0544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1271  6934.8115234375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.0823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1272  6934.828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.1200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1273  6934.81005859375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1274  6934.806640625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.1816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1275  6934.7978515625\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1276  6934.8251953125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.2249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1277  6934.81298828125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.2408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1278  6934.8203125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.2693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1279  6934.80078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.2895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1280  6934.79638671875\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1281  6934.8330078125\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.3273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1282  6934.82958984375\n",
      "dpo_loss= tensor(0.6931, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "nll_loss= tensor(3.3234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "avg_std= tensor(18.3397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "loss 1283  6934.79931640625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m get_dpo_loss_partial \u001b[38;5;241m=\u001b[39m partial(get_dpo_loss, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, dpo_loss_beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, reward_model\u001b[38;5;241m=\u001b[39mreward_model, train_reward_model\u001b[38;5;241m=\u001b[39mtrain_reward_model_partial)\n\u001b[1;32m     12\u001b[0m dpo_trained_model_with_reward_model \u001b[38;5;241m=\u001b[39m QuietStarLanguageModelLSTM(\u001b[38;5;28mlen\u001b[39m(vocab), \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_dpo_loss_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_loss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_nll\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpo_trained_model_with_reward_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(get_loss_fn, eval_fn, model, batch_size, epochs, train_dl, eval_every, print_stuff)\u001b[0m\n\u001b[1;32m     35\u001b[0m     eval_losses\u001b[38;5;241m.\u001b[39mappend((i, eval_loss))\n\u001b[1;32m     36\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 37\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_loss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_stuff:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[35], line 37\u001b[0m, in \u001b[0;36mget_dpo_loss\u001b[0;34m(model, inputs, beta_2, target_model, num_samples, dpo_loss_beta, nll_loss_beta, forward_kl_reward, reward_model, train_reward_model)\u001b[0m\n\u001b[1;32m     35\u001b[0m dpo_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(repeat_gold_action_weight\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m*\u001b[39m repeat_log_weight_on_hidden_states)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m dpo_loss \u001b[38;5;241m*\u001b[39m dpo_loss_beta \u001b[38;5;241m+\u001b[39m nll_loss \u001b[38;5;241m*\u001b[39m nll_loss_beta\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdpo_loss\u001b[49m\u001b[38;5;132;43;01m= }\u001b[39;49;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnll_loss\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m dist \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_hidden_state_dist(repeat_inputs)\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/_tensor.py:523\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    520\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/_tensor_str.py:708\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    707\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 708\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/_tensor_str.py:625\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    623\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    624\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 625\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    628\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/_tensor_str.py:357\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m/coc/flash9/jbjorner3/miniforge3/envs/quiet-star-replicate-v1/lib/python3.12/site-packages/torch/_tensor_str.py:145\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reward_model = RewardModel(len(vocab), hidden_dim=100).to(device)\n",
    "num_calls_trainer = 0\n",
    "def train_reward_model_partial(reward_model, model):\n",
    "    global num_calls_trainer\n",
    "    if num_calls_trainer % 100 == 0:\n",
    "        num_calls_trainer += 1\n",
    "        return train_reward_model(reward_model, model, sample_for_train=False, print_stuff=True)\n",
    "    else:\n",
    "        num_calls_trainer += 1\n",
    "        return None # train_reward_model(reward_model, model, sample_for_train=False, print_stuff=False)\n",
    "get_dpo_loss_partial = partial(get_dpo_loss, beta_2=0.0001, dpo_loss_beta=10000, num_samples=2, reward_model=reward_model, train_reward_model=train_reward_model_partial)\n",
    "dpo_trained_model_with_reward_model = QuietStarLanguageModelLSTM(len(vocab), 100, 1).to(device)\n",
    "train_model(get_dpo_loss_partial, lambda model: eval_loss_fn(model, get_nll), dpo_trained_model_with_reward_model, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quiet-star-replicate-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
